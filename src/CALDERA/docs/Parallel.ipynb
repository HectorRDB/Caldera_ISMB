{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing the code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from importlib import reload\n",
    "import sys\n",
    "import os\n",
    "import profiling\n",
    "import sys, os\n",
    "import numpy as np\n",
    "import time\n",
    "sys.path.append(os.path.abspath(\"/Users/hector/Documents/BGWAS2/dbgwas_docker/scripts/simulation\"))\n",
    "from generate_data import *\n",
    "sys.path.append(os.path.abspath(\"/Users/hector/Documents/BGWAS2/dbgwas_docker/Tarone/scripts\"))\n",
    "import ExploreBFS as bfs\n",
    "import ExploreDFS as dfs\n",
    "import Helper_Explo\n",
    "import speed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'line_profiler'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-946a311175ea>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_line_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'load_ext'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'line_profiler'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_line_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'load_ext'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'memory_profiler'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/site-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mrun_line_magic\u001b[0;34m(self, magic_name, line, _stack_depth)\u001b[0m\n\u001b[1;32m   2315\u001b[0m                 \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'local_ns'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getframe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstack_depth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf_locals\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2316\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuiltin_trap\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2317\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2318\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2319\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<decorator-gen-64>\u001b[0m in \u001b[0;36mload_ext\u001b[0;34m(self, module_str)\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/site-packages/IPython/core/magic.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(f, *a, **k)\u001b[0m\n\u001b[1;32m    185\u001b[0m     \u001b[0;31m# but it's overkill for just that one bit of state.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmagic_deco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 187\u001b[0;31m         \u001b[0mcall\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    188\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/site-packages/IPython/core/magics/extension.py\u001b[0m in \u001b[0;36mload_ext\u001b[0;34m(self, module_str)\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mmodule_str\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mUsageError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Missing module name.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshell\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextension_manager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_extension\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule_str\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mres\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'already loaded'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/site-packages/IPython/core/extensions.py\u001b[0m in \u001b[0;36mload_extension\u001b[0;34m(self, module_str)\u001b[0m\n\u001b[1;32m     78\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mmodule_str\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodules\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mprepended_to_syspath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mipython_extension_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 80\u001b[0;31m                     \u001b[0mmod\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimport_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule_str\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     81\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mmod\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__file__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mipython_extension_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m                         print((\"Loading extensions from {dir} is deprecated. \"\n",
      "\u001b[0;32m/usr/local/Cellar/python@3.8/3.8.2/Frameworks/Python.framework/Versions/3.8/lib/python3.8/importlib/__init__.py\u001b[0m in \u001b[0;36mimport_module\u001b[0;34m(name, package)\u001b[0m\n\u001b[1;32m    125\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m             \u001b[0mlevel\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 127\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_bootstrap\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_gcd_import\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpackage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    128\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/python@3.8/3.8.2/Frameworks/Python.framework/Versions/3.8/lib/python3.8/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_gcd_import\u001b[0;34m(name, package, level)\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/python@3.8/3.8.2/Frameworks/Python.framework/Versions/3.8/lib/python3.8/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_find_and_load\u001b[0;34m(name, import_)\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/python@3.8/3.8.2/Frameworks/Python.framework/Versions/3.8/lib/python3.8/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_find_and_load_unlocked\u001b[0;34m(name, import_)\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'line_profiler'"
     ]
    }
   ],
   "source": [
    "%load_ext line_profiler\n",
    "%load_ext memory_profiler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check with N = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.5s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.9s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:   10.3s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    4.6s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.4s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Timer unit: 1e-06 s\n",
       "\n",
       "Total time: 2.10124 s\n",
       "File: /Users/hector/Documents/BGWAS2/dbgwas_docker/Tarone/scripts/Envelope.py\n",
       "Function: minimal_p_value at line 21\n",
       "\n",
       "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
       "==============================================================\n",
       "    21                                           def minimal_p_value(xs, n1s, n2s):\n",
       "    22                                               \"\"\"Given the frequencies in the various populations, compute the minimal p-value.\"\"\"\n",
       "    23                                               \"\"\"xs - An array of frequencies, one dimension\"\"\"\n",
       "    24                                               \"\"\"n1s - An array of population size among the first group, one dimension\"\"\"\n",
       "    25                                               \"\"\"n2s - An array of population size among the second group, one dimension\"\"\"\n",
       "    26                                           \n",
       "    27     42156      79520.0      1.9      3.8      ns = n1s + n2s\n",
       "    28     42156      66420.0      1.6      3.2      num = np.multiply(xs, n1s)\n",
       "    29     42156      72358.0      1.7      3.4      num = np.divide(num, ns)\n",
       "    30     42156     400626.0      9.5     19.1      denum = n1s * n2s * xs * (1 - xs / ns) / (ns * (ns - 1))\n",
       "    31     42156     279145.0      6.6     13.3      denum = denum.sum()\n",
       "    32                                               \n",
       "    33     42156      59194.0      1.4      2.8      if denum == 0:\n",
       "    34         2          1.0      0.5      0.0          return 0\n",
       "    35                                               \n",
       "    36     42154     350128.0      8.3     16.7      aMin = np.maximum(0, xs - n2s).sum()\n",
       "    37     42154     185711.0      4.4      8.8      numMin = aMin - num.sum()\n",
       "    38     42154      63208.0      1.5      3.0      numMin = numMin**2\n",
       "    39     42154     237919.0      5.6     11.3      aMax = np.minimum(xs, n1s).sum()\n",
       "    40     42154     170539.0      4.0      8.1      numMax = aMax - num.sum()\n",
       "    41     42154      49994.0      1.2      2.4      numMax = numMax**2\n",
       "    42                                               \n",
       "    43     42154      57805.0      1.4      2.8      num = max(numMin, numMax)\n",
       "    44     42154      28673.0      0.7      1.4      return num / denum\n",
       "\n",
       "Total time: 4.41483 s\n",
       "File: /Users/hector/Documents/BGWAS2/dbgwas_docker/Tarone/scripts/Envelope.py\n",
       "Function: envelope at line 46\n",
       "\n",
       "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
       "==============================================================\n",
       "    46                                           def envelope(xs, n1s, n2s):\n",
       "    47                                               \"\"\"Given the frequencies in the various populations, compute the envelope\"\"\"\n",
       "    48                                               \"\"\"xs - An array of frequencies, one dimension\"\"\"\n",
       "    49                                               \"\"\"n1s - An array of population size among the first group, one dimension\"\"\"\n",
       "    50                                               \"\"\"n2s - An array of population size among the second group, one dimension\"\"\"\n",
       "    51                                           \n",
       "    52     21117      53398.0      2.5      1.2      thresh = xs < np.maximum(n1s, n2s)\n",
       "    53                                               # If were are below the threshold, we do not compute the enveloppe\n",
       "    54                                               # since there will be no prunning anyway\n",
       "    55     21117      36059.0      1.7      0.8      if any(thresh):\n",
       "    56        78       5523.0     70.8      0.1          return minimal_p_value(xs, n1s, n2s)\n",
       "    57                                               \n",
       "    58                                               # Otherwise we can compute the enveloppe\n",
       "    59     21039      34669.0      1.6      0.8      ns = n1s + n2s\n",
       "    60     21039     105297.0      5.0      2.4      betaLs = n1s * xs /(ns ** 2)\n",
       "    61     21039      68366.0      3.2      1.5      betaRs = n2s * xs /(ns ** 2)\n",
       "    62     21039     185911.0      8.8      4.2      piL = np.argsort(betaLs)\n",
       "    63     21039     110591.0      5.3      2.5      piR = np.argsort(betaRs)\n",
       "    64                                           \n",
       "    65     21039      86596.0      4.1      2.0      xStars = ns * 1\n",
       "    66     21039     209893.0     10.0      4.8      pMinLs = np.ones(len(piL,))\n",
       "    67     42078      60402.0      1.4      1.4      for i in range(len(piL)):\n",
       "    68     21039      40385.0      1.9      0.9          xStars[piL[i]] = xs[piL[i]]\n",
       "    69     21039    1333831.0     63.4     30.2          pMinLs[i] = minimal_p_value(xStars, n1s, n2s)\n",
       "    70                                           \n",
       "    71     21039      64302.0      3.1      1.5      xStars = ns * 1\n",
       "    72     21039     169051.0      8.0      3.8      pMinRs = np.ones(len(piR,))\n",
       "    73     42078      49220.0      1.2      1.1      for i in range(len(piR)):\n",
       "    74     21039      33761.0      1.6      0.8          xStars[piR[i]] = xs[piR[i]]\n",
       "    75     21039    1190915.0     56.6     27.0          pMinRs[i] = minimal_p_value(xStars, n1s, n2s)\n",
       "    76                                           \n",
       "    77     21039     562108.0     26.7     12.7      env = np.append(pMinLs, pMinRs).max()\n",
       "    78     21039      14551.0      0.7      0.3      return env\n",
       "\n",
       "Total time: 19.969 s\n",
       "File: /Users/hector/Documents/BGWAS2/dbgwas_docker/Tarone/scripts/ExploreBFS.py\n",
       "Function: explore at line 24\n",
       "\n",
       "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
       "==============================================================\n",
       "    24                                           def explore(G, alpha, kmax, Lmax = 10 ** 7, verbose = False, threads = 1,\n",
       "    25                                                       backend = \"loky\"):\n",
       "    26                                               \"\"\"Compute the set R by incremental values of k:\n",
       "    27                                               \n",
       "    28                                               Args:\n",
       "    29                                                   G: the graph we want to explore.\n",
       "    30                                                   alpha: between 0 and 1. FWER we want to control.\n",
       "    31                                                   n1s: An vector of group sizes among the first phenotype.\n",
       "    32                                                   n2s: An vector of group sizes among the second phenotype.\n",
       "    33                                                   kmax: an integer, the maximum value of k we allow.\n",
       "    34                                                   Lmax: maximum size of the subgraph\n",
       "    35                                                   verbose: a boolean, default to false.\n",
       "    36                                                   threads: Number of cores used in the process\n",
       "    37                                                   backend: the backend used for parallelization\n",
       "    38                                               \n",
       "    39                                               Return:\n",
       "    40                                                   The array R of testable subgraphs.\n",
       "    41                                               \"\"\"\n",
       "    42                                               # We avoid computing this too often\n",
       "    43         1        589.0    589.0      0.0      n1s, n2s = G.ns()\n",
       "    44         1        622.0    622.0      0.0      n = int(n1s.sum() + n2s.sum())\n",
       "    45         1         17.0     17.0      0.0      nNodes = G.lengths.shape[0]\n",
       "    46         1       1466.0   1466.0      0.0      k0, TH = find_ko(np.array([]), alpha , 1)\n",
       "    47         1          3.0      3.0      0.0      if verbose:\n",
       "    48                                                   message1 = ('Starting to explore a graph with ' +\n",
       "    49                                                               '{N} nodes.'.format(N = nNodes))\n",
       "    50                                                   message2 = ('The value of alpha is {alpha}. '.format(alpha = alpha) +\n",
       "    51                                                               'k0 is initialized at 1.')\n",
       "    52                                                   print(message1)\n",
       "    53                                                   print(message2)\n",
       "    54                                                   print()\n",
       "    55                                               \n",
       "    56                                               # Initiate the list of candidates. We create the closure of every subgraph\n",
       "    57                                               # of size 1\n",
       "    58         1         48.0     48.0      0.0      chunks = np.array(range(nNodes))\n",
       "    59         1         57.0     57.0      0.0      chunks = np.array_split(chunks, threads)\n",
       "    60         1        237.0    237.0      0.0      C = Parallel(n_jobs=threads, backend = backend, verbose = 1)(\n",
       "    61         1      37080.0  37080.0      0.2                   delayed(start)(chunk, G, TH, n1s, n2s) for chunk in chunks)\n",
       "    62         1         32.0     32.0      0.0      C = np.concatenate(C)\n",
       "    63                                               # Then we prune the redundant ones\n",
       "    64         1        131.0    131.0      0.0      Tb = itemtable(nNodes)\n",
       "    65                                               \n",
       "    66       101        401.0      4.0      0.0      for i, S in enumerate(C):\n",
       "    67       100       2917.0     29.2      0.0          explored = Tb.add_table(max(S.nodes), S.ys)\n",
       "    68                                               \n",
       "    69         1         65.0     65.0      0.0      chunks = np.array_split(C, threads)\n",
       "    70         1        201.0    201.0      0.0      Env = Parallel(n_jobs=threads, backend = backend, verbose = 0)(\n",
       "    71         1        535.0    535.0      0.0                     delayed(compute_envelopes)(chunk) for chunk in chunks)\n",
       "    72         1         19.0     19.0      0.0      Env = np.concatenate(Env)\n",
       "    73         1        171.0    171.0      0.0      Prunable = Parallel(n_jobs=threads, backend = backend, verbose = 0)(\n",
       "    74         1        468.0    468.0      0.0                          delayed(are_prunable)(chunk) for chunk in chunks)\n",
       "    75         1         14.0     14.0      0.0      Prunable = np.concatenate(Prunable)\n",
       "    76         1        169.0    169.0      0.0      Too_Large = Parallel(n_jobs=threads, backend = backend, verbose = 0)(\n",
       "    77         1        514.0    514.0      0.0                          delayed(are_too_large)(chunk, Lmax) for chunk in chunks)\n",
       "    78         1         15.0     15.0      0.0      Too_Large = np.concatenate(Too_Large)\n",
       "    79                                               \n",
       "    80                                               # We then find the updated k0 we considering only subgraphs of size 1\n",
       "    81         1       3359.0   3359.0      0.0      k0, TH = find_ko(Env, alpha)\n",
       "    82                                           \n",
       "    83                                               # We clean the list and we save testable subgraphs\n",
       "    84         1          7.0      7.0      0.0      are_Testable = Env >= TH\n",
       "    85         1          6.0      6.0      0.0      R = C[are_Testable]\n",
       "    86         1          4.0      4.0      0.0      R_Env = Env[are_Testable]\n",
       "    87         1         26.0     26.0      0.0      Keep = (Prunable * (1 - are_Testable) + Too_Large) == 0\n",
       "    88                                               \n",
       "    89         1          2.0      2.0      0.0      if verbose:\n",
       "    90                                                   messages(are_Testable, nNodes, Keep, Too_Large, Prunable, k0)\n",
       "    91                                               \n",
       "    92         1          4.0      4.0      0.0      C = C[Keep]\n",
       "    93                                               \n",
       "    94                                               # We then explore all subgraphs of size 2 and so on and so forth\n",
       "    95         5         17.0      3.4      0.0      while C.shape[0] > 0:\n",
       "    96         5         12.0      2.4      0.0          if k0 > kmax:\n",
       "    97                                                       if verbose:\n",
       "    98                                                           print('Reached kmax value')\n",
       "    99                                                       break\n",
       "   100                                                   # Compute all the parents\n",
       "   101         5        255.0     51.0      0.0          chunks = np.array_split(C, threads)\n",
       "   102         5        886.0    177.2      0.0          Parents = Parallel(n_jobs=threads, backend = backend, verbose = 1)(\n",
       "   103         5   19781630.0 3956326.0     99.1                  delayed(expand)(chunk, G, TH, n1s, n2s, Tb) for chunk in chunks)\n",
       "   104         5        417.0     83.4      0.0          Parents = np.concatenate(Parents)\n",
       "   105         5         31.0      6.2      0.0          if Parents.shape[0] == 0:\n",
       "   106         1          3.0      3.0      0.0              break\n",
       "   107         4         56.0     14.0      0.0          Explored = np.zeros(Parents.shape[0], dtype = np.bool)\n",
       "   108                                                   # Prune the redundants via the itemtable\n",
       "   109      2823       7029.0      2.5      0.0          for i, S in enumerate(Parents):\n",
       "   110      2819      70827.0     25.1      0.4              explored = Tb.check_table(max(S.nodes), S.ys)\n",
       "   111      2819       6341.0      2.2      0.0              if not explored:\n",
       "   112      1496      21764.0     14.5      0.1                  Tb.add_table(max(S.nodes), S.ys)\n",
       "   113      2819       7578.0      2.7      0.0              Explored[i] = explored\n",
       "   114                                                   \n",
       "   115                                                   # Update the set of closed subgraphs we explore after removing the\n",
       "   116                                                   # redundants\n",
       "   117         4        122.0     30.5      0.0          C =  Parents[Explored == False]\n",
       "   118                                                   \n",
       "   119         4        270.0     67.5      0.0          chunks = np.array_split(C, threads)\n",
       "   120         4        749.0    187.2      0.0          Env = Parallel(n_jobs=threads, backend = backend, verbose = 0)(\n",
       "   121         4       2505.0    626.2      0.0                         delayed(compute_envelopes)(chunk) for chunk in chunks)\n",
       "   122         4         61.0     15.2      0.0          Env = np.concatenate(Env)\n",
       "   123         4        625.0    156.2      0.0          Prunable = Parallel(n_jobs=threads, backend = backend, verbose = 0)(\n",
       "   124         4       2044.0    511.0      0.0                              delayed(are_prunable)(chunk) for chunk in chunks)\n",
       "   125         4         46.0     11.5      0.0          Prunable = np.concatenate(Prunable)\n",
       "   126         4        658.0    164.5      0.0          Too_Large = Parallel(n_jobs=threads, backend = backend, verbose = 0)(\n",
       "   127         4       2798.0    699.5      0.0                          delayed(are_too_large)(chunk, Lmax) for chunk in chunks)\n",
       "   128         4         55.0     13.8      0.0          Too_Large = np.concatenate(Too_Large)\n",
       "   129                                                   \n",
       "   130         4      12385.0   3096.2      0.1          k0, TH = find_ko(np.concatenate([Env, R_Env]), alpha, k0)\n",
       "   131                                                   \n",
       "   132         4         27.0      6.8      0.0          are_Testable = Env >= TH\n",
       "   133         4        363.0     90.8      0.0          R = np.concatenate([R[R_Env >= TH], C[are_Testable]])\n",
       "   134         4        103.0     25.8      0.0          R_Env = np.concatenate([R_Env[R_Env >= TH], Env[are_Testable]])\n",
       "   135         4         77.0     19.2      0.0          Keep = (Prunable * (1 - are_Testable) + Too_Large) == 0\n",
       "   136                                                   \n",
       "   137         4         10.0      2.5      0.0          if verbose:\n",
       "   138                                                       messages(are_Testable, C.shape[0], Keep, Too_Large, Prunable, k0)\n",
       "   139         4         27.0      6.8      0.0          C = C[Keep]\n",
       "   140                                                   \n",
       "   141                                               # We have finished and we return the testable graphs\n",
       "   142         1          2.0      2.0      0.0      return R, R_Env, k0, TH\n",
       "\n",
       "Total time: 0.035241 s\n",
       "File: /Users/hector/Documents/BGWAS2/dbgwas_docker/Tarone/scripts/Helper_Explo.py\n",
       "Function: start at line 51\n",
       "\n",
       "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
       "==============================================================\n",
       "    51                                           def start(nodes, G, TH, n1s, n2s):\n",
       "    52                                               \"\"\"Create the graph from the nodes and compute their envelope in chunks\n",
       "    53                                               \n",
       "    54                                               Args:\n",
       "    55                                                   nodes: a list of nodes numbers\n",
       "    56                                                   G: the graph structure we want to explore\n",
       "    57                                                   TH: the initial value of the threshold\n",
       "    58                                                   n1s: An vector of group sizes among the first phenotype.\n",
       "    59                                                   n2s: An vector of group sizes among the second phenotype.\n",
       "    60                                               Return:\n",
       "    61                                                   The graphs, their envelopes and some info for pruning\n",
       "    62                                               \"\"\"\n",
       "    63         1      35188.0  35188.0     99.8      R = [create_Graph(s, G, TH, n1s, n2s) for s in nodes]\n",
       "    64         1         52.0     52.0      0.1      R = np.array([S for S in R if S.closed and not S.to_prune], dtype = graph)\n",
       "    65         1          1.0      1.0      0.0      return R\n",
       "\n",
       "Total time: 0.034789 s\n",
       "File: /Users/hector/Documents/BGWAS2/dbgwas_docker/Tarone/scripts/Helper_Explo.py\n",
       "Function: create_Graph at line 67\n",
       "\n",
       "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
       "==============================================================\n",
       "    67                                           def create_Graph(s, G, TH, n1s, n2s):\n",
       "    68                                               \"\"\"Create and return a (closed) subgraph starting from node s of graph G\n",
       "    69                                           \n",
       "    70                                               Args:\n",
       "    71                                                   s: The node\n",
       "    72                                                   G: the graph structure we want to explore\n",
       "    73                                                   TH: the initial value of the threshold\n",
       "    74                                                   n1s: An vector of group sizes among the first phenotype.\n",
       "    75                                                   n2s: An vector of group sizes among the second phenotype.\n",
       "    76                                               Return:\n",
       "    77                                                   The closure\n",
       "    78                                               \"\"\"\n",
       "    79       100       2186.0     21.9      6.3      S = graph(G)\n",
       "    80       100      32544.0    325.4     93.5      S.new_graph(node = s, G = G, TH = TH, n1s = n1s, n2s = n2s)\n",
       "    81       100         59.0      0.6      0.2      return S\n",
       "\n",
       "Total time: 19.7246 s\n",
       "File: /Users/hector/Documents/BGWAS2/dbgwas_docker/Tarone/scripts/Helper_Explo.py\n",
       "Function: expand at line 83\n",
       "\n",
       "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
       "==============================================================\n",
       "    83                                           def expand(Ss, G, TH, n1s, n2s, Tb):\n",
       "    84                                               \"\"\"Find all parents\n",
       "    85                                           \n",
       "    86                                               Args:\n",
       "    87                                                   Ss: an array of objects of class graph for which we want to compute the\n",
       "    88                                                   envelope\n",
       "    89                                                   G: the graph structure we explore\n",
       "    90                                                   TH: the initial value of the threshold\n",
       "    91                                                   n1s: An vector of group sizes among the first phenotype.\n",
       "    92                                                   n2s: An vector of group sizes among the second phenotype.\n",
       "    93                                                   Tb: the curent itemtable\n",
       "    94                                                   \n",
       "    95                                               Return:\n",
       "    96                                                   An array of parents\n",
       "    97                                               \"\"\"\n",
       "    98         5    4208772.0 841754.4     21.3      Tb2 = copy.deepcopy(Tb)\n",
       "    99         5         39.0      7.8      0.0      if Ss.shape[0] == 0:\n",
       "   100                                                   return np.array([], dtype = graph)\n",
       "   101                                               else:\n",
       "   102         5   15515772.0 3103154.4     78.7          return np.concatenate([Tb2.Parents(S, G, TH, n1s, n2s) for S in Ss])\n",
       "\n",
       "Total time: 0.00112 s\n",
       "File: /Users/hector/Documents/BGWAS2/dbgwas_docker/Tarone/scripts/Helper_Explo.py\n",
       "Function: are_too_large at line 104\n",
       "\n",
       "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
       "==============================================================\n",
       "   104                                           def are_too_large(Ss, Lmax):\n",
       "   105                                               \"\"\"Look at whether the graphs are prunable or not\n",
       "   106                                           \n",
       "   107                                               Args:\n",
       "   108                                                   Ss: an array of objects of class graph for which we want to compute the\n",
       "   109                                                   envelope\n",
       "   110                                                   Pop: the vector of populations\n",
       "   111                                                   n1s: An vector of group sizes among the first phenotype.\n",
       "   112                                                   n2s: An vector of group sizes among the second phenotype.\n",
       "   113                                           \n",
       "   114                                               Return:\n",
       "   115                                                   A array boolean, whether the graph is prunable\n",
       "   116                                               \"\"\"\n",
       "   117         5          6.0      1.2      0.5      if len(Ss) == 1:\n",
       "   118                                                   return [Ss[0].length > Lmax]\n",
       "   119                                               else:\n",
       "   120         5       1110.0    222.0     99.1          Sizes = np.array([S.length > Lmax for S in Ss], dtype = np.bool_)\n",
       "   121         5          4.0      0.8      0.4          return Sizes\n",
       "\n",
       "Total time: 1.7e-05 s\n",
       "File: /Users/hector/Documents/BGWAS2/dbgwas_docker/Tarone/scripts/Helper_Explo.py\n",
       "Function: __init__ at line 138\n",
       "\n",
       "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
       "==============================================================\n",
       "   138                                               def __init__(self, Pop, neighbours, nodes, pheno, lengths):\n",
       "   139         1         13.0     13.0     76.5          self.Pop = Pop\n",
       "   140         1          1.0      1.0      5.9          self.neighbours = neighbours\n",
       "   141         1          1.0      1.0      5.9          self.pattern = nodes\n",
       "   142         1          1.0      1.0      5.9          self.Pheno = pheno\n",
       "   143         1          1.0      1.0      5.9          self.lengths = lengths\n",
       "\n",
       "Total time: 0.000558 s\n",
       "File: /Users/hector/Documents/BGWAS2/dbgwas_docker/Tarone/scripts/Helper_Explo.py\n",
       "Function: ns at line 145\n",
       "\n",
       "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
       "==============================================================\n",
       "   145                                               def ns(self):\n",
       "   146                                                   # We have k groups\n",
       "   147                                                   # We returns two vectors of length k with the number of sample in each\n",
       "   148                                                   # group, split by phenotype.\n",
       "   149         1         69.0     69.0     12.4          clusters = np.unique(self.Pop)\n",
       "   150         1          1.0      1.0      0.2          clusters.sort()\n",
       "   151         1          5.0      5.0      0.9          n1s = np.zeros(len(clusters))\n",
       "   152         1          2.0      2.0      0.4          n2s = np.zeros(len(clusters))\n",
       "   153                                                   \n",
       "   154         2          6.0      3.0      1.1          for clus in clusters:\n",
       "   155         1         39.0     39.0      7.0              n1s[clus] = sum(self.Pheno[self.Pop == clus])\n",
       "   156         1        435.0    435.0     78.0              n2s[clus] = sum(self.Pop == clus) - n1s[clus]\n",
       "   157                                                   \n",
       "   158         1          1.0      1.0      0.2          return n1s, n2s\n",
       "\n",
       "Total time: 0.000771 s\n",
       "File: /Users/hector/Documents/BGWAS2/dbgwas_docker/Tarone/scripts/Helper_Tarone.py\n",
       "Function: compute_envelopes at line 16\n",
       "\n",
       "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
       "==============================================================\n",
       "    16                                           def compute_envelopes(Ss):\n",
       "    17                                               \"\"\"Compute the envelope of a subgraph\n",
       "    18                                           \n",
       "    19                                               Args:\n",
       "    20                                                   Ss: an array of objects of class graph for which we want to compute the\n",
       "    21                                                    envelope\n",
       "    22                                           \n",
       "    23                                               Return:\n",
       "    24                                                   The envelopes of the subgraphs\n",
       "    25                                               \"\"\"\n",
       "    26         5        767.0    153.4     99.5      Env = np.array([S.Env for S in Ss], dtype = np.float64)\n",
       "    27         5          4.0      0.8      0.5      return Env\n",
       "\n",
       "Total time: 0.000526 s\n",
       "File: /Users/hector/Documents/BGWAS2/dbgwas_docker/Tarone/scripts/Helper_Tarone.py\n",
       "Function: are_prunable at line 51\n",
       "\n",
       "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
       "==============================================================\n",
       "    51                                           def are_prunable(Ss):\n",
       "    52                                               \"\"\"Look at whether the graphs are prunable or not\n",
       "    53                                           \n",
       "    54                                               Args:\n",
       "    55                                                   Ss: an array of objects of class graph for which we want to compute the\n",
       "    56                                                   envelope\n",
       "    57                                           \n",
       "    58                                               Return:\n",
       "    59                                                   A array boolean, whether the graph is prunable\n",
       "    60                                               \"\"\"\n",
       "    61         5        522.0    104.4     99.2      Prune = np.array([S.prunable for S in Ss], dtype = np.bool_)\n",
       "    62         5          4.0      0.8      0.8      return Prune\n",
       "\n",
       "Total time: 0.016865 s\n",
       "File: /Users/hector/Documents/BGWAS2/dbgwas_docker/Tarone/scripts/Helper_Tarone.py\n",
       "Function: find_ko at line 64\n",
       "\n",
       "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
       "==============================================================\n",
       "    64                                           def find_ko(min_ps, alpha, k = 1):\n",
       "    65                                               \"\"\"Compute the k0 according to the method in Terada et al\n",
       "    66                                               \n",
       "    67                                               Args:\n",
       "    68                                                   min_ps: The list of minimal p-values\n",
       "    69                                                   alpha: The threshold for controlling the FWER\n",
       "    70                                                   k: the previous value of k0 computed on a smaller set. Default to 1\n",
       "    71                                           \n",
       "    72                                               Return:\n",
       "    73                                                   The k0 value and associated cutoff for the Chi-square test\n",
       "    74                                               \"\"\"\n",
       "    75         6        871.0    145.2      5.2      sortedMinP = -np.sort(-min_ps)\n",
       "    76         6         20.0      3.3      0.1      N = min_ps.shape[0]\n",
       "    77         6          5.0      0.8      0.0      a = k - 1\n",
       "    78         6          4.0      0.7      0.0      b = N\n",
       "    79        43         36.0      0.8      0.2      while b - a > 1:\n",
       "    80        37         63.0      1.7      0.4          mid = int((a + b) / 2)\n",
       "    81        37      12989.0    351.1     77.0          TH = chi2.isf(alpha / (mid + 1), 1)\n",
       "    82        37         66.0      1.8      0.4          if sortedMinP[mid] >= TH:\n",
       "    83        32         20.0      0.6      0.1              a = mid \n",
       "    84                                                   else:\n",
       "    85         5          3.0      0.6      0.0              b = mid\n",
       "    86         6          3.0      0.5      0.0      k0 = a + 1\n",
       "    87         6       2778.0    463.0     16.5      TH = chi2.isf(alpha / k0, 1)\n",
       "    88         6          7.0      1.2      0.0      return k0, TH\n",
       "\n",
       "Total time: 0.000114 s\n",
       "File: /Users/hector/Documents/BGWAS2/dbgwas_docker/Tarone/scripts/ItemTable.py\n",
       "Function: __init__ at line 6\n",
       "\n",
       "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
       "==============================================================\n",
       "     6                                               def __init__(self, nNodes):\n",
       "     7         1        113.0    113.0     99.1          self.dict = {k: set() for k in range(nNodes)}\n",
       "     8         1          1.0      1.0      0.9          return\n",
       "\n",
       "Total time: 0.108238 s\n",
       "File: /Users/hector/Documents/BGWAS2/dbgwas_docker/Tarone/scripts/ItemTable.py\n",
       "Function: check_table at line 10\n",
       "\n",
       "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
       "==============================================================\n",
       "    10                                               def check_table(self, max_node, pattern):\n",
       "    11      8645       4834.0      0.6      4.5          explored = False\n",
       "    12      8645      69893.0      8.1     64.6          max_pattern = tuple(pattern)\n",
       "    13      8645      29000.0      3.4     26.8          if max_pattern in self.dict[max_node]:\n",
       "    14      1609        723.0      0.4      0.7              explored = True\n",
       "    15      8645       3788.0      0.4      3.5          return explored\n",
       "\n",
       "Total time: 0.050978 s\n",
       "File: /Users/hector/Documents/BGWAS2/dbgwas_docker/Tarone/scripts/ItemTable.py\n",
       "Function: add_table at line 17\n",
       "\n",
       "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
       "==============================================================\n",
       "    17                                               def add_table(self, max_node, pattern):\n",
       "    18      4415      31637.0      7.2     62.1          max_pattern = tuple(pattern)\n",
       "    19      4415      17347.0      3.9     34.0          self.dict[max_node].add(max_pattern)\n",
       "    20      4415       1994.0      0.5      3.9          return\n",
       "\n",
       "Total time: 15.5059 s\n",
       "File: /Users/hector/Documents/BGWAS2/dbgwas_docker/Tarone/scripts/ItemTable.py\n",
       "Function: Parents at line 22\n",
       "\n",
       "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
       "==============================================================\n",
       "    22                                               def Parents(self, S, G, TH, n1s, n2s):\n",
       "    23      1401   15446907.0  11025.6     99.6          Par = S.parents(G, TH, n1s, n2s, self)\n",
       "    24      4220       4358.0      1.0      0.0          for P in Par:\n",
       "    25      2819      53959.0     19.1      0.3              self.add_table(max(P.nodes), P.ys)\n",
       "    26      1401        695.0      0.5      0.0          return Par\n",
       "\n",
       "Total time: 0.001352 s\n",
       "File: /Users/hector/Documents/BGWAS2/dbgwas_docker/Tarone/scripts/Subgraphs.py\n",
       "Function: __init__ at line 35\n",
       "\n",
       "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
       "==============================================================\n",
       "    35                                               def __init__(self, G):\n",
       "    36                                                   \"\"\"Creating the closure of the subgraph {node}\n",
       "    37                                                   \n",
       "    38                                                   Args:\n",
       "    39                                                       G: the graph structure we want to explore\n",
       "    40                                                   \n",
       "    41                                                   Return:\n",
       "    42                                                       An empty subgraph.\n",
       "    43                                                   \"\"\"\n",
       "    44                                                   # Create the subgraph with one node\n",
       "    45                                                   ## List of presence / absence in the subgraph for each sample\n",
       "    46       100        447.0      4.5     33.1          self.ys = G.pattern[0] == 2\n",
       "    47       100         98.0      1.0      7.2          self.neighbours = G.pattern\n",
       "    48                                                   ## List of neighoring nodes that can be added\n",
       "    49                                                   ## Length in bp of all the nodes\n",
       "    50       100         64.0      0.6      4.7          self.length = 0\n",
       "    51       100        347.0      3.5     25.7          self.nodes = np.array([])\n",
       "    52       100         83.0      0.8      6.1          self.Env = 0\n",
       "    53       100         63.0      0.6      4.7          self.prunable = False\n",
       "    54       100         67.0      0.7      5.0          self.to_prune = False\n",
       "    55       100         67.0      0.7      5.0          self.closed = False\n",
       "    56       100         63.0      0.6      4.7          self.max = 0\n",
       "    57       100         53.0      0.5      3.9          return\n",
       "\n",
       "Total time: 0.030786 s\n",
       "File: /Users/hector/Documents/BGWAS2/dbgwas_docker/Tarone/scripts/Subgraphs.py\n",
       "Function: new_graph at line 59\n",
       "\n",
       "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
       "==============================================================\n",
       "    59                                               def new_graph(self, node, G, TH, n1s, n2s, close = True):\n",
       "    60                                                   \"\"\"Creating the closure of the subgraph {node}\n",
       "    61                                                   \n",
       "    62                                                   Args:\n",
       "    63                                                       node: The node from which to start\n",
       "    64                                                       G: the graph structure we want to explore\n",
       "    65                                                       TH: the initial value of the threshold\n",
       "    66                                                       n1s: An vector of group sizes among the first phenotype.\n",
       "    67                                                       n2s: An vector of group sizes among the second phenotype.\n",
       "    68                                                       close: whether to get the closure or not\n",
       "    69                                                   Return:\n",
       "    70                                                       the subgraph\n",
       "    71                                                   \"\"\"\n",
       "    72                                                   # Create the subgraph with one node\n",
       "    73                                                   ## List of presence / absence in the subgraph for each sample\n",
       "    74       100         91.0      0.9      0.3          self.max = node\n",
       "    75       100        180.0      1.8      0.6          self.ys = G.pattern[node]\n",
       "    76       100      11520.0    115.2     37.4          freqS = self.frequencies(G.Pop)\n",
       "    77       100        384.0      3.8      1.2          thresh = freqS >= np.maximum(n1s, n2s)\n",
       "    78       100        173.0      1.7      0.6          self.prunable = all(thresh)\n",
       "    79       100      12183.0    121.8     39.6          self.Env = envelope(freqS, n1s, n2s)\n",
       "    80                                                   # If we can prune directly, we prune\n",
       "    81       100         98.0      1.0      0.3          if self.Env < TH and self.prunable:\n",
       "    82                                                       self.to_prune = True\n",
       "    83                                                       return\n",
       "    84                                                   ## List of neighoring nodes that can be added\n",
       "    85       100        207.0      2.1      0.7          self.neighbours = G.neighbours[node]\n",
       "    86                                                   ## Length in bp of all the nodes\n",
       "    87       100        134.0      1.3      0.4          self.length = G.lengths[node]\n",
       "    88       100        184.0      1.8      0.6          self.nodes = {node}\n",
       "    89                                                   # Check if closed\n",
       "    90       100       3251.0     32.5     10.6          closure = (G.pattern[self.neighbours,] | self.ys) != self.ys\n",
       "    91       100       1678.0     16.8      5.5          closure = closure.sum(axis = 1) == 0\n",
       "    92       100        451.0      4.5      1.5          closure = list(closure)\n",
       "    93       100        166.0      1.7      0.5          self.closed = not any(closure)\n",
       "    94       100         86.0      0.9      0.3          return\n",
       "\n",
       "Total time: 0.181218 s\n",
       "File: /Users/hector/Documents/BGWAS2/dbgwas_docker/Tarone/scripts/Subgraphs.py\n",
       "Function: close at line 96\n",
       "\n",
       "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
       "==============================================================\n",
       "    96                                               def close(self, G, Tb, L_Stop = 10 ** 5):\n",
       "    97                                                   \"\"\"Creating the closure of a subgraph\n",
       "    98                                                   \n",
       "    99                                                   Args:\n",
       "   100                                                       self: the current subgraph\n",
       "   101                                                       G: the graph structure we want to explore\n",
       "   102                                                   \n",
       "   103                                                   Return:\n",
       "   104                                                       the closure of the subgraph\n",
       "   105                                                   \"\"\"\n",
       "   106      2819      86349.0     30.6     47.6          closure = (G.pattern[self.neighbours,] | self.ys) != self.ys\n",
       "   107      2819      46262.0     16.4     25.5          closure = closure.sum(axis = 1) == 0\n",
       "   108      2819      14386.0      5.1      7.9          closure = list(closure)\n",
       "   109      2819      17307.0      6.1      9.6          closed_neighbours = [ne for (ne, v) in zip(self.neighbours, closure) if v]\n",
       "   110      2956       3743.0      1.3      2.1          while len(closed_neighbours) > 0:\n",
       "   111       148        196.0      1.3      0.1              ne = closed_neighbours.pop()\n",
       "   112       148       9416.0     63.6      5.2              new_closed_neighbours = self.add_closure_node(ne, G)\n",
       "   113       148        153.0      1.0      0.1              if ne == self.max:\n",
       "   114        45       1086.0     24.1      0.6                  if Tb.check_table(ne, self.ys):\n",
       "   115        11         10.0      0.9      0.0                      self.to_prune = True\n",
       "   116        11          9.0      0.8      0.0                      break\n",
       "   117       137        135.0      1.0      0.1              closed_neighbours.extend(new_closed_neighbours)\n",
       "   118       137        190.0      1.4      0.1              if self.length > L_Stop:\n",
       "   119                                                           self.closed = (len(closed_neighbours) == 0)\n",
       "   120                                                           break\n",
       "   121      2819       1976.0      0.7      1.1          return\n",
       "\n",
       "Total time: 0.007323 s\n",
       "File: /Users/hector/Documents/BGWAS2/dbgwas_docker/Tarone/scripts/Subgraphs.py\n",
       "Function: add_closure_node at line 123\n",
       "\n",
       "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
       "==============================================================\n",
       "   123                                               def add_closure_node(self, node, G):\n",
       "   124                                                   \"\"\" Add a node to the growing subgraph that respect the closure\n",
       "   125                                                   \n",
       "   126                                                   Args:\n",
       "   127                                                       self: the current subgraph\n",
       "   128                                                       node: the node to add\n",
       "   129                                                       G: the graph structure we want to explore\n",
       "   130                                                   \n",
       "   131                                                   Return:\n",
       "   132                                                       S with the new node.\n",
       "   133                                                   \"\"\"\n",
       "   134       148        189.0      1.3      2.6          if node not in self.neighbours:\n",
       "   135                                                       raise NameError('This node should not be added since it is not a neighbour')\n",
       "   136       148        143.0      1.0      2.0          if node > self.max:\n",
       "   137        25         24.0      1.0      0.3              self.max = node\n",
       "   138       148        199.0      1.3      2.7          self.neighbours.remove(node)\n",
       "   139       148        747.0      5.0     10.2          self.nodes.add(node)\n",
       "   140       148        321.0      2.2      4.4          self.length = self.length + G.lengths[node]\n",
       "   141                                                   # We add only the new neighbours\n",
       "   142       148       1047.0      7.1     14.3          new_neighbours = [ne for ne in G.neighbours[node] if\n",
       "   143                                                                       ne not in self.nodes and ne not in self.neighbours]\n",
       "   144       148        163.0      1.1      2.2          self.neighbours.extend(new_neighbours)\n",
       "   145       148       2321.0     15.7     31.7          new_closure = (G.pattern[new_neighbours,] | self.ys) != self.ys\n",
       "   146       148       1640.0     11.1     22.4          new_closure = new_closure.sum(axis = 1) == 0\n",
       "   147       148        422.0      2.9      5.8          new_closed_neighbours = [ne for (ne, v) in zip(new_neighbours, new_closure) if v]\n",
       "   148       148        107.0      0.7      1.5          return new_closed_neighbours\n",
       "\n",
       "Total time: 15.1481 s\n",
       "File: /Users/hector/Documents/BGWAS2/dbgwas_docker/Tarone/scripts/Subgraphs.py\n",
       "Function: parents at line 150\n",
       "\n",
       "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
       "==============================================================\n",
       "   150                                               def parents(self, G, TH, n1s, n2s, Tb, L_Stop = 10 ** 5):\n",
       "   151                                                   \"\"\" Return the closure of all self + v for all neighbours v of self\n",
       "   152                                                   \n",
       "   153                                                   Args:\n",
       "   154                                                       self: the current subgraph\n",
       "   155                                                       G: the graph we want to explore\n",
       "   156                                                       TH: the initial value of the threshold\n",
       "   157                                                       n1s: An vector of group sizes among the first phenotype.\n",
       "   158                                                       n2s: An vector of group sizes among the second phenotype.\n",
       "   159                                                   \n",
       "   160                                                   Return:\n",
       "   161                                                       an array of graph, all parents of the subgraph\n",
       "   162                                                   \"\"\"\n",
       "   163                                                   # Get the number of neighbours\n",
       "   164      1401       2170.0      1.5      0.0          if len(self.neighbours) == 0:\n",
       "   165         1         11.0     11.0      0.0              parents = np.empty(0, dtype = graph)\n",
       "   166         1          1.0      1.0      0.0              return parents\n",
       "   167      1400      34904.0     24.9      0.2          closure = G.pattern[self.neighbours] | self.ys\n",
       "   168      1400     712051.0    508.6      4.7          closure, indexes = np.unique(closure, axis = 0, return_index = True)\n",
       "   169      1400      15711.0     11.2      0.1          parents = np.empty(len(indexes), dtype = graph)\n",
       "   170     22692      36996.0      1.6      0.2          for i, index in enumerate(indexes):\n",
       "   171     21292    7039924.0    330.6     46.5              S = copy.deepcopy(self)\n",
       "   172     21292      32357.0      1.5      0.2              ne = self.neighbours[index]\n",
       "   173     21292     659125.0     31.0      4.4              S.add_parent_node(ne, G)\n",
       "   174     21292      23413.0      1.1      0.2              if ne == S.max:\n",
       "   175      5781     137231.0     23.7      0.9                  if Tb.check_table(ne, S.ys):\n",
       "   176       275        261.0      0.9      0.0                      continue\n",
       "   177     21017    1246594.0     59.3      8.2              freqS = S.frequencies(G.Pop)\n",
       "   178     21017      81387.0      3.9      0.5              thresh = freqS >= np.maximum(n1s, n2s)\n",
       "   179     21017      55576.0      2.6      0.4              S.prunable = all(thresh)\n",
       "   180     21017    4781146.0    227.5     31.6              S.Env = envelope(freqS, n1s, n2s)\n",
       "   181                                                       # If we can prune directly, we prune\n",
       "   182     21017      29090.0      1.4      0.2              if S.Env < TH and S.prunable:\n",
       "   183     18198      16004.0      0.9      0.1                  continue\n",
       "   184      2819     207312.0     73.5      1.4              S.close(G, Tb, L_Stop)\n",
       "   185      2819       4311.0      1.5      0.0              parents[i] = S\n",
       "   186      1400      14331.0     10.2      0.1          parents = parents[parents != None]\n",
       "   187      1400      16947.0     12.1      0.1          parents = np.array([S for S in parents if S.closed])\n",
       "   188      1400       1294.0      0.9      0.0          return parents\n",
       "\n",
       "Total time: 0.472549 s\n",
       "File: /Users/hector/Documents/BGWAS2/dbgwas_docker/Tarone/scripts/Subgraphs.py\n",
       "Function: add_parent_node at line 190\n",
       "\n",
       "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
       "==============================================================\n",
       "   190                                               def add_parent_node(self, node, G):\n",
       "   191                                                    \"\"\" Add a node to the growing subgraph\n",
       "   192                                                    \n",
       "   193                                                    Args:\n",
       "   194                                                        self: the current subgraph\n",
       "   195                                                        node: the node to add\n",
       "   196                                                        G: the graph structure we want to explore\n",
       "   197                                                    \n",
       "   198                                                    Return:\n",
       "   199                                                        S with the new node.\n",
       "   200                                                    \"\"\"\n",
       "   201     21292      31342.0      1.5      6.6           if node not in self.neighbours:\n",
       "   202                                                        raise NameError('This node should not be added since it is not a neighbour')\n",
       "   203     21292      18226.0      0.9      3.9           if node > self.max:\n",
       "   204      5781       4705.0      0.8      1.0              self.max = node\n",
       "   205     21292      32435.0      1.5      6.9           self.neighbours.remove(node)\n",
       "   206     21292     113157.0      5.3     23.9           self.ys = self.ys | G.pattern[node]\n",
       "   207     21292      24548.0      1.2      5.2           self.nodes.add(node)\n",
       "   208     21292      35522.0      1.7      7.5           self.length = self.length + G.lengths[node]\n",
       "   209                                                    # We add only the new neighbours\n",
       "   210     21292     189674.0      8.9     40.1           new_neighbours = [ne for ne in G.neighbours[node] if ne not in self.nodes and ne not in self.neighbours]\n",
       "   211     21292      22940.0      1.1      4.9           self.neighbours.extend(new_neighbours)\n",
       "\n",
       "Total time: 1.13326 s\n",
       "File: /Users/hector/Documents/BGWAS2/dbgwas_docker/Tarone/scripts/Subgraphs.py\n",
       "Function: frequencies at line 219\n",
       "\n",
       "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
       "==============================================================\n",
       "   219                                               def frequencies(self, Pop):\n",
       "   220                                                   \"\"\" Return the margins for the first column of the tables\"\"\"\n",
       "   221     21117     671260.0     31.8     59.2          clusters = np.unique(Pop)\n",
       "   222     21117      21178.0      1.0      1.9          clusters.sort()\n",
       "   223     21117      61102.0      2.9      5.4          xs = np.zeros(len(clusters))\n",
       "   224     42234      75152.0      1.8      6.6          for clus in clusters:\n",
       "   225     21117     294969.0     14.0     26.0              xs[clus] = self.ys[Pop == clus].sum()\n",
       "   226     21117       9604.0      0.5      0.8          return xs\n",
       "\n",
       "Total time: 0.000408 s\n",
       "File: /usr/local/lib/python3.7/site-packages/joblib/parallel.py\n",
       "Function: delayed at line 295\n",
       "\n",
       "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
       "==============================================================\n",
       "   295                                           def delayed(function, check_pickle=None):\n",
       "   296                                               \"\"\"Decorator used to capture the arguments of a function.\"\"\"\n",
       "   297        21         17.0      0.8      4.2      if check_pickle is not None:\n",
       "   298                                                   warnings.warn('check_pickle is deprecated in joblib 0.12 and will be'\n",
       "   299                                                                 ' removed in 0.13', DeprecationWarning)\n",
       "   300                                               # Try to pickle the input function, to catch the problems early when\n",
       "   301                                               # using with multiprocessing:\n",
       "   302        21         16.0      0.8      3.9      if check_pickle:\n",
       "   303                                                   dumps(function)\n",
       "   304                                           \n",
       "   305        21         21.0      1.0      5.1      def delayed_function(*args, **kwargs):\n",
       "   306                                                   return function, args, kwargs\n",
       "   307        21          9.0      0.4      2.2      try:\n",
       "   308        21        329.0     15.7     80.6          delayed_function = functools.wraps(function)(delayed_function)\n",
       "   309                                               except AttributeError:\n",
       "   310                                                   \" functools.wraps fails on some callable objects \"\n",
       "   311        21         16.0      0.8      3.9      return delayed_function\n",
       "\n",
       "Total time: 0.002477 s\n",
       "File: /usr/local/lib/python3.7/site-packages/joblib/parallel.py\n",
       "Function: __init__ at line 615\n",
       "\n",
       "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
       "==============================================================\n",
       "   615                                               def __init__(self, n_jobs=None, backend=None, verbose=0, timeout=None,\n",
       "   616                                                            pre_dispatch='2 * n_jobs', batch_size='auto',\n",
       "   617                                                            temp_folder=None, max_nbytes='1M', mmap_mode='r',\n",
       "   618                                                            prefer=None, require=None):\n",
       "   619        21         22.0      1.0      0.9          active_backend, context_n_jobs = get_active_backend(\n",
       "   620        21        405.0     19.3     16.4              prefer=prefer, require=require, verbose=verbose)\n",
       "   621        21         26.0      1.2      1.0          nesting_level = active_backend.nesting_level\n",
       "   622        21         24.0      1.1      1.0          if backend is None and n_jobs is None:\n",
       "   623                                                       # If we are under a parallel_backend context manager, look up\n",
       "   624                                                       # the default number of jobs and use that instead:\n",
       "   625                                                       n_jobs = context_n_jobs\n",
       "   626        21         21.0      1.0      0.8          if n_jobs is None:\n",
       "   627                                                       # No specific context override and no specific value request:\n",
       "   628                                                       # default to 1.\n",
       "   629                                                       n_jobs = 1\n",
       "   630        21         31.0      1.5      1.3          self.n_jobs = n_jobs\n",
       "   631        21         25.0      1.2      1.0          self.verbose = verbose\n",
       "   632        21         22.0      1.0      0.9          self.timeout = timeout\n",
       "   633        21         22.0      1.0      0.9          self.pre_dispatch = pre_dispatch\n",
       "   634        21        656.0     31.2     26.5          self._ready_batches = queue.Queue()\n",
       "   635                                           \n",
       "   636        21         29.0      1.4      1.2          if isinstance(max_nbytes, _basestring):\n",
       "   637        21        208.0      9.9      8.4              max_nbytes = memstr_to_bytes(max_nbytes)\n",
       "   638                                           \n",
       "   639        21         26.0      1.2      1.0          self._backend_args = dict(\n",
       "   640        21         23.0      1.1      0.9              max_nbytes=max_nbytes,\n",
       "   641        21         21.0      1.0      0.8              mmap_mode=mmap_mode,\n",
       "   642        21         21.0      1.0      0.8              temp_folder=temp_folder,\n",
       "   643        21         21.0      1.0      0.8              prefer=prefer,\n",
       "   644        21         22.0      1.0      0.9              require=require,\n",
       "   645        21         72.0      3.4      2.9              verbose=max(0, self.verbose - 50),\n",
       "   646                                                   )\n",
       "   647        21         25.0      1.2      1.0          if DEFAULT_MP_CONTEXT is not None:\n",
       "   648                                                       self._backend_args['context'] = DEFAULT_MP_CONTEXT\n",
       "   649        21         37.0      1.8      1.5          elif hasattr(mp, \"get_context\"):\n",
       "   650        21         75.0      3.6      3.0              self._backend_args['context'] = mp.get_context()\n",
       "   651                                           \n",
       "   652        21         23.0      1.1      0.9          if backend is None:\n",
       "   653                                                       backend = active_backend\n",
       "   654                                           \n",
       "   655        21        126.0      6.0      5.1          elif isinstance(backend, ParallelBackendBase):\n",
       "   656                                                       # Use provided backend as is, with the current nesting_level if it\n",
       "   657                                                       # is not set yet.\n",
       "   658                                                       if backend.nesting_level is None:\n",
       "   659                                                           backend.nesting_level = nesting_level\n",
       "   660                                           \n",
       "   661        21         31.0      1.5      1.3          elif hasattr(backend, 'Pool') and hasattr(backend, 'Lock'):\n",
       "   662                                                       # Make it possible to pass a custom multiprocessing context as\n",
       "   663                                                       # backend to change the start method to forkserver or spawn or\n",
       "   664                                                       # preload modules on the forkserver helper process.\n",
       "   665                                                       self._backend_args['context'] = backend\n",
       "   666                                                       backend = MultiprocessingBackend(nesting_level=nesting_level)\n",
       "   667                                                   else:\n",
       "   668        21         24.0      1.1      1.0              try:\n",
       "   669        21         26.0      1.2      1.0                  backend_factory = BACKENDS[backend]\n",
       "   670                                                       except KeyError:\n",
       "   671                                                           raise ValueError(\"Invalid backend: %s, expected one of %r\"\n",
       "   672                                                                            % (backend, sorted(BACKENDS.keys())))\n",
       "   673        21        119.0      5.7      4.8              backend = backend_factory(nesting_level=nesting_level)\n",
       "   674                                           \n",
       "   675        21         29.0      1.4      1.2          if (require == 'sharedmem' and\n",
       "   676                                                           not getattr(backend, 'supports_sharedmem', False)):\n",
       "   677                                                       raise ValueError(\"Backend %s does not support shared memory\"\n",
       "   678                                                                        % backend)\n",
       "   679                                           \n",
       "   680        21         23.0      1.1      0.9          if (batch_size == 'auto' or isinstance(batch_size, Integral) and\n",
       "   681                                                           batch_size > 0):\n",
       "   682        21         25.0      1.2      1.0              self.batch_size = batch_size\n",
       "   683                                                   else:\n",
       "   684                                                       raise ValueError(\n",
       "   685                                                           \"batch_size must be 'auto' or a positive integer, got: %r\"\n",
       "   686                                                           % batch_size)\n",
       "   687                                           \n",
       "   688        21         26.0      1.2      1.0          self._backend = backend\n",
       "   689        21         22.0      1.0      0.9          self._output = None\n",
       "   690        21         65.0      3.1      2.6          self._jobs = list()\n",
       "   691        21         29.0      1.4      1.2          self._managed_backend = False\n",
       "   692                                           \n",
       "   693                                                   # This lock is used coordinate the main thread of this process with\n",
       "   694                                                   # the async callback thread of our the pool.\n",
       "   695        21         75.0      3.6      3.0          self._lock = threading.RLock()\n",
       "\n",
       "Total time: 0.000729 s\n",
       "File: /usr/local/lib/python3.7/site-packages/joblib/parallel.py\n",
       "Function: _initialize_backend at line 706\n",
       "\n",
       "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
       "==============================================================\n",
       "   706                                               def _initialize_backend(self):\n",
       "   707                                                   \"\"\"Build a process or thread pool and return the number of workers\"\"\"\n",
       "   708        42         24.0      0.6      3.3          try:\n",
       "   709        42         50.0      1.2      6.9              n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,\n",
       "   710        42        554.0     13.2     76.0                                               **self._backend_args)\n",
       "   711        21         19.0      0.9      2.6              if self.timeout is not None and not self._backend.supports_timeout:\n",
       "   712                                                           warnings.warn(\n",
       "   713                                                               'The backend class {!r} does not support timeout. '\n",
       "   714                                                               \"You have set 'timeout={}' in Parallel but \"\n",
       "   715                                                               \"the 'timeout' parameter will not be used.\".format(\n",
       "   716                                                                   self._backend.__class__.__name__,\n",
       "   717                                                                   self.timeout))\n",
       "   718                                           \n",
       "   719        21         24.0      1.1      3.3          except FallbackToBackend as e:\n",
       "   720                                                       # Recursively initialize the backend in case of requested fallback.\n",
       "   721        21         16.0      0.8      2.2              self._backend = e.backend\n",
       "   722        21         15.0      0.7      2.1              n_jobs = self._initialize_backend()\n",
       "   723                                           \n",
       "   724        42         27.0      0.6      3.7          return n_jobs\n",
       "\n",
       "Total time: 3.8e-05 s\n",
       "File: /usr/local/lib/python3.7/site-packages/joblib/parallel.py\n",
       "Function: _terminate_backend at line 731\n",
       "\n",
       "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
       "==============================================================\n",
       "   731                                               def _terminate_backend(self):\n",
       "   732        21         15.0      0.7     39.5          if self._backend is not None:\n",
       "   733        21         23.0      1.1     60.5              self._backend.terminate()\n",
       "\n",
       "Total time: 19.8131 s\n",
       "File: /usr/local/lib/python3.7/site-packages/joblib/parallel.py\n",
       "Function: _dispatch at line 735\n",
       "\n",
       "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
       "==============================================================\n",
       "   735                                               def _dispatch(self, batch):\n",
       "   736                                                   \"\"\"Queue the batch for computing, with or without multiprocessing\n",
       "   737                                           \n",
       "   738                                                   WARNING: this method is not thread-safe: it should be only called\n",
       "   739                                                   indirectly via dispatch_one_batch.\n",
       "   740                                           \n",
       "   741                                                   \"\"\"\n",
       "   742                                                   # If job.get() catches an exception, it closes the queue:\n",
       "   743        21         17.0      0.8      0.0          if self._aborting:\n",
       "   744                                                       return\n",
       "   745                                           \n",
       "   746        21         34.0      1.6      0.0          self.n_dispatched_tasks += len(batch)\n",
       "   747        21         16.0      0.8      0.0          self.n_dispatched_batches += 1\n",
       "   748                                           \n",
       "   749        21         21.0      1.0      0.0          dispatch_timestamp = time.time()\n",
       "   750        21         66.0      3.1      0.0          cb = BatchCompletionCallBack(dispatch_timestamp, len(batch), self)\n",
       "   751        21         21.0      1.0      0.0          with self._lock:\n",
       "   752        21         16.0      0.8      0.0              job_idx = len(self._jobs)\n",
       "   753        21   19812873.0 943470.1    100.0              job = self._backend.apply_async(batch, callback=cb)\n",
       "   754                                                       # A job can complete so quickly than its callback is\n",
       "   755                                                       # called before we get here, causing self._jobs to\n",
       "   756                                                       # grow. To ensure correct results ordering, .insert is\n",
       "   757                                                       # used (rather than .append) in the following line\n",
       "   758        21         41.0      2.0      0.0              self._jobs.insert(job_idx, job)\n",
       "\n",
       "Total time: 19.8165 s\n",
       "File: /usr/local/lib/python3.7/site-packages/joblib/parallel.py\n",
       "Function: dispatch_one_batch at line 772\n",
       "\n",
       "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
       "==============================================================\n",
       "   772                                               def dispatch_one_batch(self, iterator):\n",
       "   773                                                   \"\"\"Prefetch the tasks for the next batch and dispatch them.\n",
       "   774                                           \n",
       "   775                                                   The effective size of the batch is computed here.\n",
       "   776                                                   If there are no more jobs to dispatch, return False, else return True.\n",
       "   777                                           \n",
       "   778                                                   The iterator consumption and dispatching is protected by the same\n",
       "   779                                                   lock so calling this function should be thread safe.\n",
       "   780                                           \n",
       "   781                                                   \"\"\"\n",
       "   782        42         42.0      1.0      0.0          if self.batch_size == 'auto':\n",
       "   783        42         86.0      2.0      0.0              batch_size = self._backend.compute_batch_size()\n",
       "   784                                                   else:\n",
       "   785                                                       # Fixed batch size strategy\n",
       "   786                                                       batch_size = self.batch_size\n",
       "   787                                           \n",
       "   788        42         59.0      1.4      0.0          with self._lock:\n",
       "   789                                                       # to ensure an even distribution of the workolad between workers,\n",
       "   790                                                       # we look ahead in the original iterators more than batch_size\n",
       "   791                                                       # tasks - However, we keep consuming only one batch at each\n",
       "   792                                                       # dispatch_one_batch call. The extra tasks are stored in a local\n",
       "   793                                                       # queue, _ready_batches, that is looked-up prior to re-consuming\n",
       "   794                                                       # tasks from the origal iterator.\n",
       "   795        42         33.0      0.8      0.0              try:\n",
       "   796        42        403.0      9.6      0.0                  tasks = self._ready_batches.get(block=False)\n",
       "   797        42         49.0      1.2      0.0              except queue.Empty:\n",
       "   798                                                           # slice the iterator n_jobs * batchsize items at a time. If the\n",
       "   799                                                           # slice returns less than that, then the current batchsize puts\n",
       "   800                                                           # too much weight on a subset of workers, while other may end\n",
       "   801                                                           # up starving. So in this case, re-scale the batch size\n",
       "   802                                                           # accordingly to distribute evenly the last items between all\n",
       "   803                                                           # workers.\n",
       "   804        42         26.0      0.6      0.0                  n_jobs = self._cached_effective_n_jobs\n",
       "   805        42         37.0      0.9      0.0                  big_batch_size = batch_size * n_jobs\n",
       "   806                                           \n",
       "   807        42        984.0     23.4      0.0                  islice = list(itertools.islice(iterator, big_batch_size))\n",
       "   808        42         43.0      1.0      0.0                  if len(islice) == 0:\n",
       "   809        21         26.0      1.2      0.0                      return False\n",
       "   810        21         21.0      1.0      0.0                  elif (iterator is self._original_iterator\n",
       "   811                                                                 and len(islice) < big_batch_size):\n",
       "   812                                                               # We reached the end of the original iterator (unless\n",
       "   813                                                               # iterator is the ``pre_dispatch``-long initial slice of\n",
       "   814                                                               # the original iterator) -- decrease the batch size to\n",
       "   815                                                               # account for potential variance in the batches running\n",
       "   816                                                               # time.\n",
       "   817                                                               final_batch_size = max(1, len(islice) // (10 * n_jobs))\n",
       "   818                                                           else:\n",
       "   819        21         35.0      1.7      0.0                      final_batch_size = max(1, len(islice) // n_jobs)\n",
       "   820                                           \n",
       "   821                                                           # enqueue n_jobs batches in a local queue\n",
       "   822        42         67.0      1.6      0.0                  for i in range(0, len(islice), final_batch_size):\n",
       "   823        21         29.0      1.4      0.0                      tasks = BatchedCalls(islice[i:i + final_batch_size],\n",
       "   824        21        581.0     27.7      0.0                                           self._backend.get_nested_backend(),\n",
       "   825        21        107.0      5.1      0.0                                           self._pickle_cache)\n",
       "   826        21        309.0     14.7      0.0                      self._ready_batches.put(tasks)\n",
       "   827                                           \n",
       "   828                                                           # finally, get one task.\n",
       "   829        21        222.0     10.6      0.0                  tasks = self._ready_batches.get(block=False)\n",
       "   830        21         44.0      2.1      0.0              if len(tasks) == 0:\n",
       "   831                                                           # No more tasks available in the iterator: tell caller to stop.\n",
       "   832                                                           return False\n",
       "   833                                                       else:\n",
       "   834        21   19813306.0 943490.8    100.0                  self._dispatch(tasks)\n",
       "   835        21         25.0      1.2      0.0                  return True\n",
       "\n",
       "Total time: 0.002231 s\n",
       "File: /usr/local/lib/python3.7/site-packages/joblib/parallel.py\n",
       "Function: _print at line 837\n",
       "\n",
       "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
       "==============================================================\n",
       "   837                                               def _print(self, msg, msg_args):\n",
       "   838                                                   \"\"\"Display the message on stout or stderr depending on verbosity\"\"\"\n",
       "   839                                                   # XXX: Not using the logger framework: need to\n",
       "   840                                                   # learn to use logger better.\n",
       "   841        42         30.0      0.7      1.3          if not self.verbose:\n",
       "   842        30         11.0      0.4      0.5              return\n",
       "   843        12          4.0      0.3      0.2          if self.verbose < 50:\n",
       "   844        12         28.0      2.3      1.3              writer = sys.stderr.write\n",
       "   845                                                   else:\n",
       "   846                                                       writer = sys.stdout.write\n",
       "   847        12         31.0      2.6      1.4          msg = msg % msg_args\n",
       "   848        12       2127.0    177.2     95.3          writer('[%s]: %s\\n' % (self, msg))\n",
       "\n",
       "Total time: 9.1e-05 s\n",
       "File: /usr/local/lib/python3.7/site-packages/joblib/parallel.py\n",
       "Function: print_progress at line 850\n",
       "\n",
       "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
       "==============================================================\n",
       "   850                                               def print_progress(self):\n",
       "   851                                                   \"\"\"Display the process of the parallel execution only a fraction\n",
       "   852                                                      of time, controlled by self.verbose.\n",
       "   853                                                   \"\"\"\n",
       "   854        21         25.0      1.2     27.5          if not self.verbose:\n",
       "   855        15          8.0      0.5      8.8              return\n",
       "   856         6          9.0      1.5      9.9          elapsed_time = time.time() - self._start_time\n",
       "   857                                           \n",
       "   858                                                   # Original job iterator becomes None once it has been fully\n",
       "   859                                                   # consumed : at this point we know the total number of jobs and we are\n",
       "   860                                                   # able to display an estimation of the remaining time based on already\n",
       "   861                                                   # completed jobs. Otherwise, we simply display the number of completed\n",
       "   862                                                   # tasks.\n",
       "   863         6          5.0      0.8      5.5          if self._original_iterator is not None:\n",
       "   864                                                       if _verbosity_filter(self.n_dispatched_batches, self.verbose):\n",
       "   865                                                           return\n",
       "   866                                                       self._print('Done %3i tasks      | elapsed: %s',\n",
       "   867                                                                   (self.n_completed_tasks,\n",
       "   868                                                                    short_format_time(elapsed_time), ))\n",
       "   869                                                   else:\n",
       "   870         6          2.0      0.3      2.2              index = self.n_completed_tasks\n",
       "   871                                                       # We are finished dispatching\n",
       "   872         6          6.0      1.0      6.6              total_tasks = self.n_dispatched_tasks\n",
       "   873                                                       # We always display the first loop\n",
       "   874         6          3.0      0.5      3.3              if not index == 0:\n",
       "   875                                                           # Display depending on the number of remaining items\n",
       "   876                                                           # A message as soon as we finish dispatching, cursor is 0\n",
       "   877         6          9.0      1.5      9.9                  cursor = (total_tasks - index + 1 -\n",
       "   878         6          4.0      0.7      4.4                            self._pre_dispatch_amount)\n",
       "   879         6          6.0      1.0      6.6                  frequency = (total_tasks // self.verbose) + 1\n",
       "   880         6          4.0      0.7      4.4                  is_last_item = (index + 1 == total_tasks)\n",
       "   881         6          6.0      1.0      6.6                  if (is_last_item or cursor % frequency):\n",
       "   882         6          4.0      0.7      4.4                      return\n",
       "   883                                                       remaining_time = (elapsed_time / index) * \\\n",
       "   884                                                                        (self.n_dispatched_tasks - index * 1.0)\n",
       "   885                                                       # only display status if remaining time is greater or equal to 0\n",
       "   886                                                       self._print('Done %3i out of %3i | elapsed: %s remaining: %s',\n",
       "   887                                                                   (index,\n",
       "   888                                                                    total_tasks,\n",
       "   889                                                                    short_format_time(elapsed_time),\n",
       "   890                                                                    short_format_time(remaining_time),\n",
       "   891                                                                    ))\n",
       "\n",
       "Total time: 0.000276 s\n",
       "File: /usr/local/lib/python3.7/site-packages/joblib/parallel.py\n",
       "Function: retrieve at line 893\n",
       "\n",
       "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
       "==============================================================\n",
       "   893                                               def retrieve(self):\n",
       "   894        21         29.0      1.4     10.5          self._output = list()\n",
       "   895        42         51.0      1.2     18.5          while self._iterating or len(self._jobs) > 0:\n",
       "   896        21         21.0      1.0      7.6              if len(self._jobs) == 0:\n",
       "   897                                                           # Wait for an async callback to dispatch new jobs\n",
       "   898                                                           time.sleep(0.01)\n",
       "   899                                                           continue\n",
       "   900                                                       # We need to be careful: the job list can be filling up as\n",
       "   901                                                       # we empty it and Python list are not thread-safe by default hence\n",
       "   902                                                       # the use of the lock\n",
       "   903        21         41.0      2.0     14.9              with self._lock:\n",
       "   904        21         43.0      2.0     15.6                  job = self._jobs.pop(0)\n",
       "   905                                           \n",
       "   906        21         15.0      0.7      5.4              try:\n",
       "   907        21         27.0      1.3      9.8                  if getattr(self._backend, 'supports_timeout', False):\n",
       "   908                                                               self._output.extend(job.get(timeout=self.timeout))\n",
       "   909                                                           else:\n",
       "   910        21         49.0      2.3     17.8                      self._output.extend(job.get())\n",
       "   911                                           \n",
       "   912                                                       except BaseException as exception:\n",
       "   913                                                           # Note: we catch any BaseException instead of just Exception\n",
       "   914                                                           # instances to also include KeyboardInterrupt.\n",
       "   915                                           \n",
       "   916                                                           # Stop dispatching any new job in the async callback thread\n",
       "   917                                                           self._aborting = True\n",
       "   918                                           \n",
       "   919                                                           # If the backend allows it, cancel or kill remaining running\n",
       "   920                                                           # tasks without waiting for the results as we will raise\n",
       "   921                                                           # the exception we got back to the caller instead of returning\n",
       "   922                                                           # any result.\n",
       "   923                                                           backend = self._backend\n",
       "   924                                                           if (backend is not None and\n",
       "   925                                                                   hasattr(backend, 'abort_everything')):\n",
       "   926                                                               # If the backend is managed externally we need to make sure\n",
       "   927                                                               # to leave it in a working state to allow for future jobs\n",
       "   928                                                               # scheduling.\n",
       "   929                                                               ensure_ready = self._managed_backend\n",
       "   930                                                               backend.abort_everything(ensure_ready=ensure_ready)\n",
       "   931                                           \n",
       "   932                                                           if isinstance(exception, TransportableException):\n",
       "   933                                                               # Capture exception to add information on the local\n",
       "   934                                                               # stack in addition to the distant stack\n",
       "   935                                                               this_report = format_outer_frames(context=10,\n",
       "   936                                                                                                 stack_start=1)\n",
       "   937                                                               raise exception.unwrap(this_report)\n",
       "   938                                                           else:\n",
       "   939                                                               raise\n",
       "\n",
       "Total time: 19.823 s\n",
       "File: /usr/local/lib/python3.7/site-packages/joblib/parallel.py\n",
       "Function: __call__ at line 941\n",
       "\n",
       "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
       "==============================================================\n",
       "   941                                               def __call__(self, iterable):\n",
       "   942        21         27.0      1.3      0.0          if self._jobs:\n",
       "   943                                                       raise ValueError('This Parallel instance is already running')\n",
       "   944                                                   # A flag used to abort the dispatching of jobs in case an\n",
       "   945                                                   # exception is found\n",
       "   946        21         23.0      1.1      0.0          self._aborting = False\n",
       "   947                                           \n",
       "   948        21         21.0      1.0      0.0          if not self._managed_backend:\n",
       "   949        21        982.0     46.8      0.0              n_jobs = self._initialize_backend()\n",
       "   950                                                   else:\n",
       "   951                                                       n_jobs = self._effective_n_jobs()\n",
       "   952                                           \n",
       "   953                                                   # self._effective_n_jobs should be called in the Parallel.__call__\n",
       "   954                                                   # thread only -- store its value in an attribute for further queries.\n",
       "   955        21         21.0      1.0      0.0          self._cached_effective_n_jobs = n_jobs\n",
       "   956                                           \n",
       "   957        21         36.0      1.7      0.0          backend_name = self._backend.__class__.__name__\n",
       "   958        21         25.0      1.2      0.0          if n_jobs == 0:\n",
       "   959                                                       raise RuntimeError(\"%s has no active worker.\" % backend_name)\n",
       "   960                                           \n",
       "   961        21         23.0      1.1      0.0          self._print(\"Using backend %s with %d concurrent workers.\",\n",
       "   962        21       1136.0     54.1      0.0                      (backend_name, n_jobs))\n",
       "   963        21         44.0      2.1      0.0          if hasattr(self._backend, 'start_call'):\n",
       "   964        21         38.0      1.8      0.0              self._backend.start_call()\n",
       "   965        21         29.0      1.4      0.0          iterator = iter(iterable)\n",
       "   966        21         19.0      0.9      0.0          pre_dispatch = self.pre_dispatch\n",
       "   967                                           \n",
       "   968        21         24.0      1.1      0.0          if pre_dispatch == 'all' or n_jobs == 1:\n",
       "   969                                                       # prevent further dispatch via multiprocessing callback thread\n",
       "   970        21         23.0      1.1      0.0              self._original_iterator = None\n",
       "   971        21         20.0      1.0      0.0              self._pre_dispatch_amount = 0\n",
       "   972                                                   else:\n",
       "   973                                                       self._original_iterator = iterator\n",
       "   974                                                       if hasattr(pre_dispatch, 'endswith'):\n",
       "   975                                                           pre_dispatch = eval(pre_dispatch)\n",
       "   976                                                       self._pre_dispatch_amount = pre_dispatch = int(pre_dispatch)\n",
       "   977                                           \n",
       "   978                                                       # The main thread will consume the first pre_dispatch items and\n",
       "   979                                                       # the remaining items will later be lazily dispatched by async\n",
       "   980                                                       # callbacks upon task completions.\n",
       "   981                                           \n",
       "   982                                                       # TODO: this iterator should be batch_size * n_jobs\n",
       "   983                                                       iterator = itertools.islice(iterator, self._pre_dispatch_amount)\n",
       "   984                                           \n",
       "   985        21         43.0      2.0      0.0          self._start_time = time.time()\n",
       "   986        21         22.0      1.0      0.0          self.n_dispatched_batches = 0\n",
       "   987        21         21.0      1.0      0.0          self.n_dispatched_tasks = 0\n",
       "   988        21         19.0      0.9      0.0          self.n_completed_tasks = 0\n",
       "   989                                                   # Use a caching dict for callables that are pickled with cloudpickle to\n",
       "   990                                                   # improve performances. This cache is used only in the case of\n",
       "   991                                                   # functions that are defined in the __main__ module, functions that are\n",
       "   992                                                   # defined locally (inside another function) and lambda expressions.\n",
       "   993        21         30.0      1.4      0.0          self._pickle_cache = dict()\n",
       "   994        21         18.0      0.9      0.0          try:\n",
       "   995                                                       # Only set self._iterating to True if at least a batch\n",
       "   996                                                       # was dispatched. In particular this covers the edge\n",
       "   997                                                       # case of Parallel used with an exhausted iterator. If\n",
       "   998                                                       # self._original_iterator is None, then this means either\n",
       "   999                                                       # that pre_dispatch == \"all\", n_jobs == 1 or that the first batch\n",
       "  1000                                                       # was very quick and its callback already dispatched all the\n",
       "  1001                                                       # remaining jobs.\n",
       "  1002        21         27.0      1.3      0.0              self._iterating = False\n",
       "  1003        21   19816523.0 943644.0    100.0              if self.dispatch_one_batch(iterator):\n",
       "  1004        21         31.0      1.5      0.0                  self._iterating = self._original_iterator is not None\n",
       "  1005                                           \n",
       "  1006        21        818.0     39.0      0.0              while self.dispatch_one_batch(iterator):\n",
       "  1007                                                           pass\n",
       "  1008                                           \n",
       "  1009        21         25.0      1.2      0.0              if pre_dispatch == \"all\" or n_jobs == 1:\n",
       "  1010                                                           # The iterable was consumed all at once by the above for loop.\n",
       "  1011                                                           # No need to wait for async callbacks to trigger to\n",
       "  1012                                                           # consumption.\n",
       "  1013        21         25.0      1.2      0.0                  self._iterating = False\n",
       "  1014                                           \n",
       "  1015        21        260.0     12.4      0.0              with self._backend.retrieval_context():\n",
       "  1016        21        667.0     31.8      0.0                  self.retrieve()\n",
       "  1017                                                       # Make sure that we get a last message telling us we are done\n",
       "  1018        21         59.0      2.8      0.0              elapsed_time = time.time() - self._start_time\n",
       "  1019        21         25.0      1.2      0.0              self._print('Done %3i out of %3i | elapsed: %s finished',\n",
       "  1020        21         28.0      1.3      0.0                          (len(self._output), len(self._output),\n",
       "  1021        21       1542.0     73.4      0.0                           short_format_time(elapsed_time)))\n",
       "  1022                                                   finally:\n",
       "  1023        21         51.0      2.4      0.0              if hasattr(self._backend, 'stop_call'):\n",
       "  1024        21         47.0      2.2      0.0                  self._backend.stop_call()\n",
       "  1025        21         23.0      1.1      0.0              if not self._managed_backend:\n",
       "  1026        21         99.0      4.7      0.0                  self._terminate_backend()\n",
       "  1027        21         43.0      2.0      0.0              self._jobs = list()\n",
       "  1028        21         30.0      1.4      0.0              self._pickle_cache = None\n",
       "  1029        21         23.0      1.1      0.0          output = self._output\n",
       "  1030        21         23.0      1.1      0.0          self._output = None\n",
       "  1031        21         18.0      0.9      0.0          return output\n",
       "\n",
       "Total time: 2.6e-05 s\n",
       "File: /usr/local/lib/python3.7/site-packages/joblib/parallel.py\n",
       "Function: __repr__ at line 1033\n",
       "\n",
       "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
       "==============================================================\n",
       "  1033                                               def __repr__(self):\n",
       "  1034        12         26.0      2.2    100.0          return '%s(n_jobs=%s)' % (self.__class__.__name__, self.n_jobs)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%lprun -m ExploreBFS -s speed.BFS_Run(1, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    1.8s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    1.8s finished\n",
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    1.9s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    1.9s finished\n",
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    3.9s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    3.9s finished\n",
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:   13.2s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:   13.2s finished\n",
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:   12.9s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:   12.9s finished\n",
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:   13.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:   13.0s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Timer unit: 1e-06 s\n",
       "\n",
       "Total time: 70.2771 s\n",
       "File: /Users/hector/Documents/BGWAS2/dbgwas_docker/Tarone/scripts/ExploreBFS.py\n",
       "Function: explore at line 24\n",
       "\n",
       "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
       "==============================================================\n",
       "    24                                           def explore(G, alpha, kmax, Lmax = 10 ** 7, verbose = False, threads = 1,\n",
       "    25                                                       backend = \"loky\"):\n",
       "    26                                               \"\"\"Compute the set R by incremental values of k:\n",
       "    27                                               \n",
       "    28                                               Args:\n",
       "    29                                                   G: the graph we want to explore.\n",
       "    30                                                   alpha: between 0 and 1. FWER we want to control.\n",
       "    31                                                   n1s: An vector of group sizes among the first phenotype.\n",
       "    32                                                   n2s: An vector of group sizes among the second phenotype.\n",
       "    33                                                   kmax: an integer, the maximum value of k we allow.\n",
       "    34                                                   Lmax: maximum size of the subgraph\n",
       "    35                                                   verbose: a boolean, default to false.\n",
       "    36                                                   threads: Number of cores used in the process\n",
       "    37                                                   backend: the backend used for parallelization\n",
       "    38                                               \n",
       "    39                                               Return:\n",
       "    40                                                   The array R of testable subgraphs.\n",
       "    41                                               \"\"\"\n",
       "    42                                               # We avoid computing this too often\n",
       "    43         1        961.0    961.0      0.0      n1s, n2s = G.ns()\n",
       "    44         1         60.0     60.0      0.0      n = int(n1s.sum() + n2s.sum())\n",
       "    45         1          7.0      7.0      0.0      nNodes = G.lengths.shape[0]\n",
       "    46         1        990.0    990.0      0.0      k0, TH = find_ko(np.array([]), alpha , 1)\n",
       "    47         1          5.0      5.0      0.0      if verbose:\n",
       "    48                                                   message1 = ('Starting to explore a graph with ' +\n",
       "    49                                                               '{N} nodes.'.format(N = nNodes))\n",
       "    50                                                   message2 = ('The value of alpha is {alpha}. '.format(alpha = alpha) +\n",
       "    51                                                               'k0 is initialized at 1.')\n",
       "    52                                                   print(message1)\n",
       "    53                                                   print(message2)\n",
       "    54                                                   print()\n",
       "    55                                               \n",
       "    56                                               # Initiate the list of candidates. We create the closure of every subgraph\n",
       "    57                                               # of size 1\n",
       "    58         1         50.0     50.0      0.0      chunks = np.array(range(nNodes))\n",
       "    59         1         91.0     91.0      0.0      chunks = np.array_split(chunks, threads)\n",
       "    60         1        236.0    236.0      0.0      C = Parallel(n_jobs=threads, backend = backend, verbose = 1)(\n",
       "    61         1    1838695.0 1838695.0      2.6                   delayed(start)(chunk, G, TH, n1s, n2s) for chunk in chunks)\n",
       "    62         1        104.0    104.0      0.0      C = np.concatenate(C)\n",
       "    63                                               # Then we prune the redundant ones\n",
       "    64         1        167.0    167.0      0.0      Tb = itemtable(nNodes)\n",
       "    65                                               \n",
       "    66       101        383.0      3.8      0.0      for i, S in enumerate(C):\n",
       "    67       100       2767.0     27.7      0.0          explored = Tb.add_table(max(S.nodes), S.ys)\n",
       "    68                                               \n",
       "    69         1        300.0    300.0      0.0      chunks = np.array_split(C, threads)\n",
       "    70         1        396.0    396.0      0.0      Env = Parallel(n_jobs=threads, backend = backend, verbose = 0)(\n",
       "    71         1    1476839.0 1476839.0      2.1                     delayed(compute_envelopes)(chunk) for chunk in chunks)\n",
       "    72         1        168.0    168.0      0.0      Env = np.concatenate(Env)\n",
       "    73         1        793.0    793.0      0.0      Prunable = Parallel(n_jobs=threads, backend = backend, verbose = 0)(\n",
       "    74         1    1513973.0 1513973.0      2.2                          delayed(are_prunable)(chunk) for chunk in chunks)\n",
       "    75         1         55.0     55.0      0.0      Prunable = np.concatenate(Prunable)\n",
       "    76         1        828.0    828.0      0.0      Too_Large = Parallel(n_jobs=threads, backend = backend, verbose = 0)(\n",
       "    77         1    1781704.0 1781704.0      2.5                          delayed(are_too_large)(chunk, Lmax) for chunk in chunks)\n",
       "    78         1        142.0    142.0      0.0      Too_Large = np.concatenate(Too_Large)\n",
       "    79                                               \n",
       "    80                                               # We then find the updated k0 we considering only subgraphs of size 1\n",
       "    81         1       4089.0   4089.0      0.0      k0, TH = find_ko(Env, alpha)\n",
       "    82                                           \n",
       "    83                                               # We clean the list and we save testable subgraphs\n",
       "    84         1         21.0     21.0      0.0      are_Testable = Env >= TH\n",
       "    85         1         10.0     10.0      0.0      R = C[are_Testable]\n",
       "    86         1          4.0      4.0      0.0      R_Env = Env[are_Testable]\n",
       "    87         1         30.0     30.0      0.0      Keep = (Prunable * (1 - are_Testable) + Too_Large) == 0\n",
       "    88                                               \n",
       "    89         1          2.0      2.0      0.0      if verbose:\n",
       "    90                                                   messages(are_Testable, nNodes, Keep, Too_Large, Prunable, k0)\n",
       "    91                                               \n",
       "    92         1          5.0      5.0      0.0      C = C[Keep]\n",
       "    93                                               \n",
       "    94                                               # We then explore all subgraphs of size 2 and so on and so forth\n",
       "    95         5         19.0      3.8      0.0      while C.shape[0] > 0:\n",
       "    96         5         15.0      3.0      0.0          if k0 > kmax:\n",
       "    97                                                       if verbose:\n",
       "    98                                                           print('Reached kmax value')\n",
       "    99                                                       break\n",
       "   100                                                   # Compute all the parents\n",
       "   101         5        752.0    150.4      0.0          chunks = np.array_split(C, threads)\n",
       "   102         5       2315.0    463.0      0.0          Parents = Parallel(n_jobs=threads, backend = backend, verbose = 1)(\n",
       "   103         5   45750574.0 9150114.8     65.1                  delayed(expand)(chunk, G, TH, n1s, n2s, Tb) for chunk in chunks)\n",
       "   104         5        217.0     43.4      0.0          Parents = np.concatenate(Parents)\n",
       "   105         5         25.0      5.0      0.0          if Parents.shape[0] == 0:\n",
       "   106         1          2.0      2.0      0.0              break\n",
       "   107         4         91.0     22.8      0.0          Explored = np.zeros(Parents.shape[0], dtype = np.bool)\n",
       "   108                                                   # Prune the redundants via the itemtable\n",
       "   109      3103       7705.0      2.5      0.0          for i, S in enumerate(Parents):\n",
       "   110      3099      80017.0     25.8      0.1              explored = Tb.check_table(max(S.nodes), S.ys)\n",
       "   111      3099       6953.0      2.2      0.0              if not explored:\n",
       "   112      1656      23704.0     14.3      0.0                  Tb.add_table(max(S.nodes), S.ys)\n",
       "   113      3099       8500.0      2.7      0.0              Explored[i] = explored\n",
       "   114                                                   \n",
       "   115                                                   # Update the set of closed subgraphs we explore after removing the\n",
       "   116                                                   # redundants\n",
       "   117         4        167.0     41.8      0.0          C =  Parents[Explored == False]\n",
       "   118                                                   \n",
       "   119         4        424.0    106.0      0.0          chunks = np.array_split(C, threads)\n",
       "   120         4        921.0    230.2      0.0          Env = Parallel(n_jobs=threads, backend = backend, verbose = 0)(\n",
       "   121         4    5985052.0 1496263.0      8.5                         delayed(compute_envelopes)(chunk) for chunk in chunks)\n",
       "   122         4        514.0    128.5      0.0          Env = np.concatenate(Env)\n",
       "   123         4       3343.0    835.8      0.0          Prunable = Parallel(n_jobs=threads, backend = backend, verbose = 0)(\n",
       "   124         4    5483043.0 1370760.8      7.8                              delayed(are_prunable)(chunk) for chunk in chunks)\n",
       "   125         4        660.0    165.0      0.0          Prunable = np.concatenate(Prunable)\n",
       "   126         4       3492.0    873.0      0.0          Too_Large = Parallel(n_jobs=threads, backend = backend, verbose = 0)(\n",
       "   127         4    6272680.0 1568170.0      8.9                          delayed(are_too_large)(chunk, Lmax) for chunk in chunks)\n",
       "   128         4        723.0    180.8      0.0          Too_Large = np.concatenate(Too_Large)\n",
       "   129                                                   \n",
       "   130         4      19777.0   4944.2      0.0          k0, TH = find_ko(np.concatenate([Env, R_Env]), alpha, k0)\n",
       "   131                                                   \n",
       "   132         4         48.0     12.0      0.0          are_Testable = Env >= TH\n",
       "   133         4       1138.0    284.5      0.0          R = np.concatenate([R[R_Env >= TH], C[are_Testable]])\n",
       "   134         4        138.0     34.5      0.0          R_Env = np.concatenate([R_Env[R_Env >= TH], Env[are_Testable]])\n",
       "   135         4        124.0     31.0      0.0          Keep = (Prunable * (1 - are_Testable) + Too_Large) == 0\n",
       "   136                                                   \n",
       "   137         4         11.0      2.8      0.0          if verbose:\n",
       "   138                                                       messages(are_Testable, C.shape[0], Keep, Too_Large, Prunable, k0)\n",
       "   139         4         48.0     12.0      0.0          C = C[Keep]\n",
       "   140                                                   \n",
       "   141                                               # We have finished and we return the testable graphs\n",
       "   142         1          2.0      2.0      0.0      return R, R_Env, k0, TH\n",
       "\n",
       "Total time: 1e-05 s\n",
       "File: /Users/hector/Documents/BGWAS2/dbgwas_docker/Tarone/scripts/Helper_Explo.py\n",
       "Function: __init__ at line 138\n",
       "\n",
       "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
       "==============================================================\n",
       "   138                                               def __init__(self, Pop, neighbours, nodes, pheno, lengths):\n",
       "   139         1          4.0      4.0     40.0          self.Pop = Pop\n",
       "   140         1          2.0      2.0     20.0          self.neighbours = neighbours\n",
       "   141         1          1.0      1.0     10.0          self.pattern = nodes\n",
       "   142         1          2.0      2.0     20.0          self.Pheno = pheno\n",
       "   143         1          1.0      1.0     10.0          self.lengths = lengths\n",
       "\n",
       "Total time: 0.000926 s\n",
       "File: /Users/hector/Documents/BGWAS2/dbgwas_docker/Tarone/scripts/Helper_Explo.py\n",
       "Function: ns at line 145\n",
       "\n",
       "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
       "==============================================================\n",
       "   145                                               def ns(self):\n",
       "   146                                                   # We have k groups\n",
       "   147                                                   # We returns two vectors of length k with the number of sample in each\n",
       "   148                                                   # group, split by phenotype.\n",
       "   149         1         87.0     87.0      9.4          clusters = np.unique(self.Pop)\n",
       "   150         1          2.0      2.0      0.2          clusters.sort()\n",
       "   151         1          7.0      7.0      0.8          n1s = np.zeros(len(clusters))\n",
       "   152         1          4.0      4.0      0.4          n2s = np.zeros(len(clusters))\n",
       "   153                                                   \n",
       "   154         2          7.0      3.5      0.8          for clus in clusters:\n",
       "   155         1         71.0     71.0      7.7              n1s[clus] = sum(self.Pheno[self.Pop == clus])\n",
       "   156         1        746.0    746.0     80.6              n2s[clus] = sum(self.Pop == clus) - n1s[clus]\n",
       "   157                                                   \n",
       "   158         1          2.0      2.0      0.2          return n1s, n2s\n",
       "\n",
       "Total time: 0.02375 s\n",
       "File: /Users/hector/Documents/BGWAS2/dbgwas_docker/Tarone/scripts/Helper_Tarone.py\n",
       "Function: find_ko at line 64\n",
       "\n",
       "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
       "==============================================================\n",
       "    64                                           def find_ko(min_ps, alpha, k = 1):\n",
       "    65                                               \"\"\"Compute the k0 according to the method in Terada et al\n",
       "    66                                               \n",
       "    67                                               Args:\n",
       "    68                                                   min_ps: The list of minimal p-values\n",
       "    69                                                   alpha: The threshold for controlling the FWER\n",
       "    70                                                   k: the previous value of k0 computed on a smaller set. Default to 1\n",
       "    71                                           \n",
       "    72                                               Return:\n",
       "    73                                                   The k0 value and associated cutoff for the Chi-square test\n",
       "    74                                               \"\"\"\n",
       "    75         6        814.0    135.7      3.4      sortedMinP = -np.sort(-min_ps)\n",
       "    76         6         24.0      4.0      0.1      N = min_ps.shape[0]\n",
       "    77         6          8.0      1.3      0.0      a = k - 1\n",
       "    78         6          5.0      0.8      0.0      b = N\n",
       "    79        47         45.0      1.0      0.2      while b - a > 1:\n",
       "    80        41        106.0      2.6      0.4          mid = int((a + b) / 2)\n",
       "    81        41      19919.0    485.8     83.9          TH = chi2.isf(alpha / (mid + 1), 1)\n",
       "    82        41         97.0      2.4      0.4          if sortedMinP[mid] >= TH:\n",
       "    83        28         19.0      0.7      0.1              a = mid \n",
       "    84                                                   else:\n",
       "    85        13         13.0      1.0      0.1              b = mid\n",
       "    86         6          5.0      0.8      0.0      k0 = a + 1\n",
       "    87         6       2687.0    447.8     11.3      TH = chi2.isf(alpha / k0, 1)\n",
       "    88         6          8.0      1.3      0.0      return k0, TH\n",
       "\n",
       "Total time: 0.000112 s\n",
       "File: /Users/hector/Documents/BGWAS2/dbgwas_docker/Tarone/scripts/ItemTable.py\n",
       "Function: __init__ at line 6\n",
       "\n",
       "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
       "==============================================================\n",
       "     6                                               def __init__(self, nNodes):\n",
       "     7         1        111.0    111.0     99.1          self.dict = {k: set() for k in range(nNodes)}\n",
       "     8         1          1.0      1.0      0.9          return\n",
       "\n",
       "Total time: 0.039353 s\n",
       "File: /Users/hector/Documents/BGWAS2/dbgwas_docker/Tarone/scripts/ItemTable.py\n",
       "Function: check_table at line 10\n",
       "\n",
       "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
       "==============================================================\n",
       "    10                                               def check_table(self, max_node, pattern):\n",
       "    11      3099       1495.0      0.5      3.8          explored = False\n",
       "    12      3099      23679.0      7.6     60.2          max_pattern = tuple(pattern)\n",
       "    13      3099      12270.0      4.0     31.2          if max_pattern in self.dict[max_node]:\n",
       "    14      1443        643.0      0.4      1.6              explored = True\n",
       "    15      3099       1266.0      0.4      3.2          return explored\n",
       "\n",
       "Total time: 0.01727 s\n",
       "File: /Users/hector/Documents/BGWAS2/dbgwas_docker/Tarone/scripts/ItemTable.py\n",
       "Function: add_table at line 17\n",
       "\n",
       "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
       "==============================================================\n",
       "    17                                               def add_table(self, max_node, pattern):\n",
       "    18      1756      11361.0      6.5     65.8          max_pattern = tuple(pattern)\n",
       "    19      1756       5156.0      2.9     29.9          self.dict[max_node].add(max_pattern)\n",
       "    20      1756        753.0      0.4      4.4          return\n",
       "\n",
       "Total time: 0.001378 s\n",
       "File: /usr/local/lib/python3.7/site-packages/joblib/parallel.py\n",
       "Function: delayed at line 295\n",
       "\n",
       "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
       "==============================================================\n",
       "   295                                           def delayed(function, check_pickle=None):\n",
       "   296                                               \"\"\"Decorator used to capture the arguments of a function.\"\"\"\n",
       "   297        42         34.0      0.8      2.5      if check_pickle is not None:\n",
       "   298                                                   warnings.warn('check_pickle is deprecated in joblib 0.12 and will be'\n",
       "   299                                                                 ' removed in 0.13', DeprecationWarning)\n",
       "   300                                               # Try to pickle the input function, to catch the problems early when\n",
       "   301                                               # using with multiprocessing:\n",
       "   302        42         29.0      0.7      2.1      if check_pickle:\n",
       "   303                                                   dumps(function)\n",
       "   304                                           \n",
       "   305        42         41.0      1.0      3.0      def delayed_function(*args, **kwargs):\n",
       "   306                                                   return function, args, kwargs\n",
       "   307        42         23.0      0.5      1.7      try:\n",
       "   308        42       1222.0     29.1     88.7          delayed_function = functools.wraps(function)(delayed_function)\n",
       "   309                                               except AttributeError:\n",
       "   310                                                   \" functools.wraps fails on some callable objects \"\n",
       "   311        42         29.0      0.7      2.1      return delayed_function\n",
       "\n",
       "Total time: 0.008859 s\n",
       "File: /usr/local/lib/python3.7/site-packages/joblib/parallel.py\n",
       "Function: __init__ at line 615\n",
       "\n",
       "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
       "==============================================================\n",
       "   615                                               def __init__(self, n_jobs=None, backend=None, verbose=0, timeout=None,\n",
       "   616                                                            pre_dispatch='2 * n_jobs', batch_size='auto',\n",
       "   617                                                            temp_folder=None, max_nbytes='1M', mmap_mode='r',\n",
       "   618                                                            prefer=None, require=None):\n",
       "   619        21         58.0      2.8      0.7          active_backend, context_n_jobs = get_active_backend(\n",
       "   620        21       1434.0     68.3     16.2              prefer=prefer, require=require, verbose=verbose)\n",
       "   621        21         44.0      2.1      0.5          nesting_level = active_backend.nesting_level\n",
       "   622        21         36.0      1.7      0.4          if backend is None and n_jobs is None:\n",
       "   623                                                       # If we are under a parallel_backend context manager, look up\n",
       "   624                                                       # the default number of jobs and use that instead:\n",
       "   625                                                       n_jobs = context_n_jobs\n",
       "   626        21         32.0      1.5      0.4          if n_jobs is None:\n",
       "   627                                                       # No specific context override and no specific value request:\n",
       "   628                                                       # default to 1.\n",
       "   629                                                       n_jobs = 1\n",
       "   630        21        596.0     28.4      6.7          self.n_jobs = n_jobs\n",
       "   631        21         39.0      1.9      0.4          self.verbose = verbose\n",
       "   632        21         38.0      1.8      0.4          self.timeout = timeout\n",
       "   633        21         35.0      1.7      0.4          self.pre_dispatch = pre_dispatch\n",
       "   634        21       1775.0     84.5     20.0          self._ready_batches = queue.Queue()\n",
       "   635                                           \n",
       "   636        21         54.0      2.6      0.6          if isinstance(max_nbytes, _basestring):\n",
       "   637        21        938.0     44.7     10.6              max_nbytes = memstr_to_bytes(max_nbytes)\n",
       "   638                                           \n",
       "   639        21         36.0      1.7      0.4          self._backend_args = dict(\n",
       "   640        21         32.0      1.5      0.4              max_nbytes=max_nbytes,\n",
       "   641        21         34.0      1.6      0.4              mmap_mode=mmap_mode,\n",
       "   642        21         30.0      1.4      0.3              temp_folder=temp_folder,\n",
       "   643        21         34.0      1.6      0.4              prefer=prefer,\n",
       "   644        21         32.0      1.5      0.4              require=require,\n",
       "   645        21        211.0     10.0      2.4              verbose=max(0, self.verbose - 50),\n",
       "   646                                                   )\n",
       "   647        21         41.0      2.0      0.5          if DEFAULT_MP_CONTEXT is not None:\n",
       "   648                                                       self._backend_args['context'] = DEFAULT_MP_CONTEXT\n",
       "   649        21        150.0      7.1      1.7          elif hasattr(mp, \"get_context\"):\n",
       "   650        21       1113.0     53.0     12.6              self._backend_args['context'] = mp.get_context()\n",
       "   651                                           \n",
       "   652        21         39.0      1.9      0.4          if backend is None:\n",
       "   653                                                       backend = active_backend\n",
       "   654                                           \n",
       "   655        21       1188.0     56.6     13.4          elif isinstance(backend, ParallelBackendBase):\n",
       "   656                                                       # Use provided backend as is, with the current nesting_level if it\n",
       "   657                                                       # is not set yet.\n",
       "   658                                                       if backend.nesting_level is None:\n",
       "   659                                                           backend.nesting_level = nesting_level\n",
       "   660                                           \n",
       "   661        21         90.0      4.3      1.0          elif hasattr(backend, 'Pool') and hasattr(backend, 'Lock'):\n",
       "   662                                                       # Make it possible to pass a custom multiprocessing context as\n",
       "   663                                                       # backend to change the start method to forkserver or spawn or\n",
       "   664                                                       # preload modules on the forkserver helper process.\n",
       "   665                                                       self._backend_args['context'] = backend\n",
       "   666                                                       backend = MultiprocessingBackend(nesting_level=nesting_level)\n",
       "   667                                                   else:\n",
       "   668        21         32.0      1.5      0.4              try:\n",
       "   669        21         44.0      2.1      0.5                  backend_factory = BACKENDS[backend]\n",
       "   670                                                       except KeyError:\n",
       "   671                                                           raise ValueError(\"Invalid backend: %s, expected one of %r\"\n",
       "   672                                                                            % (backend, sorted(BACKENDS.keys())))\n",
       "   673        21        249.0     11.9      2.8              backend = backend_factory(nesting_level=nesting_level)\n",
       "   674                                           \n",
       "   675        21         35.0      1.7      0.4          if (require == 'sharedmem' and\n",
       "   676                                                           not getattr(backend, 'supports_sharedmem', False)):\n",
       "   677                                                       raise ValueError(\"Backend %s does not support shared memory\"\n",
       "   678                                                                        % backend)\n",
       "   679                                           \n",
       "   680        21         38.0      1.8      0.4          if (batch_size == 'auto' or isinstance(batch_size, Integral) and\n",
       "   681                                                           batch_size > 0):\n",
       "   682        21         41.0      2.0      0.5              self.batch_size = batch_size\n",
       "   683                                                   else:\n",
       "   684                                                       raise ValueError(\n",
       "   685                                                           \"batch_size must be 'auto' or a positive integer, got: %r\"\n",
       "   686                                                           % batch_size)\n",
       "   687                                           \n",
       "   688        21         34.0      1.6      0.4          self._backend = backend\n",
       "   689        21         35.0      1.7      0.4          self._output = None\n",
       "   690        21         53.0      2.5      0.6          self._jobs = list()\n",
       "   691        21         36.0      1.7      0.4          self._managed_backend = False\n",
       "   692                                           \n",
       "   693                                                   # This lock is used coordinate the main thread of this process with\n",
       "   694                                                   # the async callback thread of our the pool.\n",
       "   695        21        153.0      7.3      1.7          self._lock = threading.RLock()\n",
       "\n",
       "Total time: 3.50402 s\n",
       "File: /usr/local/lib/python3.7/site-packages/joblib/parallel.py\n",
       "Function: _initialize_backend at line 706\n",
       "\n",
       "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
       "==============================================================\n",
       "   706                                               def _initialize_backend(self):\n",
       "   707                                                   \"\"\"Build a process or thread pool and return the number of workers\"\"\"\n",
       "   708        21         21.0      1.0      0.0          try:\n",
       "   709        21        751.0     35.8      0.0              n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,\n",
       "   710        21    3503167.0 166817.5    100.0                                               **self._backend_args)\n",
       "   711        21         71.0      3.4      0.0              if self.timeout is not None and not self._backend.supports_timeout:\n",
       "   712                                                           warnings.warn(\n",
       "   713                                                               'The backend class {!r} does not support timeout. '\n",
       "   714                                                               \"You have set 'timeout={}' in Parallel but \"\n",
       "   715                                                               \"the 'timeout' parameter will not be used.\".format(\n",
       "   716                                                                   self._backend.__class__.__name__,\n",
       "   717                                                                   self.timeout))\n",
       "   718                                           \n",
       "   719                                                   except FallbackToBackend as e:\n",
       "   720                                                       # Recursively initialize the backend in case of requested fallback.\n",
       "   721                                                       self._backend = e.backend\n",
       "   722                                                       n_jobs = self._initialize_backend()\n",
       "   723                                           \n",
       "   724        21         14.0      0.7      0.0          return n_jobs\n",
       "\n",
       "Total time: 0.006408 s\n",
       "File: /usr/local/lib/python3.7/site-packages/joblib/parallel.py\n",
       "Function: _terminate_backend at line 731\n",
       "\n",
       "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
       "==============================================================\n",
       "   731                                               def _terminate_backend(self):\n",
       "   732        21         21.0      1.0      0.3          if self._backend is not None:\n",
       "   733        21       6387.0    304.1     99.7              self._backend.terminate()\n",
       "\n",
       "Total time: 0.685322 s\n",
       "File: /usr/local/lib/python3.7/site-packages/joblib/parallel.py\n",
       "Function: _dispatch at line 735\n",
       "\n",
       "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
       "==============================================================\n",
       "   735                                               def _dispatch(self, batch):\n",
       "   736                                                   \"\"\"Queue the batch for computing, with or without multiprocessing\n",
       "   737                                           \n",
       "   738                                                   WARNING: this method is not thread-safe: it should be only called\n",
       "   739                                                   indirectly via dispatch_one_batch.\n",
       "   740                                           \n",
       "   741                                                   \"\"\"\n",
       "   742                                                   # If job.get() catches an exception, it closes the queue:\n",
       "   743        42        220.0      5.2      0.0          if self._aborting:\n",
       "   744                                                       return\n",
       "   745                                           \n",
       "   746        42         98.0      2.3      0.0          self.n_dispatched_tasks += len(batch)\n",
       "   747        42         45.0      1.1      0.0          self.n_dispatched_batches += 1\n",
       "   748                                           \n",
       "   749        42        374.0      8.9      0.1          dispatch_timestamp = time.time()\n",
       "   750        42        718.0     17.1      0.1          cb = BatchCompletionCallBack(dispatch_timestamp, len(batch), self)\n",
       "   751        42         75.0      1.8      0.0          with self._lock:\n",
       "   752        42         44.0      1.0      0.0              job_idx = len(self._jobs)\n",
       "   753        42     683279.0  16268.5     99.7              job = self._backend.apply_async(batch, callback=cb)\n",
       "   754                                                       # A job can complete so quickly than its callback is\n",
       "   755                                                       # called before we get here, causing self._jobs to\n",
       "   756                                                       # grow. To ensure correct results ordering, .insert is\n",
       "   757                                                       # used (rather than .append) in the following line\n",
       "   758        42        469.0     11.2      0.1              self._jobs.insert(job_idx, job)\n",
       "\n",
       "Total time: 0.695744 s\n",
       "File: /usr/local/lib/python3.7/site-packages/joblib/parallel.py\n",
       "Function: dispatch_one_batch at line 772\n",
       "\n",
       "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
       "==============================================================\n",
       "   772                                               def dispatch_one_batch(self, iterator):\n",
       "   773                                                   \"\"\"Prefetch the tasks for the next batch and dispatch them.\n",
       "   774                                           \n",
       "   775                                                   The effective size of the batch is computed here.\n",
       "   776                                                   If there are no more jobs to dispatch, return False, else return True.\n",
       "   777                                           \n",
       "   778                                                   The iterator consumption and dispatching is protected by the same\n",
       "   779                                                   lock so calling this function should be thread safe.\n",
       "   780                                           \n",
       "   781                                                   \"\"\"\n",
       "   782        63        196.0      3.1      0.0          if self.batch_size == 'auto':\n",
       "   783        63        768.0     12.2      0.1              batch_size = self._backend.compute_batch_size()\n",
       "   784                                                   else:\n",
       "   785                                                       # Fixed batch size strategy\n",
       "   786                                                       batch_size = self.batch_size\n",
       "   787                                           \n",
       "   788        63        165.0      2.6      0.0          with self._lock:\n",
       "   789                                                       # to ensure an even distribution of the workolad between workers,\n",
       "   790                                                       # we look ahead in the original iterators more than batch_size\n",
       "   791                                                       # tasks - However, we keep consuming only one batch at each\n",
       "   792                                                       # dispatch_one_batch call. The extra tasks are stored in a local\n",
       "   793                                                       # queue, _ready_batches, that is looked-up prior to re-consuming\n",
       "   794                                                       # tasks from the origal iterator.\n",
       "   795        63         55.0      0.9      0.0              try:\n",
       "   796        63       1658.0     26.3      0.2                  tasks = self._ready_batches.get(block=False)\n",
       "   797        42        197.0      4.7      0.0              except queue.Empty:\n",
       "   798                                                           # slice the iterator n_jobs * batchsize items at a time. If the\n",
       "   799                                                           # slice returns less than that, then the current batchsize puts\n",
       "   800                                                           # too much weight on a subset of workers, while other may end\n",
       "   801                                                           # up starving. So in this case, re-scale the batch size\n",
       "   802                                                           # accordingly to distribute evenly the last items between all\n",
       "   803                                                           # workers.\n",
       "   804        42         50.0      1.2      0.0                  n_jobs = self._cached_effective_n_jobs\n",
       "   805        42         50.0      1.2      0.0                  big_batch_size = batch_size * n_jobs\n",
       "   806                                           \n",
       "   807        42       3223.0     76.7      0.5                  islice = list(itertools.islice(iterator, big_batch_size))\n",
       "   808        42         62.0      1.5      0.0                  if len(islice) == 0:\n",
       "   809        21         55.0      2.6      0.0                      return False\n",
       "   810        21         23.0      1.1      0.0                  elif (iterator is self._original_iterator\n",
       "   811                                                                 and len(islice) < big_batch_size):\n",
       "   812                                                               # We reached the end of the original iterator (unless\n",
       "   813                                                               # iterator is the ``pre_dispatch``-long initial slice of\n",
       "   814                                                               # the original iterator) -- decrease the batch size to\n",
       "   815                                                               # account for potential variance in the batches running\n",
       "   816                                                               # time.\n",
       "   817                                                               final_batch_size = max(1, len(islice) // (10 * n_jobs))\n",
       "   818                                                           else:\n",
       "   819        21         42.0      2.0      0.0                      final_batch_size = max(1, len(islice) // n_jobs)\n",
       "   820                                           \n",
       "   821                                                           # enqueue n_jobs batches in a local queue\n",
       "   822        63         93.0      1.5      0.0                  for i in range(0, len(islice), final_batch_size):\n",
       "   823        42         64.0      1.5      0.0                      tasks = BatchedCalls(islice[i:i + final_batch_size],\n",
       "   824        42        292.0      7.0      0.0                                           self._backend.get_nested_backend(),\n",
       "   825        42        292.0      7.0      0.0                                           self._pickle_cache)\n",
       "   826        42        738.0     17.6      0.1                      self._ready_batches.put(tasks)\n",
       "   827                                           \n",
       "   828                                                           # finally, get one task.\n",
       "   829        21        251.0     12.0      0.0                  tasks = self._ready_batches.get(block=False)\n",
       "   830        42        630.0     15.0      0.1              if len(tasks) == 0:\n",
       "   831                                                           # No more tasks available in the iterator: tell caller to stop.\n",
       "   832                                                           return False\n",
       "   833                                                       else:\n",
       "   834        42     686576.0  16347.0     98.7                  self._dispatch(tasks)\n",
       "   835        42        264.0      6.3      0.0                  return True\n",
       "\n",
       "Total time: 0.005711 s\n",
       "File: /usr/local/lib/python3.7/site-packages/joblib/parallel.py\n",
       "Function: _print at line 837\n",
       "\n",
       "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
       "==============================================================\n",
       "   837                                               def _print(self, msg, msg_args):\n",
       "   838                                                   \"\"\"Display the message on stout or stderr depending on verbosity\"\"\"\n",
       "   839                                                   # XXX: Not using the logger framework: need to\n",
       "   840                                                   # learn to use logger better.\n",
       "   841        42         61.0      1.5      1.1          if not self.verbose:\n",
       "   842        30         22.0      0.7      0.4              return\n",
       "   843        12         12.0      1.0      0.2          if self.verbose < 50:\n",
       "   844        12        113.0      9.4      2.0              writer = sys.stderr.write\n",
       "   845                                                   else:\n",
       "   846                                                       writer = sys.stdout.write\n",
       "   847        12         34.0      2.8      0.6          msg = msg % msg_args\n",
       "   848        12       5469.0    455.8     95.8          writer('[%s]: %s\\n' % (self, msg))\n",
       "\n",
       "Total time: 65.8689 s\n",
       "File: /usr/local/lib/python3.7/site-packages/joblib/parallel.py\n",
       "Function: retrieve at line 893\n",
       "\n",
       "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
       "==============================================================\n",
       "   893                                               def retrieve(self):\n",
       "   894        21        600.0     28.6      0.0          self._output = list()\n",
       "   895        63        271.0      4.3      0.0          while self._iterating or len(self._jobs) > 0:\n",
       "   896        42         85.0      2.0      0.0              if len(self._jobs) == 0:\n",
       "   897                                                           # Wait for an async callback to dispatch new jobs\n",
       "   898                                                           time.sleep(0.01)\n",
       "   899                                                           continue\n",
       "   900                                                       # We need to be careful: the job list can be filling up as\n",
       "   901                                                       # we empty it and Python list are not thread-safe by default hence\n",
       "   902                                                       # the use of the lock\n",
       "   903        42        155.0      3.7      0.0              with self._lock:\n",
       "   904        42        178.0      4.2      0.0                  job = self._jobs.pop(0)\n",
       "   905                                           \n",
       "   906        42         64.0      1.5      0.0              try:\n",
       "   907        42        124.0      3.0      0.0                  if getattr(self._backend, 'supports_timeout', False):\n",
       "   908        42   65867386.0 1568271.1    100.0                      self._output.extend(job.get(timeout=self.timeout))\n",
       "   909                                                           else:\n",
       "   910                                                               self._output.extend(job.get())\n",
       "   911                                           \n",
       "   912                                                       except BaseException as exception:\n",
       "   913                                                           # Note: we catch any BaseException instead of just Exception\n",
       "   914                                                           # instances to also include KeyboardInterrupt.\n",
       "   915                                           \n",
       "   916                                                           # Stop dispatching any new job in the async callback thread\n",
       "   917                                                           self._aborting = True\n",
       "   918                                           \n",
       "   919                                                           # If the backend allows it, cancel or kill remaining running\n",
       "   920                                                           # tasks without waiting for the results as we will raise\n",
       "   921                                                           # the exception we got back to the caller instead of returning\n",
       "   922                                                           # any result.\n",
       "   923                                                           backend = self._backend\n",
       "   924                                                           if (backend is not None and\n",
       "   925                                                                   hasattr(backend, 'abort_everything')):\n",
       "   926                                                               # If the backend is managed externally we need to make sure\n",
       "   927                                                               # to leave it in a working state to allow for future jobs\n",
       "   928                                                               # scheduling.\n",
       "   929                                                               ensure_ready = self._managed_backend\n",
       "   930                                                               backend.abort_everything(ensure_ready=ensure_ready)\n",
       "   931                                           \n",
       "   932                                                           if isinstance(exception, TransportableException):\n",
       "   933                                                               # Capture exception to add information on the local\n",
       "   934                                                               # stack in addition to the distant stack\n",
       "   935                                                               this_report = format_outer_frames(context=10,\n",
       "   936                                                                                                 stack_start=1)\n",
       "   937                                                               raise exception.unwrap(this_report)\n",
       "   938                                                           else:\n",
       "   939                                                               raise\n",
       "\n",
       "Total time: 70.0931 s\n",
       "File: /usr/local/lib/python3.7/site-packages/joblib/parallel.py\n",
       "Function: __call__ at line 941\n",
       "\n",
       "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
       "==============================================================\n",
       "   941                                               def __call__(self, iterable):\n",
       "   942        21         45.0      2.1      0.0          if self._jobs:\n",
       "   943                                                       raise ValueError('This Parallel instance is already running')\n",
       "   944                                                   # A flag used to abort the dispatching of jobs in case an\n",
       "   945                                                   # exception is found\n",
       "   946        21         48.0      2.3      0.0          self._aborting = False\n",
       "   947                                           \n",
       "   948        21         31.0      1.5      0.0          if not self._managed_backend:\n",
       "   949        21    3504366.0 166874.6      5.0              n_jobs = self._initialize_backend()\n",
       "   950                                                   else:\n",
       "   951                                                       n_jobs = self._effective_n_jobs()\n",
       "   952                                           \n",
       "   953                                                   # self._effective_n_jobs should be called in the Parallel.__call__\n",
       "   954                                                   # thread only -- store its value in an attribute for further queries.\n",
       "   955        21         27.0      1.3      0.0          self._cached_effective_n_jobs = n_jobs\n",
       "   956                                           \n",
       "   957        21         61.0      2.9      0.0          backend_name = self._backend.__class__.__name__\n",
       "   958        21         23.0      1.1      0.0          if n_jobs == 0:\n",
       "   959                                                       raise RuntimeError(\"%s has no active worker.\" % backend_name)\n",
       "   960                                           \n",
       "   961        21         32.0      1.5      0.0          self._print(\"Using backend %s with %d concurrent workers.\",\n",
       "   962        21       3541.0    168.6      0.0                      (backend_name, n_jobs))\n",
       "   963        21         77.0      3.7      0.0          if hasattr(self._backend, 'start_call'):\n",
       "   964        21         80.0      3.8      0.0              self._backend.start_call()\n",
       "   965        21         35.0      1.7      0.0          iterator = iter(iterable)\n",
       "   966        21         25.0      1.2      0.0          pre_dispatch = self.pre_dispatch\n",
       "   967                                           \n",
       "   968        21         29.0      1.4      0.0          if pre_dispatch == 'all' or n_jobs == 1:\n",
       "   969                                                       # prevent further dispatch via multiprocessing callback thread\n",
       "   970                                                       self._original_iterator = None\n",
       "   971                                                       self._pre_dispatch_amount = 0\n",
       "   972                                                   else:\n",
       "   973        21         29.0      1.4      0.0              self._original_iterator = iterator\n",
       "   974        21         41.0      2.0      0.0              if hasattr(pre_dispatch, 'endswith'):\n",
       "   975        21       1421.0     67.7      0.0                  pre_dispatch = eval(pre_dispatch)\n",
       "   976        21         70.0      3.3      0.0              self._pre_dispatch_amount = pre_dispatch = int(pre_dispatch)\n",
       "   977                                           \n",
       "   978                                                       # The main thread will consume the first pre_dispatch items and\n",
       "   979                                                       # the remaining items will later be lazily dispatched by async\n",
       "   980                                                       # callbacks upon task completions.\n",
       "   981                                           \n",
       "   982                                                       # TODO: this iterator should be batch_size * n_jobs\n",
       "   983        21         91.0      4.3      0.0              iterator = itertools.islice(iterator, self._pre_dispatch_amount)\n",
       "   984                                           \n",
       "   985        21         98.0      4.7      0.0          self._start_time = time.time()\n",
       "   986        21         33.0      1.6      0.0          self.n_dispatched_batches = 0\n",
       "   987        21         26.0      1.2      0.0          self.n_dispatched_tasks = 0\n",
       "   988        21         25.0      1.2      0.0          self.n_completed_tasks = 0\n",
       "   989                                                   # Use a caching dict for callables that are pickled with cloudpickle to\n",
       "   990                                                   # improve performances. This cache is used only in the case of\n",
       "   991                                                   # functions that are defined in the __main__ module, functions that are\n",
       "   992                                                   # defined locally (inside another function) and lambda expressions.\n",
       "   993        21        132.0      6.3      0.0          self._pickle_cache = dict()\n",
       "   994        21         22.0      1.0      0.0          try:\n",
       "   995                                                       # Only set self._iterating to True if at least a batch\n",
       "   996                                                       # was dispatched. In particular this covers the edge\n",
       "   997                                                       # case of Parallel used with an exhausted iterator. If\n",
       "   998                                                       # self._original_iterator is None, then this means either\n",
       "   999                                                       # that pre_dispatch == \"all\", n_jobs == 1 or that the first batch\n",
       "  1000                                                       # was very quick and its callback already dispatched all the\n",
       "  1001                                                       # remaining jobs.\n",
       "  1002        21         34.0      1.6      0.0              self._iterating = False\n",
       "  1003        21     656569.0  31265.2      0.9              if self.dispatch_one_batch(iterator):\n",
       "  1004        21        298.0     14.2      0.0                  self._iterating = self._original_iterator is not None\n",
       "  1005                                           \n",
       "  1006        42      41483.0    987.7      0.1              while self.dispatch_one_batch(iterator):\n",
       "  1007        21         28.0      1.3      0.0                  pass\n",
       "  1008                                           \n",
       "  1009        21         43.0      2.0      0.0              if pre_dispatch == \"all\" or n_jobs == 1:\n",
       "  1010                                                           # The iterable was consumed all at once by the above for loop.\n",
       "  1011                                                           # No need to wait for async callbacks to trigger to\n",
       "  1012                                                           # consumption.\n",
       "  1013                                                           self._iterating = False\n",
       "  1014                                           \n",
       "  1015        21       2285.0    108.8      0.0              with self._backend.retrieval_context():\n",
       "  1016        21   65870463.0 3136688.7     94.0                  self.retrieve()\n",
       "  1017                                                       # Make sure that we get a last message telling us we are done\n",
       "  1018        21        668.0     31.8      0.0              elapsed_time = time.time() - self._start_time\n",
       "  1019        21         98.0      4.7      0.0              self._print('Done %3i out of %3i | elapsed: %s finished',\n",
       "  1020        21         59.0      2.8      0.0                          (len(self._output), len(self._output),\n",
       "  1021        21       3460.0    164.8      0.0                           short_format_time(elapsed_time)))\n",
       "  1022                                                   finally:\n",
       "  1023        21        107.0      5.1      0.0              if hasattr(self._backend, 'stop_call'):\n",
       "  1024        21         83.0      4.0      0.0                  self._backend.stop_call()\n",
       "  1025        21         43.0      2.0      0.0              if not self._managed_backend:\n",
       "  1026        21       6670.0    317.6      0.0                  self._terminate_backend()\n",
       "  1027        21         98.0      4.7      0.0              self._jobs = list()\n",
       "  1028        21         77.0      3.7      0.0              self._pickle_cache = None\n",
       "  1029        21         40.0      1.9      0.0          output = self._output\n",
       "  1030        21         36.0      1.7      0.0          self._output = None\n",
       "  1031        21         28.0      1.3      0.0          return output\n",
       "\n",
       "Total time: 5.9e-05 s\n",
       "File: /usr/local/lib/python3.7/site-packages/joblib/parallel.py\n",
       "Function: __repr__ at line 1033\n",
       "\n",
       "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
       "==============================================================\n",
       "  1033                                               def __repr__(self):\n",
       "  1034        12         59.0      4.9    100.0          return '%s(n_jobs=%s)' % (self.__class__.__name__, self.n_jobs)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%lprun -m ExploreBFS -s speed.BFS_Run(2, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Using backend MultiprocessingBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=2)]: Using backend MultiprocessingBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    1.3s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    1.3s finished\n",
      "[Parallel(n_jobs=2)]: Using backend MultiprocessingBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    4.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    4.0s finished\n",
      "[Parallel(n_jobs=2)]: Using backend MultiprocessingBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    6.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    6.1s finished\n",
      "[Parallel(n_jobs=2)]: Using backend MultiprocessingBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    3.2s remaining:    0.0s\n",
      "[Parallel(n_jobs=2)]: Done   2 out of   2 | elapsed:    3.2s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Timer unit: 1e-06 s\n",
       "\n",
       "Total time: 17.7882 s\n",
       "File: /Users/hector/Documents/BGWAS2/dbgwas_docker/Tarone/scripts/ExploreBFS.py\n",
       "Function: explore at line 24\n",
       "\n",
       "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
       "==============================================================\n",
       "    24                                           def explore(G, alpha, kmax, Lmax = 10 ** 7, verbose = False, threads = 1,\n",
       "    25                                                       backend = \"loky\"):\n",
       "    26                                               \"\"\"Compute the set R by incremental values of k:\n",
       "    27                                               \n",
       "    28                                               Args:\n",
       "    29                                                   G: the graph we want to explore.\n",
       "    30                                                   alpha: between 0 and 1. FWER we want to control.\n",
       "    31                                                   n1s: An vector of group sizes among the first phenotype.\n",
       "    32                                                   n2s: An vector of group sizes among the second phenotype.\n",
       "    33                                                   kmax: an integer, the maximum value of k we allow.\n",
       "    34                                                   Lmax: maximum size of the subgraph\n",
       "    35                                                   verbose: a boolean, default to false.\n",
       "    36                                                   threads: Number of cores used in the process\n",
       "    37                                                   backend: the backend used for parallelization\n",
       "    38                                               \n",
       "    39                                               Return:\n",
       "    40                                                   The array R of testable subgraphs.\n",
       "    41                                               \"\"\"\n",
       "    42                                               # We avoid computing this too often\n",
       "    43         1       1359.0   1359.0      0.0      n1s, n2s = G.ns()\n",
       "    44         1         38.0     38.0      0.0      n = int(n1s.sum() + n2s.sum())\n",
       "    45         1          7.0      7.0      0.0      nNodes = G.lengths.shape[0]\n",
       "    46         1        534.0    534.0      0.0      k0, TH = find_ko(np.array([]), alpha , 1)\n",
       "    47         1          2.0      2.0      0.0      if verbose:\n",
       "    48                                                   message1 = ('Starting to explore a graph with ' +\n",
       "    49                                                               '{N} nodes.'.format(N = nNodes))\n",
       "    50                                                   message2 = ('The value of alpha is {alpha}. '.format(alpha = alpha) +\n",
       "    51                                                               'k0 is initialized at 1.')\n",
       "    52                                                   print(message1)\n",
       "    53                                                   print(message2)\n",
       "    54                                                   print()\n",
       "    55                                               \n",
       "    56                                               # Initiate the list of candidates. We create the closure of every subgraph\n",
       "    57                                               # of size 1\n",
       "    58         1         30.0     30.0      0.0      chunks = np.array(range(nNodes))\n",
       "    59         1         56.0     56.0      0.0      chunks = np.array_split(chunks, threads)\n",
       "    60         1        199.0    199.0      0.0      C = Parallel(n_jobs=threads, backend = backend, verbose = 1)(\n",
       "    61         1     251141.0 251141.0      1.4                   delayed(start)(chunk, G, TH, n1s, n2s) for chunk in chunks)\n",
       "    62         1         75.0     75.0      0.0      C = np.concatenate(C)\n",
       "    63                                               # Then we prune the redundant ones\n",
       "    64         1        166.0    166.0      0.0      Tb = itemtable(nNodes)\n",
       "    65                                               \n",
       "    66       101        386.0      3.8      0.0      for i, S in enumerate(C):\n",
       "    67       100       3840.0     38.4      0.0          explored = Tb.add_table(max(S.nodes), S.ys)\n",
       "    68                                               \n",
       "    69         1       7445.0   7445.0      0.0      chunks = np.array_split(C, threads)\n",
       "    70         1        622.0    622.0      0.0      Env = Parallel(n_jobs=threads, backend = backend, verbose = 0)(\n",
       "    71         1     213308.0 213308.0      1.2                     delayed(compute_envelopes)(chunk) for chunk in chunks)\n",
       "    72         1        121.0    121.0      0.0      Env = np.concatenate(Env)\n",
       "    73         1       1004.0   1004.0      0.0      Prunable = Parallel(n_jobs=threads, backend = backend, verbose = 0)(\n",
       "    74         1     245574.0 245574.0      1.4                          delayed(are_prunable)(chunk) for chunk in chunks)\n",
       "    75         1        499.0    499.0      0.0      Prunable = np.concatenate(Prunable)\n",
       "    76         1       3250.0   3250.0      0.0      Too_Large = Parallel(n_jobs=threads, backend = backend, verbose = 0)(\n",
       "    77         1     309029.0 309029.0      1.7                          delayed(are_too_large)(chunk, Lmax) for chunk in chunks)\n",
       "    78         1         84.0     84.0      0.0      Too_Large = np.concatenate(Too_Large)\n",
       "    79                                               \n",
       "    80                                               # We then find the updated k0 we considering only subgraphs of size 1\n",
       "    81         1       8937.0   8937.0      0.1      k0, TH = find_ko(Env, alpha)\n",
       "    82                                           \n",
       "    83                                               # We clean the list and we save testable subgraphs\n",
       "    84         1          8.0      8.0      0.0      are_Testable = Env >= TH\n",
       "    85         1          8.0      8.0      0.0      R = C[are_Testable]\n",
       "    86         1          3.0      3.0      0.0      R_Env = Env[are_Testable]\n",
       "    87         1         31.0     31.0      0.0      Keep = (Prunable * (1 - are_Testable) + Too_Large) == 0\n",
       "    88                                               \n",
       "    89         1          3.0      3.0      0.0      if verbose:\n",
       "    90                                                   messages(are_Testable, nNodes, Keep, Too_Large, Prunable, k0)\n",
       "    91                                               \n",
       "    92         1          5.0      5.0      0.0      C = C[Keep]\n",
       "    93                                               \n",
       "    94                                               # We then explore all subgraphs of size 2 and so on and so forth\n",
       "    95         4         15.0      3.8      0.0      while C.shape[0] > 0:\n",
       "    96         4         12.0      3.0      0.0          if k0 > kmax:\n",
       "    97                                                       if verbose:\n",
       "    98                                                           print('Reached kmax value')\n",
       "    99                                                       break\n",
       "   100                                                   # Compute all the parents\n",
       "   101         4        476.0    119.0      0.0          chunks = np.array_split(C, threads)\n",
       "   102         4       2273.0    568.2      0.0          Parents = Parallel(n_jobs=threads, backend = backend, verbose = 1)(\n",
       "   103         4   15063521.0 3765880.2     84.7                  delayed(expand)(chunk, G, TH, n1s, n2s, Tb) for chunk in chunks)\n",
       "   104         4        736.0    184.0      0.0          Parents = np.concatenate(Parents)\n",
       "   105         4         26.0      6.5      0.0          if Parents.shape[0] == 0:\n",
       "   106         1          3.0      3.0      0.0              break\n",
       "   107         3        461.0    153.7      0.0          Explored = np.zeros(Parents.shape[0], dtype = np.bool)\n",
       "   108                                                   # Prune the redundants via the itemtable\n",
       "   109      1948       4731.0      2.4      0.0          for i, S in enumerate(Parents):\n",
       "   110      1945      49410.0     25.4      0.3              explored = Tb.check_table(max(S.nodes), S.ys)\n",
       "   111      1945       4247.0      2.2      0.0              if not explored:\n",
       "   112      1034      14641.0     14.2      0.1                  Tb.add_table(max(S.nodes), S.ys)\n",
       "   113      1945       4768.0      2.5      0.0              Explored[i] = explored\n",
       "   114                                                   \n",
       "   115                                                   # Update the set of closed subgraphs we explore after removing the\n",
       "   116                                                   # redundants\n",
       "   117         3        466.0    155.3      0.0          C =  Parents[Explored == False]\n",
       "   118                                                   \n",
       "   119         3        708.0    236.0      0.0          chunks = np.array_split(C, threads)\n",
       "   120         3       1785.0    595.0      0.0          Env = Parallel(n_jobs=threads, backend = backend, verbose = 0)(\n",
       "   121         3     514303.0 171434.3      2.9                         delayed(compute_envelopes)(chunk) for chunk in chunks)\n",
       "   122         3        292.0     97.3      0.0          Env = np.concatenate(Env)\n",
       "   123         3       2632.0    877.3      0.0          Prunable = Parallel(n_jobs=threads, backend = backend, verbose = 0)(\n",
       "   124         3     538899.0 179633.0      3.0                              delayed(are_prunable)(chunk) for chunk in chunks)\n",
       "   125         3        246.0     82.0      0.0          Prunable = np.concatenate(Prunable)\n",
       "   126         3       2404.0    801.3      0.0          Too_Large = Parallel(n_jobs=threads, backend = backend, verbose = 0)(\n",
       "   127         3     514046.0 171348.7      2.9                          delayed(are_too_large)(chunk, Lmax) for chunk in chunks)\n",
       "   128         3        176.0     58.7      0.0          Too_Large = np.concatenate(Too_Large)\n",
       "   129                                                   \n",
       "   130         3      17922.0   5974.0      0.1          k0, TH = find_ko(np.concatenate([Env, R_Env]), alpha, k0)\n",
       "   131                                                   \n",
       "   132         3         69.0     23.0      0.0          are_Testable = Env >= TH\n",
       "   133         3        889.0    296.3      0.0          R = np.concatenate([R[R_Env >= TH], C[are_Testable]])\n",
       "   134         3        140.0     46.7      0.0          R_Env = np.concatenate([R_Env[R_Env >= TH], Env[are_Testable]])\n",
       "   135         3         82.0     27.3      0.0          Keep = (Prunable * (1 - are_Testable) + Too_Large) == 0\n",
       "   136                                                   \n",
       "   137         3          8.0      2.7      0.0          if verbose:\n",
       "   138                                                       messages(are_Testable, C.shape[0], Keep, Too_Large, Prunable, k0)\n",
       "   139         3         24.0      8.0      0.0          C = C[Keep]\n",
       "   140                                                   \n",
       "   141                                               # We have finished and we return the testable graphs\n",
       "   142         1          3.0      3.0      0.0      return R, R_Env, k0, TH\n",
       "\n",
       "Total time: 1.1e-05 s\n",
       "File: /Users/hector/Documents/BGWAS2/dbgwas_docker/Tarone/scripts/Helper_Explo.py\n",
       "Function: __init__ at line 138\n",
       "\n",
       "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
       "==============================================================\n",
       "   138                                               def __init__(self, Pop, neighbours, nodes, pheno, lengths):\n",
       "   139         1          5.0      5.0     45.5          self.Pop = Pop\n",
       "   140         1          2.0      2.0     18.2          self.neighbours = neighbours\n",
       "   141         1          1.0      1.0      9.1          self.pattern = nodes\n",
       "   142         1          1.0      1.0      9.1          self.Pheno = pheno\n",
       "   143         1          2.0      2.0     18.2          self.lengths = lengths\n",
       "\n",
       "Total time: 0.00132 s\n",
       "File: /Users/hector/Documents/BGWAS2/dbgwas_docker/Tarone/scripts/Helper_Explo.py\n",
       "Function: ns at line 145\n",
       "\n",
       "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
       "==============================================================\n",
       "   145                                               def ns(self):\n",
       "   146                                                   # We have k groups\n",
       "   147                                                   # We returns two vectors of length k with the number of sample in each\n",
       "   148                                                   # group, split by phenotype.\n",
       "   149         1        140.0    140.0     10.6          clusters = np.unique(self.Pop)\n",
       "   150         1          3.0      3.0      0.2          clusters.sort()\n",
       "   151         1          9.0      9.0      0.7          n1s = np.zeros(len(clusters))\n",
       "   152         1          4.0      4.0      0.3          n2s = np.zeros(len(clusters))\n",
       "   153                                                   \n",
       "   154         2          8.0      4.0      0.6          for clus in clusters:\n",
       "   155         1         67.0     67.0      5.1              n1s[clus] = sum(self.Pheno[self.Pop == clus])\n",
       "   156         1       1088.0   1088.0     82.4              n2s[clus] = sum(self.Pop == clus) - n1s[clus]\n",
       "   157                                                   \n",
       "   158         1          1.0      1.0      0.1          return n1s, n2s\n",
       "\n",
       "Total time: 0.026404 s\n",
       "File: /Users/hector/Documents/BGWAS2/dbgwas_docker/Tarone/scripts/Helper_Tarone.py\n",
       "Function: find_ko at line 64\n",
       "\n",
       "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
       "==============================================================\n",
       "    64                                           def find_ko(min_ps, alpha, k = 1):\n",
       "    65                                               \"\"\"Compute the k0 according to the method in Terada et al\n",
       "    66                                               \n",
       "    67                                               Args:\n",
       "    68                                                   min_ps: The list of minimal p-values\n",
       "    69                                                   alpha: The threshold for controlling the FWER\n",
       "    70                                                   k: the previous value of k0 computed on a smaller set. Default to 1\n",
       "    71                                           \n",
       "    72                                               Return:\n",
       "    73                                                   The k0 value and associated cutoff for the Chi-square test\n",
       "    74                                               \"\"\"\n",
       "    75         5        864.0    172.8      3.3      sortedMinP = -np.sort(-min_ps)\n",
       "    76         5         17.0      3.4      0.1      N = min_ps.shape[0]\n",
       "    77         5          5.0      1.0      0.0      a = k - 1\n",
       "    78         5          2.0      0.4      0.0      b = N\n",
       "    79        35         40.0      1.1      0.2      while b - a > 1:\n",
       "    80        30         99.0      3.3      0.4          mid = int((a + b) / 2)\n",
       "    81        30      22799.0    760.0     86.3          TH = chi2.isf(alpha / (mid + 1), 1)\n",
       "    82        30        105.0      3.5      0.4          if sortedMinP[mid] >= TH:\n",
       "    83        25         18.0      0.7      0.1              a = mid \n",
       "    84                                                   else:\n",
       "    85         5          4.0      0.8      0.0              b = mid\n",
       "    86         5          3.0      0.6      0.0      k0 = a + 1\n",
       "    87         5       2440.0    488.0      9.2      TH = chi2.isf(alpha / k0, 1)\n",
       "    88         5          8.0      1.6      0.0      return k0, TH\n",
       "\n",
       "Total time: 9.8e-05 s\n",
       "File: /Users/hector/Documents/BGWAS2/dbgwas_docker/Tarone/scripts/ItemTable.py\n",
       "Function: __init__ at line 6\n",
       "\n",
       "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
       "==============================================================\n",
       "     6                                               def __init__(self, nNodes):\n",
       "     7         1         97.0     97.0     99.0          self.dict = {k: set() for k in range(nNodes)}\n",
       "     8         1          1.0      1.0      1.0          return\n",
       "\n",
       "Total time: 0.02522 s\n",
       "File: /Users/hector/Documents/BGWAS2/dbgwas_docker/Tarone/scripts/ItemTable.py\n",
       "Function: check_table at line 10\n",
       "\n",
       "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
       "==============================================================\n",
       "    10                                               def check_table(self, max_node, pattern):\n",
       "    11      1945        899.0      0.5      3.6          explored = False\n",
       "    12      1945      15760.0      8.1     62.5          max_pattern = tuple(pattern)\n",
       "    13      1945       7356.0      3.8     29.2          if max_pattern in self.dict[max_node]:\n",
       "    14       911        408.0      0.4      1.6              explored = True\n",
       "    15      1945        797.0      0.4      3.2          return explored\n",
       "\n",
       "Total time: 0.01226 s\n",
       "File: /Users/hector/Documents/BGWAS2/dbgwas_docker/Tarone/scripts/ItemTable.py\n",
       "Function: add_table at line 17\n",
       "\n",
       "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
       "==============================================================\n",
       "    17                                               def add_table(self, max_node, pattern):\n",
       "    18      1134       7957.0      7.0     64.9          max_pattern = tuple(pattern)\n",
       "    19      1134       3802.0      3.4     31.0          self.dict[max_node].add(max_pattern)\n",
       "    20      1134        501.0      0.4      4.1          return\n",
       "\n",
       "Total time: 0.003565 s\n",
       "File: /usr/local/lib/python3.7/site-packages/joblib/parallel.py\n",
       "Function: delayed at line 295\n",
       "\n",
       "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
       "==============================================================\n",
       "   295                                           def delayed(function, check_pickle=None):\n",
       "   296                                               \"\"\"Decorator used to capture the arguments of a function.\"\"\"\n",
       "   297        34         54.0      1.6      1.5      if check_pickle is not None:\n",
       "   298                                                   warnings.warn('check_pickle is deprecated in joblib 0.12 and will be'\n",
       "   299                                                                 ' removed in 0.13', DeprecationWarning)\n",
       "   300                                               # Try to pickle the input function, to catch the problems early when\n",
       "   301                                               # using with multiprocessing:\n",
       "   302        34         45.0      1.3      1.3      if check_pickle:\n",
       "   303                                                   dumps(function)\n",
       "   304                                           \n",
       "   305        34        245.0      7.2      6.9      def delayed_function(*args, **kwargs):\n",
       "   306                                                   return function, args, kwargs\n",
       "   307        34         26.0      0.8      0.7      try:\n",
       "   308        34       3157.0     92.9     88.6          delayed_function = functools.wraps(function)(delayed_function)\n",
       "   309                                               except AttributeError:\n",
       "   310                                                   \" functools.wraps fails on some callable objects \"\n",
       "   311        34         38.0      1.1      1.1      return delayed_function\n",
       "\n",
       "Total time: 0.01025 s\n",
       "File: /usr/local/lib/python3.7/site-packages/joblib/parallel.py\n",
       "Function: __init__ at line 615\n",
       "\n",
       "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
       "==============================================================\n",
       "   615                                               def __init__(self, n_jobs=None, backend=None, verbose=0, timeout=None,\n",
       "   616                                                            pre_dispatch='2 * n_jobs', batch_size='auto',\n",
       "   617                                                            temp_folder=None, max_nbytes='1M', mmap_mode='r',\n",
       "   618                                                            prefer=None, require=None):\n",
       "   619        17         62.0      3.6      0.6          active_backend, context_n_jobs = get_active_backend(\n",
       "   620        17       1377.0     81.0     13.4              prefer=prefer, require=require, verbose=verbose)\n",
       "   621        17         64.0      3.8      0.6          nesting_level = active_backend.nesting_level\n",
       "   622        17         26.0      1.5      0.3          if backend is None and n_jobs is None:\n",
       "   623                                                       # If we are under a parallel_backend context manager, look up\n",
       "   624                                                       # the default number of jobs and use that instead:\n",
       "   625                                                       n_jobs = context_n_jobs\n",
       "   626        17         21.0      1.2      0.2          if n_jobs is None:\n",
       "   627                                                       # No specific context override and no specific value request:\n",
       "   628                                                       # default to 1.\n",
       "   629                                                       n_jobs = 1\n",
       "   630        17       1037.0     61.0     10.1          self.n_jobs = n_jobs\n",
       "   631        17         43.0      2.5      0.4          self.verbose = verbose\n",
       "   632        17         29.0      1.7      0.3          self.timeout = timeout\n",
       "   633        17         23.0      1.4      0.2          self.pre_dispatch = pre_dispatch\n",
       "   634        17       1889.0    111.1     18.4          self._ready_batches = queue.Queue()\n",
       "   635                                           \n",
       "   636        17         36.0      2.1      0.4          if isinstance(max_nbytes, _basestring):\n",
       "   637        17        668.0     39.3      6.5              max_nbytes = memstr_to_bytes(max_nbytes)\n",
       "   638                                           \n",
       "   639        17         27.0      1.6      0.3          self._backend_args = dict(\n",
       "   640        17         20.0      1.2      0.2              max_nbytes=max_nbytes,\n",
       "   641        17         29.0      1.7      0.3              mmap_mode=mmap_mode,\n",
       "   642        17         30.0      1.8      0.3              temp_folder=temp_folder,\n",
       "   643        17         21.0      1.2      0.2              prefer=prefer,\n",
       "   644        17         21.0      1.2      0.2              require=require,\n",
       "   645        17        126.0      7.4      1.2              verbose=max(0, self.verbose - 50),\n",
       "   646                                                   )\n",
       "   647        17         44.0      2.6      0.4          if DEFAULT_MP_CONTEXT is not None:\n",
       "   648                                                       self._backend_args['context'] = DEFAULT_MP_CONTEXT\n",
       "   649        17        496.0     29.2      4.8          elif hasattr(mp, \"get_context\"):\n",
       "   650        17        183.0     10.8      1.8              self._backend_args['context'] = mp.get_context()\n",
       "   651                                           \n",
       "   652        17         21.0      1.2      0.2          if backend is None:\n",
       "   653                                                       backend = active_backend\n",
       "   654                                           \n",
       "   655        17       1864.0    109.6     18.2          elif isinstance(backend, ParallelBackendBase):\n",
       "   656                                                       # Use provided backend as is, with the current nesting_level if it\n",
       "   657                                                       # is not set yet.\n",
       "   658                                                       if backend.nesting_level is None:\n",
       "   659                                                           backend.nesting_level = nesting_level\n",
       "   660                                           \n",
       "   661        17        143.0      8.4      1.4          elif hasattr(backend, 'Pool') and hasattr(backend, 'Lock'):\n",
       "   662                                                       # Make it possible to pass a custom multiprocessing context as\n",
       "   663                                                       # backend to change the start method to forkserver or spawn or\n",
       "   664                                                       # preload modules on the forkserver helper process.\n",
       "   665                                                       self._backend_args['context'] = backend\n",
       "   666                                                       backend = MultiprocessingBackend(nesting_level=nesting_level)\n",
       "   667                                                   else:\n",
       "   668        17         24.0      1.4      0.2              try:\n",
       "   669        17         38.0      2.2      0.4                  backend_factory = BACKENDS[backend]\n",
       "   670                                                       except KeyError:\n",
       "   671                                                           raise ValueError(\"Invalid backend: %s, expected one of %r\"\n",
       "   672                                                                            % (backend, sorted(BACKENDS.keys())))\n",
       "   673        17        241.0     14.2      2.4              backend = backend_factory(nesting_level=nesting_level)\n",
       "   674                                           \n",
       "   675        17         28.0      1.6      0.3          if (require == 'sharedmem' and\n",
       "   676                                                           not getattr(backend, 'supports_sharedmem', False)):\n",
       "   677                                                       raise ValueError(\"Backend %s does not support shared memory\"\n",
       "   678                                                                        % backend)\n",
       "   679                                           \n",
       "   680        17         22.0      1.3      0.2          if (batch_size == 'auto' or isinstance(batch_size, Integral) and\n",
       "   681                                                           batch_size > 0):\n",
       "   682        17         30.0      1.8      0.3              self.batch_size = batch_size\n",
       "   683                                                   else:\n",
       "   684                                                       raise ValueError(\n",
       "   685                                                           \"batch_size must be 'auto' or a positive integer, got: %r\"\n",
       "   686                                                           % batch_size)\n",
       "   687                                           \n",
       "   688        17         25.0      1.5      0.2          self._backend = backend\n",
       "   689        17         22.0      1.3      0.2          self._output = None\n",
       "   690        17         35.0      2.1      0.3          self._jobs = list()\n",
       "   691        17         38.0      2.2      0.4          self._managed_backend = False\n",
       "   692                                           \n",
       "   693                                                   # This lock is used coordinate the main thread of this process with\n",
       "   694                                                   # the async callback thread of our the pool.\n",
       "   695        17       1447.0     85.1     14.1          self._lock = threading.RLock()\n",
       "\n",
       "Total time: 1.3574 s\n",
       "File: /usr/local/lib/python3.7/site-packages/joblib/parallel.py\n",
       "Function: _initialize_backend at line 706\n",
       "\n",
       "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
       "==============================================================\n",
       "   706                                               def _initialize_backend(self):\n",
       "   707                                                   \"\"\"Build a process or thread pool and return the number of workers\"\"\"\n",
       "   708        17         12.0      0.7      0.0          try:\n",
       "   709        17        748.0     44.0      0.1              n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,\n",
       "   710        17    1356005.0  79765.0     99.9                                               **self._backend_args)\n",
       "   711        17        611.0     35.9      0.0              if self.timeout is not None and not self._backend.supports_timeout:\n",
       "   712                                                           warnings.warn(\n",
       "   713                                                               'The backend class {!r} does not support timeout. '\n",
       "   714                                                               \"You have set 'timeout={}' in Parallel but \"\n",
       "   715                                                               \"the 'timeout' parameter will not be used.\".format(\n",
       "   716                                                                   self._backend.__class__.__name__,\n",
       "   717                                                                   self.timeout))\n",
       "   718                                           \n",
       "   719                                                   except FallbackToBackend as e:\n",
       "   720                                                       # Recursively initialize the backend in case of requested fallback.\n",
       "   721                                                       self._backend = e.backend\n",
       "   722                                                       n_jobs = self._initialize_backend()\n",
       "   723                                           \n",
       "   724        17         23.0      1.4      0.0          return n_jobs\n",
       "\n",
       "Total time: 1.14923 s\n",
       "File: /usr/local/lib/python3.7/site-packages/joblib/parallel.py\n",
       "Function: _terminate_backend at line 731\n",
       "\n",
       "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
       "==============================================================\n",
       "   731                                               def _terminate_backend(self):\n",
       "   732        17         12.0      0.7      0.0          if self._backend is not None:\n",
       "   733        17    1149221.0  67601.2    100.0              self._backend.terminate()\n",
       "\n",
       "Total time: 0.005025 s\n",
       "File: /usr/local/lib/python3.7/site-packages/joblib/parallel.py\n",
       "Function: _dispatch at line 735\n",
       "\n",
       "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
       "==============================================================\n",
       "   735                                               def _dispatch(self, batch):\n",
       "   736                                                   \"\"\"Queue the batch for computing, with or without multiprocessing\n",
       "   737                                           \n",
       "   738                                                   WARNING: this method is not thread-safe: it should be only called\n",
       "   739                                                   indirectly via dispatch_one_batch.\n",
       "   740                                           \n",
       "   741                                                   \"\"\"\n",
       "   742                                                   # If job.get() catches an exception, it closes the queue:\n",
       "   743        34        232.0      6.8      4.6          if self._aborting:\n",
       "   744                                                       return\n",
       "   745                                           \n",
       "   746        34        112.0      3.3      2.2          self.n_dispatched_tasks += len(batch)\n",
       "   747        34         50.0      1.5      1.0          self.n_dispatched_batches += 1\n",
       "   748                                           \n",
       "   749        34         91.0      2.7      1.8          dispatch_timestamp = time.time()\n",
       "   750        34        476.0     14.0      9.5          cb = BatchCompletionCallBack(dispatch_timestamp, len(batch), self)\n",
       "   751        34         99.0      2.9      2.0          with self._lock:\n",
       "   752        34         68.0      2.0      1.4              job_idx = len(self._jobs)\n",
       "   753        34       3597.0    105.8     71.6              job = self._backend.apply_async(batch, callback=cb)\n",
       "   754                                                       # A job can complete so quickly than its callback is\n",
       "   755                                                       # called before we get here, causing self._jobs to\n",
       "   756                                                       # grow. To ensure correct results ordering, .insert is\n",
       "   757                                                       # used (rather than .append) in the following line\n",
       "   758        34        300.0      8.8      6.0              self._jobs.insert(job_idx, job)\n",
       "\n",
       "Total time: 0.022009 s\n",
       "File: /usr/local/lib/python3.7/site-packages/joblib/parallel.py\n",
       "Function: dispatch_one_batch at line 772\n",
       "\n",
       "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
       "==============================================================\n",
       "   772                                               def dispatch_one_batch(self, iterator):\n",
       "   773                                                   \"\"\"Prefetch the tasks for the next batch and dispatch them.\n",
       "   774                                           \n",
       "   775                                                   The effective size of the batch is computed here.\n",
       "   776                                                   If there are no more jobs to dispatch, return False, else return True.\n",
       "   777                                           \n",
       "   778                                                   The iterator consumption and dispatching is protected by the same\n",
       "   779                                                   lock so calling this function should be thread safe.\n",
       "   780                                           \n",
       "   781                                                   \"\"\"\n",
       "   782        51        186.0      3.6      0.8          if self.batch_size == 'auto':\n",
       "   783        51        878.0     17.2      4.0              batch_size = self._backend.compute_batch_size()\n",
       "   784                                                   else:\n",
       "   785                                                       # Fixed batch size strategy\n",
       "   786                                                       batch_size = self.batch_size\n",
       "   787                                           \n",
       "   788        51        246.0      4.8      1.1          with self._lock:\n",
       "   789                                                       # to ensure an even distribution of the workolad between workers,\n",
       "   790                                                       # we look ahead in the original iterators more than batch_size\n",
       "   791                                                       # tasks - However, we keep consuming only one batch at each\n",
       "   792                                                       # dispatch_one_batch call. The extra tasks are stored in a local\n",
       "   793                                                       # queue, _ready_batches, that is looked-up prior to re-consuming\n",
       "   794                                                       # tasks from the origal iterator.\n",
       "   795        51         55.0      1.1      0.2              try:\n",
       "   796        51       1683.0     33.0      7.6                  tasks = self._ready_batches.get(block=False)\n",
       "   797        34        191.0      5.6      0.9              except queue.Empty:\n",
       "   798                                                           # slice the iterator n_jobs * batchsize items at a time. If the\n",
       "   799                                                           # slice returns less than that, then the current batchsize puts\n",
       "   800                                                           # too much weight on a subset of workers, while other may end\n",
       "   801                                                           # up starving. So in this case, re-scale the batch size\n",
       "   802                                                           # accordingly to distribute evenly the last items between all\n",
       "   803                                                           # workers.\n",
       "   804        34        688.0     20.2      3.1                  n_jobs = self._cached_effective_n_jobs\n",
       "   805        34         62.0      1.8      0.3                  big_batch_size = batch_size * n_jobs\n",
       "   806                                           \n",
       "   807        34       6094.0    179.2     27.7                  islice = list(itertools.islice(iterator, big_batch_size))\n",
       "   808        34         59.0      1.7      0.3                  if len(islice) == 0:\n",
       "   809        17         41.0      2.4      0.2                      return False\n",
       "   810        17         28.0      1.6      0.1                  elif (iterator is self._original_iterator\n",
       "   811                                                                 and len(islice) < big_batch_size):\n",
       "   812                                                               # We reached the end of the original iterator (unless\n",
       "   813                                                               # iterator is the ``pre_dispatch``-long initial slice of\n",
       "   814                                                               # the original iterator) -- decrease the batch size to\n",
       "   815                                                               # account for potential variance in the batches running\n",
       "   816                                                               # time.\n",
       "   817                                                               final_batch_size = max(1, len(islice) // (10 * n_jobs))\n",
       "   818                                                           else:\n",
       "   819        17         58.0      3.4      0.3                      final_batch_size = max(1, len(islice) // n_jobs)\n",
       "   820                                           \n",
       "   821                                                           # enqueue n_jobs batches in a local queue\n",
       "   822        51        141.0      2.8      0.6                  for i in range(0, len(islice), final_batch_size):\n",
       "   823        34        343.0     10.1      1.6                      tasks = BatchedCalls(islice[i:i + final_batch_size],\n",
       "   824        34       1019.0     30.0      4.6                                           self._backend.get_nested_backend(),\n",
       "   825        34       1310.0     38.5      6.0                                           self._pickle_cache)\n",
       "   826        34       1544.0     45.4      7.0                      self._ready_batches.put(tasks)\n",
       "   827                                           \n",
       "   828                                                           # finally, get one task.\n",
       "   829        17       1076.0     63.3      4.9                  tasks = self._ready_batches.get(block=False)\n",
       "   830        34        224.0      6.6      1.0              if len(tasks) == 0:\n",
       "   831                                                           # No more tasks available in the iterator: tell caller to stop.\n",
       "   832                                                           return False\n",
       "   833                                                       else:\n",
       "   834        34       5970.0    175.6     27.1                  self._dispatch(tasks)\n",
       "   835        34        113.0      3.3      0.5                  return True\n",
       "\n",
       "Total time: 0.00668 s\n",
       "File: /usr/local/lib/python3.7/site-packages/joblib/parallel.py\n",
       "Function: _print at line 837\n",
       "\n",
       "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
       "==============================================================\n",
       "   837                                               def _print(self, msg, msg_args):\n",
       "   838                                                   \"\"\"Display the message on stout or stderr depending on verbosity\"\"\"\n",
       "   839                                                   # XXX: Not using the logger framework: need to\n",
       "   840                                                   # learn to use logger better.\n",
       "   841        34        321.0      9.4      4.8          if not self.verbose:\n",
       "   842        24         21.0      0.9      0.3              return\n",
       "   843        10         14.0      1.4      0.2          if self.verbose < 50:\n",
       "   844        10        106.0     10.6      1.6              writer = sys.stderr.write\n",
       "   845                                                   else:\n",
       "   846                                                       writer = sys.stdout.write\n",
       "   847        10         86.0      8.6      1.3          msg = msg % msg_args\n",
       "   848        10       6132.0    613.2     91.8          writer('[%s]: %s\\n' % (self, msg))\n",
       "\n",
       "Total time: 15.0832 s\n",
       "File: /usr/local/lib/python3.7/site-packages/joblib/parallel.py\n",
       "Function: retrieve at line 893\n",
       "\n",
       "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
       "==============================================================\n",
       "   893                                               def retrieve(self):\n",
       "   894        17        162.0      9.5      0.0          self._output = list()\n",
       "   895        51        191.0      3.7      0.0          while self._iterating or len(self._jobs) > 0:\n",
       "   896        34         60.0      1.8      0.0              if len(self._jobs) == 0:\n",
       "   897                                                           # Wait for an async callback to dispatch new jobs\n",
       "   898                                                           time.sleep(0.01)\n",
       "   899                                                           continue\n",
       "   900                                                       # We need to be careful: the job list can be filling up as\n",
       "   901                                                       # we empty it and Python list are not thread-safe by default hence\n",
       "   902                                                       # the use of the lock\n",
       "   903        34        100.0      2.9      0.0              with self._lock:\n",
       "   904        34        198.0      5.8      0.0                  job = self._jobs.pop(0)\n",
       "   905                                           \n",
       "   906        34         39.0      1.1      0.0              try:\n",
       "   907        34         81.0      2.4      0.0                  if getattr(self._backend, 'supports_timeout', False):\n",
       "   908        34   15082418.0 443600.5    100.0                      self._output.extend(job.get(timeout=self.timeout))\n",
       "   909                                                           else:\n",
       "   910                                                               self._output.extend(job.get())\n",
       "   911                                           \n",
       "   912                                                       except BaseException as exception:\n",
       "   913                                                           # Note: we catch any BaseException instead of just Exception\n",
       "   914                                                           # instances to also include KeyboardInterrupt.\n",
       "   915                                           \n",
       "   916                                                           # Stop dispatching any new job in the async callback thread\n",
       "   917                                                           self._aborting = True\n",
       "   918                                           \n",
       "   919                                                           # If the backend allows it, cancel or kill remaining running\n",
       "   920                                                           # tasks without waiting for the results as we will raise\n",
       "   921                                                           # the exception we got back to the caller instead of returning\n",
       "   922                                                           # any result.\n",
       "   923                                                           backend = self._backend\n",
       "   924                                                           if (backend is not None and\n",
       "   925                                                                   hasattr(backend, 'abort_everything')):\n",
       "   926                                                               # If the backend is managed externally we need to make sure\n",
       "   927                                                               # to leave it in a working state to allow for future jobs\n",
       "   928                                                               # scheduling.\n",
       "   929                                                               ensure_ready = self._managed_backend\n",
       "   930                                                               backend.abort_everything(ensure_ready=ensure_ready)\n",
       "   931                                           \n",
       "   932                                                           if isinstance(exception, TransportableException):\n",
       "   933                                                               # Capture exception to add information on the local\n",
       "   934                                                               # stack in addition to the distant stack\n",
       "   935                                                               this_report = format_outer_frames(context=10,\n",
       "   936                                                                                                 stack_start=1)\n",
       "   937                                                               raise exception.unwrap(this_report)\n",
       "   938                                                           else:\n",
       "   939                                                               raise\n",
       "\n",
       "Total time: 17.6378 s\n",
       "File: /usr/local/lib/python3.7/site-packages/joblib/parallel.py\n",
       "Function: __call__ at line 941\n",
       "\n",
       "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
       "==============================================================\n",
       "   941                                               def __call__(self, iterable):\n",
       "   942        17         33.0      1.9      0.0          if self._jobs:\n",
       "   943                                                       raise ValueError('This Parallel instance is already running')\n",
       "   944                                                   # A flag used to abort the dispatching of jobs in case an\n",
       "   945                                                   # exception is found\n",
       "   946        17         25.0      1.5      0.0          self._aborting = False\n",
       "   947                                           \n",
       "   948        17         19.0      1.1      0.0          if not self._managed_backend:\n",
       "   949        17    1358703.0  79923.7      7.7              n_jobs = self._initialize_backend()\n",
       "   950                                                   else:\n",
       "   951                                                       n_jobs = self._effective_n_jobs()\n",
       "   952                                           \n",
       "   953                                                   # self._effective_n_jobs should be called in the Parallel.__call__\n",
       "   954                                                   # thread only -- store its value in an attribute for further queries.\n",
       "   955        17        292.0     17.2      0.0          self._cached_effective_n_jobs = n_jobs\n",
       "   956                                           \n",
       "   957        17        413.0     24.3      0.0          backend_name = self._backend.__class__.__name__\n",
       "   958        17         30.0      1.8      0.0          if n_jobs == 0:\n",
       "   959                                                       raise RuntimeError(\"%s has no active worker.\" % backend_name)\n",
       "   960                                           \n",
       "   961        17        117.0      6.9      0.0          self._print(\"Using backend %s with %d concurrent workers.\",\n",
       "   962        17       6249.0    367.6      0.0                      (backend_name, n_jobs))\n",
       "   963        17        371.0     21.8      0.0          if hasattr(self._backend, 'start_call'):\n",
       "   964        17        362.0     21.3      0.0              self._backend.start_call()\n",
       "   965        17        109.0      6.4      0.0          iterator = iter(iterable)\n",
       "   966        17         61.0      3.6      0.0          pre_dispatch = self.pre_dispatch\n",
       "   967                                           \n",
       "   968        17         52.0      3.1      0.0          if pre_dispatch == 'all' or n_jobs == 1:\n",
       "   969                                                       # prevent further dispatch via multiprocessing callback thread\n",
       "   970                                                       self._original_iterator = None\n",
       "   971                                                       self._pre_dispatch_amount = 0\n",
       "   972                                                   else:\n",
       "   973        17         45.0      2.6      0.0              self._original_iterator = iterator\n",
       "   974        17        110.0      6.5      0.0              if hasattr(pre_dispatch, 'endswith'):\n",
       "   975        17       5714.0    336.1      0.0                  pre_dispatch = eval(pre_dispatch)\n",
       "   976        17        101.0      5.9      0.0              self._pre_dispatch_amount = pre_dispatch = int(pre_dispatch)\n",
       "   977                                           \n",
       "   978                                                       # The main thread will consume the first pre_dispatch items and\n",
       "   979                                                       # the remaining items will later be lazily dispatched by async\n",
       "   980                                                       # callbacks upon task completions.\n",
       "   981                                           \n",
       "   982                                                       # TODO: this iterator should be batch_size * n_jobs\n",
       "   983        17        446.0     26.2      0.0              iterator = itertools.islice(iterator, self._pre_dispatch_amount)\n",
       "   984                                           \n",
       "   985        17        456.0     26.8      0.0          self._start_time = time.time()\n",
       "   986        17         67.0      3.9      0.0          self.n_dispatched_batches = 0\n",
       "   987        17         27.0      1.6      0.0          self.n_dispatched_tasks = 0\n",
       "   988        17         28.0      1.6      0.0          self.n_completed_tasks = 0\n",
       "   989                                                   # Use a caching dict for callables that are pickled with cloudpickle to\n",
       "   990                                                   # improve performances. This cache is used only in the case of\n",
       "   991                                                   # functions that are defined in the __main__ module, functions that are\n",
       "   992                                                   # defined locally (inside another function) and lambda expressions.\n",
       "   993        17        226.0     13.3      0.0          self._pickle_cache = dict()\n",
       "   994        17         43.0      2.5      0.0          try:\n",
       "   995                                                       # Only set self._iterating to True if at least a batch\n",
       "   996                                                       # was dispatched. In particular this covers the edge\n",
       "   997                                                       # case of Parallel used with an exhausted iterator. If\n",
       "   998                                                       # self._original_iterator is None, then this means either\n",
       "   999                                                       # that pre_dispatch == \"all\", n_jobs == 1 or that the first batch\n",
       "  1000                                                       # was very quick and its callback already dispatched all the\n",
       "  1001                                                       # remaining jobs.\n",
       "  1002        17        145.0      8.5      0.0              self._iterating = False\n",
       "  1003        17      19382.0   1140.1      0.1              if self.dispatch_one_batch(iterator):\n",
       "  1004        17         34.0      2.0      0.0                  self._iterating = self._original_iterator is not None\n",
       "  1005                                           \n",
       "  1006        34       4961.0    145.9      0.0              while self.dispatch_one_batch(iterator):\n",
       "  1007        17         33.0      1.9      0.0                  pass\n",
       "  1008                                           \n",
       "  1009        17         26.0      1.5      0.0              if pre_dispatch == \"all\" or n_jobs == 1:\n",
       "  1010                                                           # The iterable was consumed all at once by the above for loop.\n",
       "  1011                                                           # No need to wait for async callbacks to trigger to\n",
       "  1012                                                           # consumption.\n",
       "  1013                                                           self._iterating = False\n",
       "  1014                                           \n",
       "  1015        17       2085.0    122.6      0.0              with self._backend.retrieval_context():\n",
       "  1016        17   15084957.0 887350.4     85.5                  self.retrieve()\n",
       "  1017                                                       # Make sure that we get a last message telling us we are done\n",
       "  1018        17         72.0      4.2      0.0              elapsed_time = time.time() - self._start_time\n",
       "  1019        17         24.0      1.4      0.0              self._print('Done %3i out of %3i | elapsed: %s finished',\n",
       "  1020        17         38.0      2.2      0.0                          (len(self._output), len(self._output),\n",
       "  1021        17       1935.0    113.8      0.0                           short_format_time(elapsed_time)))\n",
       "  1022                                                   finally:\n",
       "  1023        17         76.0      4.5      0.0              if hasattr(self._backend, 'stop_call'):\n",
       "  1024        17         61.0      3.6      0.0                  self._backend.stop_call()\n",
       "  1025        17         18.0      1.1      0.0              if not self._managed_backend:\n",
       "  1026        17    1149594.0  67623.2      6.5                  self._terminate_backend()\n",
       "  1027        17        102.0      6.0      0.0              self._jobs = list()\n",
       "  1028        17         45.0      2.6      0.0              self._pickle_cache = None\n",
       "  1029        17         25.0      1.5      0.0          output = self._output\n",
       "  1030        17         25.0      1.5      0.0          self._output = None\n",
       "  1031        17         20.0      1.2      0.0          return output\n",
       "\n",
       "Total time: 0.000112 s\n",
       "File: /usr/local/lib/python3.7/site-packages/joblib/parallel.py\n",
       "Function: __repr__ at line 1033\n",
       "\n",
       "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
       "==============================================================\n",
       "  1033                                               def __repr__(self):\n",
       "  1034        10        112.0     11.2    100.0          return '%s(n_jobs=%s)' % (self.__class__.__name__, self.n_jobs)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%lprun -m ExploreBFS -s speed.BFS_Run(2, 100, backend = \"multiprocessing\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check with N=500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.6s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:   16.5s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:   22.5s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    3.2s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Timer unit: 1e-06 s\n",
       "\n",
       "Total time: 5.07208 s\n",
       "File: /Users/hector/Documents/BGWAS2/dbgwas_docker/Tarone/scripts/Envelope.py\n",
       "Function: minimal_p_value at line 21\n",
       "\n",
       "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
       "==============================================================\n",
       "    21                                           def minimal_p_value(xs, n1s, n2s):\n",
       "    22                                               \"\"\"Given the frequencies in the various populations, compute the minimal p-value.\"\"\"\n",
       "    23                                               \"\"\"xs - An array of frequencies, one dimension\"\"\"\n",
       "    24                                               \"\"\"n1s - An array of population size among the first group, one dimension\"\"\"\n",
       "    25                                               \"\"\"n2s - An array of population size among the second group, one dimension\"\"\"\n",
       "    26                                           \n",
       "    27     97440     192962.0      2.0      3.8      ns = n1s + n2s\n",
       "    28     97440     163735.0      1.7      3.2      num = np.multiply(xs, n1s)\n",
       "    29     97440     176915.0      1.8      3.5      num = np.divide(num, ns)\n",
       "    30     97440     981904.0     10.1     19.4      denum = n1s * n2s * xs * (1 - xs / ns) / (ns * (ns - 1))\n",
       "    31     97440     699248.0      7.2     13.8      denum = denum.sum()\n",
       "    32                                               \n",
       "    33     97440     144702.0      1.5      2.9      if denum == 0:\n",
       "    34         2          2.0      1.0      0.0          return 0\n",
       "    35                                               \n",
       "    36     97438     842433.0      8.6     16.6      aMin = np.maximum(0, xs - n2s).sum()\n",
       "    37     97438     436315.0      4.5      8.6      numMin = aMin - num.sum()\n",
       "    38     97438     156418.0      1.6      3.1      numMin = numMin**2\n",
       "    39     97438     548927.0      5.6     10.8      aMax = np.minimum(xs, n1s).sum()\n",
       "    40     97438     395406.0      4.1      7.8      numMax = aMax - num.sum()\n",
       "    41     97438     121437.0      1.2      2.4      numMax = numMax**2\n",
       "    42                                               \n",
       "    43     97438     141230.0      1.4      2.8      num = max(numMin, numMax)\n",
       "    44     97438      70451.0      0.7      1.4      return num / denum\n",
       "\n",
       "Total time: 10.7918 s\n",
       "File: /Users/hector/Documents/BGWAS2/dbgwas_docker/Tarone/scripts/Envelope.py\n",
       "Function: envelope at line 46\n",
       "\n",
       "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
       "==============================================================\n",
       "    46                                           def envelope(xs, n1s, n2s):\n",
       "    47                                               \"\"\"Given the frequencies in the various populations, compute the envelope\"\"\"\n",
       "    48                                               \"\"\"xs - An array of frequencies, one dimension\"\"\"\n",
       "    49                                               \"\"\"n1s - An array of population size among the first group, one dimension\"\"\"\n",
       "    50                                               \"\"\"n2s - An array of population size among the second group, one dimension\"\"\"\n",
       "    51                                           \n",
       "    52     48847     129498.0      2.7      1.2      thresh = xs < np.maximum(n1s, n2s)\n",
       "    53                                               # If were are below the threshold, we do not compute the enveloppe\n",
       "    54                                               # since there will be no prunning anyway\n",
       "    55     48847      92094.0      1.9      0.9      if any(thresh):\n",
       "    56       254      17064.0     67.2      0.2          return minimal_p_value(xs, n1s, n2s)\n",
       "    57                                               \n",
       "    58                                               # Otherwise we can compute the enveloppe\n",
       "    59     48593      84542.0      1.7      0.8      ns = n1s + n2s\n",
       "    60     48593     252561.0      5.2      2.3      betaLs = n1s * xs /(ns ** 2)\n",
       "    61     48593     163123.0      3.4      1.5      betaRs = n2s * xs /(ns ** 2)\n",
       "    62     48593     474251.0      9.8      4.4      piL = np.argsort(betaLs)\n",
       "    63     48593     280155.0      5.8      2.6      piR = np.argsort(betaRs)\n",
       "    64                                           \n",
       "    65     48593     214066.0      4.4      2.0      xStars = ns * 1\n",
       "    66     48593     512377.0     10.5      4.7      pMinLs = np.ones(len(piL,))\n",
       "    67     97186     149919.0      1.5      1.4      for i in range(len(piL)):\n",
       "    68     48593     101736.0      2.1      0.9          xStars[piL[i]] = xs[piL[i]]\n",
       "    69     48593    3255594.0     67.0     30.2          pMinLs[i] = minimal_p_value(xStars, n1s, n2s)\n",
       "    70                                           \n",
       "    71     48593     158701.0      3.3      1.5      xStars = ns * 1\n",
       "    72     48593     426481.0      8.8      4.0      pMinRs = np.ones(len(piR,))\n",
       "    73     97186     121470.0      1.2      1.1      for i in range(len(piR)):\n",
       "    74     48593      85245.0      1.8      0.8          xStars[piR[i]] = xs[piR[i]]\n",
       "    75     48593    2851428.0     58.7     26.4          pMinRs[i] = minimal_p_value(xStars, n1s, n2s)\n",
       "    76                                           \n",
       "    77     48593    1386067.0     28.5     12.8      env = np.append(pMinLs, pMinRs).max()\n",
       "    78     48593      35390.0      0.7      0.3      return env\n",
       "\n",
       "Total time: 45.3365 s\n",
       "File: /Users/hector/Documents/BGWAS2/dbgwas_docker/Tarone/scripts/ExploreBFS.py\n",
       "Function: explore at line 24\n",
       "\n",
       "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
       "==============================================================\n",
       "    24                                           def explore(G, alpha, kmax, Lmax = 10 ** 7, verbose = False, threads = 1,\n",
       "    25                                                       backend = \"locky\"):\n",
       "    26                                               \"\"\"Compute the set R by incremental values of k:\n",
       "    27                                               \n",
       "    28                                               Args:\n",
       "    29                                                   G: the graph we want to explore.\n",
       "    30                                                   alpha: between 0 and 1. FWER we want to control.\n",
       "    31                                                   n1s: An vector of group sizes among the first phenotype.\n",
       "    32                                                   n2s: An vector of group sizes among the second phenotype.\n",
       "    33                                                   kmax: an integer, the maximum value of k we allow.\n",
       "    34                                                   Lmax: maximum size of the subgraph\n",
       "    35                                                   verbose: a boolean, default to false.\n",
       "    36                                                   threads: Number of cores used in the process\n",
       "    37                                               \n",
       "    38                                               Return:\n",
       "    39                                                   The array R of testable subgraphs.\n",
       "    40                                               \"\"\"\n",
       "    41                                               # We avoid computing this too often\n",
       "    42         1       1151.0   1151.0      0.0      n1s, n2s = G.ns()\n",
       "    43         1         30.0     30.0      0.0      n = int(n1s.sum() + n2s.sum())\n",
       "    44         1          6.0      6.0      0.0      nNodes = G.lengths.shape[0]\n",
       "    45         1       3417.0   3417.0      0.0      k0, TH = find_ko(np.array([]), alpha , 1)\n",
       "    46         1          3.0      3.0      0.0      if verbose:\n",
       "    47                                                   message1 = ('Starting to explore a graph with ' +\n",
       "    48                                                               '{N} nodes.'.format(N = nNodes))\n",
       "    49                                                   message2 = ('The value of alpha is {alpha}. '.format(alpha = alpha) +\n",
       "    50                                                               'k0 is initialized at 1.')\n",
       "    51                                                   print(message1)\n",
       "    52                                                   print(message2)\n",
       "    53                                                   print()\n",
       "    54                                               \n",
       "    55                                               # Initiate the list of candidates. We create the closure of every subgraph\n",
       "    56                                               # of size 1\n",
       "    57         1         94.0     94.0      0.0      chunks = np.array(range(nNodes))\n",
       "    58         1         54.0     54.0      0.0      chunks = np.array_split(chunks, threads)\n",
       "    59         1        204.0    204.0      0.0      C = Parallel(n_jobs=threads, verbose = 1)(delayed(start)\n",
       "    60         1     169572.0 169572.0      0.4                   (chunk, G, TH, n1s, n2s) for chunk in chunks)\n",
       "    61         1         20.0     20.0      0.0      C = np.concatenate(C)\n",
       "    62                                               # Then we prune the redundant ones\n",
       "    63         1        165.0    165.0      0.0      Tb = itemtable(nNodes)\n",
       "    64                                               \n",
       "    65       499       1149.0      2.3      0.0      for i, S in enumerate(C):\n",
       "    66       498       7042.0     14.1      0.0          explored = Tb.add_table(max(S.nodes), S.ys)\n",
       "    67                                               \n",
       "    68         1         73.0     73.0      0.0      chunks = np.array_split(C, threads)\n",
       "    69         1        208.0    208.0      0.0      Env = Parallel(n_jobs=threads, backend = backend, verbose = 0)(delayed(compute_envelopes)\n",
       "    70         1        673.0    673.0      0.0                     (chunk) for chunk in chunks)\n",
       "    71         1         16.0     16.0      0.0      Env = np.concatenate(Env)\n",
       "    72         1        164.0    164.0      0.0      Prunable = Parallel(n_jobs=threads, backend = backend, verbose = 0)(delayed(are_prunable)\n",
       "    73         1        561.0    561.0      0.0                          (chunk) for chunk in chunks)\n",
       "    74         1         12.0     12.0      0.0      Prunable = np.concatenate(Prunable)\n",
       "    75         1        158.0    158.0      0.0      Too_Large = Parallel(n_jobs=threads, backend = backend, verbose = 0)(delayed(are_too_large)\n",
       "    76         1        843.0    843.0      0.0                           (chunk, Lmax) for chunk in chunks)\n",
       "    77         1         19.0     19.0      0.0      Too_Large = np.concatenate(Too_Large)\n",
       "    78                                               \n",
       "    79                                               # We then find the updated k0 we considering only subgraphs of size 1\n",
       "    80         1       3271.0   3271.0      0.0      k0, TH = find_ko(Env, alpha)\n",
       "    81                                           \n",
       "    82                                               # We clean the list and we save testable subgraphs\n",
       "    83         1          7.0      7.0      0.0      are_Testable = Env >= TH\n",
       "    84         1          9.0      9.0      0.0      R = C[are_Testable]\n",
       "    85         1          4.0      4.0      0.0      R_Env = Env[are_Testable]\n",
       "    86         1         17.0     17.0      0.0      Keep = (Prunable * (1 - are_Testable) + Too_Large) == 0\n",
       "    87                                               \n",
       "    88         1          3.0      3.0      0.0      if verbose:\n",
       "    89                                                   messages(are_Testable, nNodes, Keep, Too_Large, Prunable, k0)\n",
       "    90                                               \n",
       "    91         1          6.0      6.0      0.0      C = C[Keep]\n",
       "    92                                               \n",
       "    93                                               # We then explore all subgraphs of size 2 and so on and so forth\n",
       "    94         4         12.0      3.0      0.0      while C.shape[0] > 0:\n",
       "    95         4          9.0      2.2      0.0          if k0 > kmax:\n",
       "    96                                                       if verbose:\n",
       "    97                                                           print('Reached kmax value')\n",
       "    98                                                       break\n",
       "    99                                                   # Compute all the parents\n",
       "   100         4        198.0     49.5      0.0          chunks = np.array_split(C, threads)\n",
       "   101         4        706.0    176.5      0.0          Parents = Parallel(n_jobs=threads, backend = backend, verbose = 1)(delayed(expand)\n",
       "   102         4   44854385.0 11213596.2     98.9                             (chunk, G, TH, n1s, n2s, Tb) for chunk in chunks)\n",
       "   103         4        460.0    115.0      0.0          Parents = np.concatenate(Parents)\n",
       "   104         4         27.0      6.8      0.0          if Parents.shape[0] == 0:\n",
       "   105         1          3.0      3.0      0.0              break\n",
       "   106         3       1248.0    416.0      0.0          Explored = np.zeros(Parents.shape[0], dtype = np.bool)\n",
       "   107                                                   # Prune the redundants via the itemtable\n",
       "   108      5651      15434.0      2.7      0.0          for i, S in enumerate(Parents):\n",
       "   109      5648     164932.0     29.2      0.4              explored = Tb.check_table(max(S.nodes), S.ys)\n",
       "   110      5648      14122.0      2.5      0.0              if not explored:\n",
       "   111      2936      52699.0     17.9      0.1                  Tb.add_table(max(S.nodes), S.ys)\n",
       "   112      5648      16184.0      2.9      0.0              Explored[i] = explored\n",
       "   113                                                   \n",
       "   114                                                   # Update the set of closed subgraphs we explore after removing the\n",
       "   115                                                   # redundants\n",
       "   116         3        137.0     45.7      0.0          C =  Parents[Explored == False]\n",
       "   117                                                   \n",
       "   118         3        243.0     81.0      0.0          chunks = np.array_split(C, threads)\n",
       "   119         3       1104.0    368.0      0.0          Env = Parallel(n_jobs=threads, backend = backend, verbose = 0)(delayed(compute_envelopes)\n",
       "   120         3       2779.0    926.3      0.0                         (chunk) for chunk in chunks)\n",
       "   121         3         52.0     17.3      0.0          Env = np.concatenate(Env)\n",
       "   122         3        567.0    189.0      0.0          Prunable = Parallel(n_jobs=threads, backend = backend, verbose = 0)(delayed(are_prunable)\n",
       "   123         3       2099.0    699.7      0.0                              (chunk) for chunk in chunks)\n",
       "   124         3         53.0     17.7      0.0          Prunable = np.concatenate(Prunable)\n",
       "   125         3        550.0    183.3      0.0          Too_Large = Parallel(n_jobs=threads, backend = backend, verbose = 0)(delayed(are_too_large)\n",
       "   126         3       3133.0   1044.3      0.0                               (chunk, Lmax) for chunk in chunks)\n",
       "   127         3         49.0     16.3      0.0          Too_Large = np.concatenate(Too_Large)\n",
       "   128                                                   \n",
       "   129         3      15928.0   5309.3      0.0          k0, TH = find_ko(np.concatenate([Env, R_Env]), alpha, k0)\n",
       "   130                                                   \n",
       "   131         3         26.0      8.7      0.0          are_Testable = Env >= TH\n",
       "   132         3        261.0     87.0      0.0          R = np.concatenate([R[R_Env >= TH], C[are_Testable]])\n",
       "   133         3         64.0     21.3      0.0          R_Env = np.concatenate([R_Env[R_Env >= TH], Env[are_Testable]])\n",
       "   134         3         56.0     18.7      0.0          Keep = (Prunable * (1 - are_Testable) + Too_Large) == 0\n",
       "   135                                                   \n",
       "   136         3          7.0      2.3      0.0          if verbose:\n",
       "   137                                                       messages(are_Testable, C.shape[0], Keep, Too_Large, Prunable, k0)\n",
       "   138         3         28.0      9.3      0.0          C = C[Keep]\n",
       "   139                                                   \n",
       "   140                                               # We have finished and we return the testable graphs\n",
       "   141         1          3.0      3.0      0.0      return R, R_Env, k0, TH\n",
       "\n",
       "Total time: 0.167803 s\n",
       "File: /Users/hector/Documents/BGWAS2/dbgwas_docker/Tarone/scripts/Helper_Explo.py\n",
       "Function: start at line 51\n",
       "\n",
       "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
       "==============================================================\n",
       "    51                                           def start(nodes, G, TH, n1s, n2s):\n",
       "    52                                               \"\"\"Create the graph from the nodes and compute their envelope in chunks\n",
       "    53                                               \n",
       "    54                                               Args:\n",
       "    55                                                   nodes: a list of nodes numbers\n",
       "    56                                                   G: the graph structure we want to explore\n",
       "    57                                                   TH: the initial value of the threshold\n",
       "    58                                                   n1s: An vector of group sizes among the first phenotype.\n",
       "    59                                                   n2s: An vector of group sizes among the second phenotype.\n",
       "    60                                               Return:\n",
       "    61                                                   The graphs, their envelopes and some info for pruning\n",
       "    62                                               \"\"\"\n",
       "    63         1     167573.0 167573.0     99.9      R = [create_Graph(s, G, TH, n1s, n2s) for s in nodes]\n",
       "    64         1        229.0    229.0      0.1      R = np.array([S for S in R if S.closed and not S.to_prune], dtype = graph)\n",
       "    65         1          1.0      1.0      0.0      return R\n",
       "\n",
       "Total time: 0.165818 s\n",
       "File: /Users/hector/Documents/BGWAS2/dbgwas_docker/Tarone/scripts/Helper_Explo.py\n",
       "Function: create_Graph at line 67\n",
       "\n",
       "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
       "==============================================================\n",
       "    67                                           def create_Graph(s, G, TH, n1s, n2s):\n",
       "    68                                               \"\"\"Create and return a (closed) subgraph starting from node s of graph G\n",
       "    69                                           \n",
       "    70                                               Args:\n",
       "    71                                                   s: The node\n",
       "    72                                                   G: the graph structure we want to explore\n",
       "    73                                                   TH: the initial value of the threshold\n",
       "    74                                                   n1s: An vector of group sizes among the first phenotype.\n",
       "    75                                                   n2s: An vector of group sizes among the second phenotype.\n",
       "    76                                               Return:\n",
       "    77                                                   The closure\n",
       "    78                                               \"\"\"\n",
       "    79       500      10587.0     21.2      6.4      S = graph(G)\n",
       "    80       500     154983.0    310.0     93.5      S.new_graph(node = s, G = G, TH = TH, n1s = n1s, n2s = n2s)\n",
       "    81       500        248.0      0.5      0.1      return S\n",
       "\n",
       "Total time: 44.7286 s\n",
       "File: /Users/hector/Documents/BGWAS2/dbgwas_docker/Tarone/scripts/Helper_Explo.py\n",
       "Function: expand at line 83\n",
       "\n",
       "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
       "==============================================================\n",
       "    83                                           def expand(Ss, G, TH, n1s, n2s, Tb):\n",
       "    84                                               \"\"\"Find all parents\n",
       "    85                                           \n",
       "    86                                               Args:\n",
       "    87                                                   Ss: an array of objects of class graph for which we want to compute the\n",
       "    88                                                   envelope\n",
       "    89                                                   G: the graph structure we explore\n",
       "    90                                                   TH: the initial value of the threshold\n",
       "    91                                                   n1s: An vector of group sizes among the first phenotype.\n",
       "    92                                                   n2s: An vector of group sizes among the second phenotype.\n",
       "    93                                                   Tb: the curent itemtable\n",
       "    94                                                   \n",
       "    95                                               Return:\n",
       "    96                                                   An array of parents\n",
       "    97                                               \"\"\"\n",
       "    98         4    7702856.0 1925714.0     17.2      Tb2 = copy.deepcopy(Tb)\n",
       "    99         4         29.0      7.2      0.0      if Ss.shape[0] == 0:\n",
       "   100                                                   return np.array([], dtype = graph)\n",
       "   101                                               else:\n",
       "   102         4   37025728.0 9256432.0     82.8          return np.concatenate([Tb2.Parents(S, G, TH, n1s, n2s) for S in Ss])\n",
       "\n",
       "Total time: 0.00224 s\n",
       "File: /Users/hector/Documents/BGWAS2/dbgwas_docker/Tarone/scripts/Helper_Explo.py\n",
       "Function: are_too_large at line 104\n",
       "\n",
       "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
       "==============================================================\n",
       "   104                                           def are_too_large(Ss, Lmax):\n",
       "   105                                               \"\"\"Look at whether the graphs are prunable or not\n",
       "   106                                           \n",
       "   107                                               Args:\n",
       "   108                                                   Ss: an array of objects of class graph for which we want to compute the\n",
       "   109                                                   envelope\n",
       "   110                                                   Pop: the vector of populations\n",
       "   111                                                   n1s: An vector of group sizes among the first phenotype.\n",
       "   112                                                   n2s: An vector of group sizes among the second phenotype.\n",
       "   113                                           \n",
       "   114                                               Return:\n",
       "   115                                                   A array boolean, whether the graph is prunable\n",
       "   116                                               \"\"\"\n",
       "   117         4          6.0      1.5      0.3      if len(Ss) == 1:\n",
       "   118                                                   return [Ss[0].length > Lmax]\n",
       "   119                                               else:\n",
       "   120         4       2232.0    558.0     99.6          Sizes = np.array([S.length > Lmax for S in Ss], dtype = np.bool_)\n",
       "   121         4          2.0      0.5      0.1          return Sizes\n",
       "\n",
       "Total time: 9e-06 s\n",
       "File: /Users/hector/Documents/BGWAS2/dbgwas_docker/Tarone/scripts/Helper_Explo.py\n",
       "Function: __init__ at line 138\n",
       "\n",
       "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
       "==============================================================\n",
       "   138                                               def __init__(self, Pop, neighbours, nodes, pheno, lengths):\n",
       "   139         1          4.0      4.0     44.4          self.Pop = Pop\n",
       "   140         1          2.0      2.0     22.2          self.neighbours = neighbours\n",
       "   141         1          1.0      1.0     11.1          self.pattern = nodes\n",
       "   142         1          1.0      1.0     11.1          self.Pheno = pheno\n",
       "   143         1          1.0      1.0     11.1          self.lengths = lengths\n",
       "\n",
       "Total time: 0.001124 s\n",
       "File: /Users/hector/Documents/BGWAS2/dbgwas_docker/Tarone/scripts/Helper_Explo.py\n",
       "Function: ns at line 145\n",
       "\n",
       "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
       "==============================================================\n",
       "   145                                               def ns(self):\n",
       "   146                                                   # We have k groups\n",
       "   147                                                   # We returns two vectors of length k with the number of sample in each\n",
       "   148                                                   # group, split by phenotype.\n",
       "   149         1        520.0    520.0     46.3          clusters = np.unique(self.Pop)\n",
       "   150         1          5.0      5.0      0.4          clusters.sort()\n",
       "   151         1         12.0     12.0      1.1          n1s = np.zeros(len(clusters))\n",
       "   152         1          4.0      4.0      0.4          n2s = np.zeros(len(clusters))\n",
       "   153                                                   \n",
       "   154         2          5.0      2.5      0.4          for clus in clusters:\n",
       "   155         1         77.0     77.0      6.9              n1s[clus] = sum(self.Pheno[self.Pop == clus])\n",
       "   156         1        500.0    500.0     44.5              n2s[clus] = sum(self.Pop == clus) - n1s[clus]\n",
       "   157                                                   \n",
       "   158         1          1.0      1.0      0.1          return n1s, n2s\n",
       "\n",
       "Total time: 0.001564 s\n",
       "File: /Users/hector/Documents/BGWAS2/dbgwas_docker/Tarone/scripts/Helper_Tarone.py\n",
       "Function: compute_envelopes at line 16\n",
       "\n",
       "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
       "==============================================================\n",
       "    16                                           def compute_envelopes(Ss):\n",
       "    17                                               \"\"\"Compute the envelope of a subgraph\n",
       "    18                                           \n",
       "    19                                               Args:\n",
       "    20                                                   Ss: an array of objects of class graph for which we want to compute the\n",
       "    21                                                    envelope\n",
       "    22                                           \n",
       "    23                                               Return:\n",
       "    24                                                   The envelopes of the subgraphs\n",
       "    25                                               \"\"\"\n",
       "    26         4       1560.0    390.0     99.7      Env = np.array([S.Env for S in Ss], dtype = np.float64)\n",
       "    27         4          4.0      1.0      0.3      return Env\n",
       "\n",
       "Total time: 0.000879 s\n",
       "File: /Users/hector/Documents/BGWAS2/dbgwas_docker/Tarone/scripts/Helper_Tarone.py\n",
       "Function: are_prunable at line 51\n",
       "\n",
       "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
       "==============================================================\n",
       "    51                                           def are_prunable(Ss):\n",
       "    52                                               \"\"\"Look at whether the graphs are prunable or not\n",
       "    53                                           \n",
       "    54                                               Args:\n",
       "    55                                                   Ss: an array of objects of class graph for which we want to compute the\n",
       "    56                                                   envelope\n",
       "    57                                           \n",
       "    58                                               Return:\n",
       "    59                                                   A array boolean, whether the graph is prunable\n",
       "    60                                               \"\"\"\n",
       "    61         4        875.0    218.8     99.5      Prune = np.array([S.prunable for S in Ss], dtype = np.bool_)\n",
       "    62         4          4.0      1.0      0.5      return Prune\n",
       "\n",
       "Total time: 0.022076 s\n",
       "File: /Users/hector/Documents/BGWAS2/dbgwas_docker/Tarone/scripts/Helper_Tarone.py\n",
       "Function: find_ko at line 64\n",
       "\n",
       "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
       "==============================================================\n",
       "    64                                           def find_ko(min_ps, alpha, k = 1):\n",
       "    65                                               \"\"\"Compute the k0 according to the method in Terada et al\n",
       "    66                                               \n",
       "    67                                               Args:\n",
       "    68                                                   min_ps: The list of minimal p-values\n",
       "    69                                                   alpha: The threshold for controlling the FWER\n",
       "    70                                                   k: the previous value of k0 computed on a smaller set. Default to 1\n",
       "    71                                           \n",
       "    72                                               Return:\n",
       "    73                                                   The k0 value and associated cutoff for the Chi-square test\n",
       "    74                                               \"\"\"\n",
       "    75         5        667.0    133.4      3.0      sortedMinP = -np.sort(-min_ps)\n",
       "    76         5         11.0      2.2      0.0      N = min_ps.shape[0]\n",
       "    77         5          4.0      0.8      0.0      a = k - 1\n",
       "    78         5          4.0      0.8      0.0      b = N\n",
       "    79        41         43.0      1.0      0.2      while b - a > 1:\n",
       "    80        36         90.0      2.5      0.4          mid = int((a + b) / 2)\n",
       "    81        36      16576.0    460.4     75.1          TH = chi2.isf(alpha / (mid + 1), 1)\n",
       "    82        36         93.0      2.6      0.4          if sortedMinP[mid] >= TH:\n",
       "    83        34         23.0      0.7      0.1              a = mid \n",
       "    84                                                   else:\n",
       "    85         2          2.0      1.0      0.0              b = mid\n",
       "    86         5          3.0      0.6      0.0      k0 = a + 1\n",
       "    87         5       4555.0    911.0     20.6      TH = chi2.isf(alpha / k0, 1)\n",
       "    88         5          5.0      1.0      0.0      return k0, TH\n",
       "\n",
       "Total time: 0.000158 s\n",
       "File: /Users/hector/Documents/BGWAS2/dbgwas_docker/Tarone/scripts/ItemTable.py\n",
       "Function: __init__ at line 6\n",
       "\n",
       "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
       "==============================================================\n",
       "     6                                               def __init__(self, nNodes):\n",
       "     7         1        157.0    157.0     99.4          self.dict = {k: set() for k in range(nNodes)}\n",
       "     8         1          1.0      1.0      0.6          return\n",
       "\n",
       "Total time: 0.270691 s\n",
       "File: /Users/hector/Documents/BGWAS2/dbgwas_docker/Tarone/scripts/ItemTable.py\n",
       "Function: check_table at line 10\n",
       "\n",
       "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
       "==============================================================\n",
       "    10                                               def check_table(self, max_node, pattern):\n",
       "    11     20054      11485.0      0.6      4.2          explored = False\n",
       "    12     20054     171682.0      8.6     63.4          max_pattern = tuple(pattern)\n",
       "    13     20054      76538.0      3.8     28.3          if max_pattern in self.dict[max_node]:\n",
       "    14      3026       1461.0      0.5      0.5              explored = True\n",
       "    15     20054       9525.0      0.5      3.5          return explored\n",
       "\n",
       "Total time: 0.110744 s\n",
       "File: /Users/hector/Documents/BGWAS2/dbgwas_docker/Tarone/scripts/ItemTable.py\n",
       "Function: add_table at line 17\n",
       "\n",
       "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
       "==============================================================\n",
       "    17                                               def add_table(self, max_node, pattern):\n",
       "    18      9082      67173.0      7.4     60.7          max_pattern = tuple(pattern)\n",
       "    19      9082      39515.0      4.4     35.7          self.dict[max_node].add(max_pattern)\n",
       "    20      9082       4056.0      0.4      3.7          return\n",
       "\n",
       "Total time: 37.0012 s\n",
       "File: /Users/hector/Documents/BGWAS2/dbgwas_docker/Tarone/scripts/ItemTable.py\n",
       "Function: Parents at line 22\n",
       "\n",
       "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
       "==============================================================\n",
       "    22                                               def Parents(self, S, G, TH, n1s, n2s):\n",
       "    23      3416   36875350.0  10794.9     99.7          Par = S.parents(G, TH, n1s, n2s, self)\n",
       "    24      9064      10016.0      1.1      0.0          for P in Par:\n",
       "    25      5648     114241.0     20.2      0.3              self.add_table(max(P.nodes), P.ys)\n",
       "    26      3416       1637.0      0.5      0.0          return Par\n",
       "\n",
       "Total time: 0.006346 s\n",
       "File: /Users/hector/Documents/BGWAS2/dbgwas_docker/Tarone/scripts/Subgraphs.py\n",
       "Function: __init__ at line 35\n",
       "\n",
       "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
       "==============================================================\n",
       "    35                                               def __init__(self, G):\n",
       "    36                                                   \"\"\"Creating the closure of the subgraph {node}\n",
       "    37                                                   \n",
       "    38                                                   Args:\n",
       "    39                                                       G: the graph structure we want to explore\n",
       "    40                                                   \n",
       "    41                                                   Return:\n",
       "    42                                                       An empty subgraph.\n",
       "    43                                                   \"\"\"\n",
       "    44                                                   # Create the subgraph with one node\n",
       "    45                                                   ## List of presence / absence in the subgraph for each sample\n",
       "    46       500       2045.0      4.1     32.2          self.ys = G.pattern[0] == 2\n",
       "    47       500        356.0      0.7      5.6          self.neighbours = G.pattern\n",
       "    48                                                   ## List of neighoring nodes that can be added\n",
       "    49                                                   ## Length in bp of all the nodes\n",
       "    50       500        626.0      1.3      9.9          self.length = 0\n",
       "    51       500       1734.0      3.5     27.3          self.nodes = np.array([])\n",
       "    52       500        292.0      0.6      4.6          self.Env = 0\n",
       "    53       500        276.0      0.6      4.3          self.prunable = False\n",
       "    54       500        262.0      0.5      4.1          self.to_prune = False\n",
       "    55       500        256.0      0.5      4.0          self.closed = False\n",
       "    56       500        284.0      0.6      4.5          self.max = 0\n",
       "    57       500        215.0      0.4      3.4          return\n",
       "\n",
       "Total time: 0.147293 s\n",
       "File: /Users/hector/Documents/BGWAS2/dbgwas_docker/Tarone/scripts/Subgraphs.py\n",
       "Function: new_graph at line 59\n",
       "\n",
       "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
       "==============================================================\n",
       "    59                                               def new_graph(self, node, G, TH, n1s, n2s, close = True):\n",
       "    60                                                   \"\"\"Creating the closure of the subgraph {node}\n",
       "    61                                                   \n",
       "    62                                                   Args:\n",
       "    63                                                       node: The node from which to start\n",
       "    64                                                       G: the graph structure we want to explore\n",
       "    65                                                       TH: the initial value of the threshold\n",
       "    66                                                       n1s: An vector of group sizes among the first phenotype.\n",
       "    67                                                       n2s: An vector of group sizes among the second phenotype.\n",
       "    68                                                       close: whether to get the closure or not\n",
       "    69                                                   Return:\n",
       "    70                                                       the subgraph\n",
       "    71                                                   \"\"\"\n",
       "    72                                                   # Create the subgraph with one node\n",
       "    73                                                   ## List of presence / absence in the subgraph for each sample\n",
       "    74       500        442.0      0.9      0.3          self.max = node\n",
       "    75       500        812.0      1.6      0.6          self.ys = G.pattern[node]\n",
       "    76       500      32352.0     64.7     22.0          freqS = self.frequencies(G.Pop)\n",
       "    77       500       1703.0      3.4      1.2          thresh = freqS >= np.maximum(n1s, n2s)\n",
       "    78       500       1018.0      2.0      0.7          self.prunable = all(thresh)\n",
       "    79       500      84241.0    168.5     57.2          self.Env = envelope(freqS, n1s, n2s)\n",
       "    80                                                   # If we can prune directly, we prune\n",
       "    81       500        505.0      1.0      0.3          if self.Env < TH and self.prunable:\n",
       "    82                                                       self.to_prune = True\n",
       "    83                                                       return\n",
       "    84                                                   ## List of neighoring nodes that can be added\n",
       "    85       500       1070.0      2.1      0.7          self.neighbours = G.neighbours[node]\n",
       "    86                                                   ## Length in bp of all the nodes\n",
       "    87       500        691.0      1.4      0.5          self.length = G.lengths[node]\n",
       "    88       500        891.0      1.8      0.6          self.nodes = {node}\n",
       "    89                                                   # Check if closed\n",
       "    90       500      13223.0     26.4      9.0          closure = (G.pattern[self.neighbours,] | self.ys) != self.ys\n",
       "    91       500       6912.0     13.8      4.7          closure = closure.sum(axis = 1) == 0\n",
       "    92       500       2262.0      4.5      1.5          closure = list(closure)\n",
       "    93       500        817.0      1.6      0.6          self.closed = not any(closure)\n",
       "    94       500        354.0      0.7      0.2          return\n",
       "\n",
       "Total time: 0.367285 s\n",
       "File: /Users/hector/Documents/BGWAS2/dbgwas_docker/Tarone/scripts/Subgraphs.py\n",
       "Function: close at line 96\n",
       "\n",
       "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
       "==============================================================\n",
       "    96                                               def close(self, G, Tb, L_Stop = 10 ** 5):\n",
       "    97                                                   \"\"\"Creating the closure of a subgraph\n",
       "    98                                                   \n",
       "    99                                                   Args:\n",
       "   100                                                       self: the current subgraph\n",
       "   101                                                       G: the graph structure we want to explore\n",
       "   102                                                   \n",
       "   103                                                   Return:\n",
       "   104                                                       the closure of the subgraph\n",
       "   105                                                   \"\"\"\n",
       "   106      5648     172757.0     30.6     47.0          closure = (G.pattern[self.neighbours,] | self.ys) != self.ys\n",
       "   107      5648      91527.0     16.2     24.9          closure = closure.sum(axis = 1) == 0\n",
       "   108      5648      30091.0      5.3      8.2          closure = list(closure)\n",
       "   109      5648      34467.0      6.1      9.4          closed_neighbours = [ne for (ne, v) in zip(self.neighbours, closure) if v]\n",
       "   110      5925       7710.0      1.3      2.1          while len(closed_neighbours) > 0:\n",
       "   111       321        410.0      1.3      0.1              ne = closed_neighbours.pop()\n",
       "   112       321      21974.0     68.5      6.0              new_closed_neighbours = self.add_closure_node(ne, G)\n",
       "   113       321        407.0      1.3      0.1              if ne == self.max:\n",
       "   114       106       3165.0     29.9      0.9                  if Tb.check_table(ne, self.ys):\n",
       "   115        44         63.0      1.4      0.0                      self.to_prune = True\n",
       "   116        44         44.0      1.0      0.0                      break\n",
       "   117       277        318.0      1.1      0.1              closed_neighbours.extend(new_closed_neighbours)\n",
       "   118       277        474.0      1.7      0.1              if self.length > L_Stop:\n",
       "   119                                                           self.closed = (len(closed_neighbours) == 0)\n",
       "   120                                                           break\n",
       "   121      5648       3878.0      0.7      1.1          return\n",
       "\n",
       "Total time: 0.016632 s\n",
       "File: /Users/hector/Documents/BGWAS2/dbgwas_docker/Tarone/scripts/Subgraphs.py\n",
       "Function: add_closure_node at line 123\n",
       "\n",
       "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
       "==============================================================\n",
       "   123                                               def add_closure_node(self, node, G):\n",
       "   124                                                   \"\"\" Add a node to the growing subgraph that respect the closure\n",
       "   125                                                   \n",
       "   126                                                   Args:\n",
       "   127                                                       self: the current subgraph\n",
       "   128                                                       node: the node to add\n",
       "   129                                                       G: the graph structure we want to explore\n",
       "   130                                                   \n",
       "   131                                                   Return:\n",
       "   132                                                       S with the new node.\n",
       "   133                                                   \"\"\"\n",
       "   134       321        448.0      1.4      2.7          if node not in self.neighbours:\n",
       "   135                                                       raise NameError('This node should not be added since it is not a neighbour')\n",
       "   136       321        355.0      1.1      2.1          if node > self.max:\n",
       "   137        92         99.0      1.1      0.6              self.max = node\n",
       "   138       321        471.0      1.5      2.8          self.neighbours.remove(node)\n",
       "   139       321        457.0      1.4      2.7          self.nodes.add(node)\n",
       "   140       321        817.0      2.5      4.9          self.length = self.length + G.lengths[node]\n",
       "   141                                                   # We add only the new neighbours\n",
       "   142       321       1875.0      5.8     11.3          new_neighbours = [ne for ne in G.neighbours[node] if\n",
       "   143                                                                       ne not in self.nodes and ne not in self.neighbours]\n",
       "   144       321        384.0      1.2      2.3          self.neighbours.extend(new_neighbours)\n",
       "   145       321       6014.0     18.7     36.2          new_closure = (G.pattern[new_neighbours,] | self.ys) != self.ys\n",
       "   146       321       4355.0     13.6     26.2          new_closure = new_closure.sum(axis = 1) == 0\n",
       "   147       321       1107.0      3.4      6.7          new_closed_neighbours = [ne for (ne, v) in zip(new_neighbours, new_closure) if v]\n",
       "   148       321        250.0      0.8      1.5          return new_closed_neighbours\n",
       "\n",
       "Total time: 36.1394 s\n",
       "File: /Users/hector/Documents/BGWAS2/dbgwas_docker/Tarone/scripts/Subgraphs.py\n",
       "Function: parents at line 150\n",
       "\n",
       "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
       "==============================================================\n",
       "   150                                               def parents(self, G, TH, n1s, n2s, Tb, L_Stop = 10 ** 5):\n",
       "   151                                                   \"\"\" Return the closure of all self + v for all neighbours v of self\n",
       "   152                                                   \n",
       "   153                                                   Args:\n",
       "   154                                                       self: the current subgraph\n",
       "   155                                                       G: the graph we want to explore\n",
       "   156                                                       TH: the initial value of the threshold\n",
       "   157                                                       n1s: An vector of group sizes among the first phenotype.\n",
       "   158                                                       n2s: An vector of group sizes among the second phenotype.\n",
       "   159                                                   \n",
       "   160                                                   Return:\n",
       "   161                                                       an array of graph, all parents of the subgraph\n",
       "   162                                                   \"\"\"\n",
       "   163                                                   # Get the number of neighbours\n",
       "   164      3416       5740.0      1.7      0.0          if len(self.neighbours) == 0:\n",
       "   165         5       2972.0    594.4      0.0              parents = np.empty(0, dtype = graph)\n",
       "   166         5         19.0      3.8      0.0              return parents\n",
       "   167      3411      90074.0     26.4      0.2          closure = G.pattern[self.neighbours] | self.ys\n",
       "   168      3411    1761849.0    516.5      4.9          closure, indexes = np.unique(closure, axis = 0, return_index = True)\n",
       "   169      3411      42215.0     12.4      0.1          parents = np.empty(len(indexes), dtype = graph)\n",
       "   170     52028      98035.0      1.9      0.3          for i, index in enumerate(indexes):\n",
       "   171     48617   16339209.0    336.1     45.2              S = copy.deepcopy(self)\n",
       "   172     48617      82170.0      1.7      0.2              ne = self.neighbours[index]\n",
       "   173     48617    1634639.0     33.6      4.5              S.add_parent_node(ne, G)\n",
       "   174     48617      59590.0      1.2      0.2              if ne == S.max:\n",
       "   175     14300     369521.0     25.8      1.0                  if Tb.check_table(ne, S.ys):\n",
       "   176       270        343.0      1.3      0.0                      continue\n",
       "   177     48347    3039909.0     62.9      8.4              freqS = S.frequencies(G.Pop)\n",
       "   178     48347     197614.0      4.1      0.5              thresh = freqS >= np.maximum(n1s, n2s)\n",
       "   179     48347     143458.0      3.0      0.4              S.prunable = all(thresh)\n",
       "   180     48347   11651056.0    241.0     32.2              S.Env = envelope(freqS, n1s, n2s)\n",
       "   181                                                       # If we can prune directly, we prune\n",
       "   182     48347      70505.0      1.5      0.2              if S.Env < TH and S.prunable:\n",
       "   183     42699      38659.0      0.9      0.1                  continue\n",
       "   184      5648     421396.0     74.6      1.2              S.close(G, Tb, L_Stop)\n",
       "   185      5648       9067.0      1.6      0.0              parents[i] = S\n",
       "   186      3411      37245.0     10.9      0.1          parents = parents[parents != None]\n",
       "   187      3411      40863.0     12.0      0.1          parents = np.array([S for S in parents if S.closed])\n",
       "   188      3411       3221.0      0.9      0.0          return parents\n",
       "\n",
       "Total time: 1.19371 s\n",
       "File: /Users/hector/Documents/BGWAS2/dbgwas_docker/Tarone/scripts/Subgraphs.py\n",
       "Function: add_parent_node at line 190\n",
       "\n",
       "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
       "==============================================================\n",
       "   190                                               def add_parent_node(self, node, G):\n",
       "   191                                                    \"\"\" Add a node to the growing subgraph\n",
       "   192                                                    \n",
       "   193                                                    Args:\n",
       "   194                                                        self: the current subgraph\n",
       "   195                                                        node: the node to add\n",
       "   196                                                        G: the graph structure we want to explore\n",
       "   197                                                    \n",
       "   198                                                    Return:\n",
       "   199                                                        S with the new node.\n",
       "   200                                                    \"\"\"\n",
       "   201     48617      77276.0      1.6      6.5           if node not in self.neighbours:\n",
       "   202                                                        raise NameError('This node should not be added since it is not a neighbour')\n",
       "   203     48617      43347.0      0.9      3.6           if node > self.max:\n",
       "   204     14300      11937.0      0.8      1.0              self.max = node\n",
       "   205     48617      77568.0      1.6      6.5           self.neighbours.remove(node)\n",
       "   206     48617     287497.0      5.9     24.1           self.ys = self.ys | G.pattern[node]\n",
       "   207     48617      56747.0      1.2      4.8           self.nodes.add(node)\n",
       "   208     48617      88292.0      1.8      7.4           self.length = self.length + G.lengths[node]\n",
       "   209                                                    # We add only the new neighbours\n",
       "   210     48617     495042.0     10.2     41.5           new_neighbours = [ne for ne in G.neighbours[node] if ne not in self.nodes and ne not in self.neighbours]\n",
       "   211     48617      55999.0      1.2      4.7           self.neighbours.extend(new_neighbours)\n",
       "\n",
       "Total time: 2.77445 s\n",
       "File: /Users/hector/Documents/BGWAS2/dbgwas_docker/Tarone/scripts/Subgraphs.py\n",
       "Function: frequencies at line 219\n",
       "\n",
       "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
       "==============================================================\n",
       "   219                                               def frequencies(self, Pop):\n",
       "   220                                                   \"\"\" Return the margins for the first column of the tables\"\"\"\n",
       "   221     48847    1625479.0     33.3     58.6          clusters = np.unique(Pop)\n",
       "   222     48847      55343.0      1.1      2.0          clusters.sort()\n",
       "   223     48847     156089.0      3.2      5.6          xs = np.zeros(len(clusters))\n",
       "   224     97694     182429.0      1.9      6.6          for clus in clusters:\n",
       "   225     48847     731364.0     15.0     26.4              xs[clus] = self.ys[Pop == clus].sum()\n",
       "   226     48847      23749.0      0.5      0.9          return xs\n",
       "\n",
       "Total time: 0.000382 s\n",
       "File: /usr/local/lib/python3.7/site-packages/joblib/parallel.py\n",
       "Function: delayed at line 295\n",
       "\n",
       "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
       "==============================================================\n",
       "   295                                           def delayed(function, check_pickle=None):\n",
       "   296                                               \"\"\"Decorator used to capture the arguments of a function.\"\"\"\n",
       "   297        17         12.0      0.7      3.1      if check_pickle is not None:\n",
       "   298                                                   warnings.warn('check_pickle is deprecated in joblib 0.12 and will be'\n",
       "   299                                                                 ' removed in 0.13', DeprecationWarning)\n",
       "   300                                               # Try to pickle the input function, to catch the problems early when\n",
       "   301                                               # using with multiprocessing:\n",
       "   302        17         14.0      0.8      3.7      if check_pickle:\n",
       "   303                                                   dumps(function)\n",
       "   304                                           \n",
       "   305        17         15.0      0.9      3.9      def delayed_function(*args, **kwargs):\n",
       "   306                                                   return function, args, kwargs\n",
       "   307        17         13.0      0.8      3.4      try:\n",
       "   308        17        317.0     18.6     83.0          delayed_function = functools.wraps(function)(delayed_function)\n",
       "   309                                               except AttributeError:\n",
       "   310                                                   \" functools.wraps fails on some callable objects \"\n",
       "   311        17         11.0      0.6      2.9      return delayed_function\n",
       "\n",
       "Total time: 0.002577 s\n",
       "File: /usr/local/lib/python3.7/site-packages/joblib/parallel.py\n",
       "Function: __init__ at line 615\n",
       "\n",
       "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
       "==============================================================\n",
       "   615                                               def __init__(self, n_jobs=None, backend=None, verbose=0, timeout=None,\n",
       "   616                                                            pre_dispatch='2 * n_jobs', batch_size='auto',\n",
       "   617                                                            temp_folder=None, max_nbytes='1M', mmap_mode='r',\n",
       "   618                                                            prefer=None, require=None):\n",
       "   619        17         23.0      1.4      0.9          active_backend, context_n_jobs = get_active_backend(\n",
       "   620        17        664.0     39.1     25.8              prefer=prefer, require=require, verbose=verbose)\n",
       "   621        17         36.0      2.1      1.4          nesting_level = active_backend.nesting_level\n",
       "   622        17         18.0      1.1      0.7          if backend is None and n_jobs is None:\n",
       "   623                                                       # If we are under a parallel_backend context manager, look up\n",
       "   624                                                       # the default number of jobs and use that instead:\n",
       "   625                                                       n_jobs = context_n_jobs\n",
       "   626        17         17.0      1.0      0.7          if n_jobs is None:\n",
       "   627                                                       # No specific context override and no specific value request:\n",
       "   628                                                       # default to 1.\n",
       "   629                                                       n_jobs = 1\n",
       "   630        17         22.0      1.3      0.9          self.n_jobs = n_jobs\n",
       "   631        17         21.0      1.2      0.8          self.verbose = verbose\n",
       "   632        17         20.0      1.2      0.8          self.timeout = timeout\n",
       "   633        17         25.0      1.5      1.0          self.pre_dispatch = pre_dispatch\n",
       "   634        17        642.0     37.8     24.9          self._ready_batches = queue.Queue()\n",
       "   635                                           \n",
       "   636        17         29.0      1.7      1.1          if isinstance(max_nbytes, _basestring):\n",
       "   637        17        184.0     10.8      7.1              max_nbytes = memstr_to_bytes(max_nbytes)\n",
       "   638                                           \n",
       "   639        17         22.0      1.3      0.9          self._backend_args = dict(\n",
       "   640        17         19.0      1.1      0.7              max_nbytes=max_nbytes,\n",
       "   641        17         19.0      1.1      0.7              mmap_mode=mmap_mode,\n",
       "   642        17         19.0      1.1      0.7              temp_folder=temp_folder,\n",
       "   643        17         18.0      1.1      0.7              prefer=prefer,\n",
       "   644        17         18.0      1.1      0.7              require=require,\n",
       "   645        17         64.0      3.8      2.5              verbose=max(0, self.verbose - 50),\n",
       "   646                                                   )\n",
       "   647        17         22.0      1.3      0.9          if DEFAULT_MP_CONTEXT is not None:\n",
       "   648                                                       self._backend_args['context'] = DEFAULT_MP_CONTEXT\n",
       "   649        17         39.0      2.3      1.5          elif hasattr(mp, \"get_context\"):\n",
       "   650        17         87.0      5.1      3.4              self._backend_args['context'] = mp.get_context()\n",
       "   651                                           \n",
       "   652        17         23.0      1.4      0.9          if backend is None:\n",
       "   653         1          1.0      1.0      0.0              backend = active_backend\n",
       "   654                                           \n",
       "   655        16        118.0      7.4      4.6          elif isinstance(backend, ParallelBackendBase):\n",
       "   656                                                       # Use provided backend as is, with the current nesting_level if it\n",
       "   657                                                       # is not set yet.\n",
       "   658                                                       if backend.nesting_level is None:\n",
       "   659                                                           backend.nesting_level = nesting_level\n",
       "   660                                           \n",
       "   661        16         32.0      2.0      1.2          elif hasattr(backend, 'Pool') and hasattr(backend, 'Lock'):\n",
       "   662                                                       # Make it possible to pass a custom multiprocessing context as\n",
       "   663                                                       # backend to change the start method to forkserver or spawn or\n",
       "   664                                                       # preload modules on the forkserver helper process.\n",
       "   665                                                       self._backend_args['context'] = backend\n",
       "   666                                                       backend = MultiprocessingBackend(nesting_level=nesting_level)\n",
       "   667                                                   else:\n",
       "   668        16         17.0      1.1      0.7              try:\n",
       "   669        16         24.0      1.5      0.9                  backend_factory = BACKENDS[backend]\n",
       "   670                                                       except KeyError:\n",
       "   671                                                           raise ValueError(\"Invalid backend: %s, expected one of %r\"\n",
       "   672                                                                            % (backend, sorted(BACKENDS.keys())))\n",
       "   673        16        108.0      6.8      4.2              backend = backend_factory(nesting_level=nesting_level)\n",
       "   674                                           \n",
       "   675        17         23.0      1.4      0.9          if (require == 'sharedmem' and\n",
       "   676                                                           not getattr(backend, 'supports_sharedmem', False)):\n",
       "   677                                                       raise ValueError(\"Backend %s does not support shared memory\"\n",
       "   678                                                                        % backend)\n",
       "   679                                           \n",
       "   680        17         20.0      1.2      0.8          if (batch_size == 'auto' or isinstance(batch_size, Integral) and\n",
       "   681                                                           batch_size > 0):\n",
       "   682        17         21.0      1.2      0.8              self.batch_size = batch_size\n",
       "   683                                                   else:\n",
       "   684                                                       raise ValueError(\n",
       "   685                                                           \"batch_size must be 'auto' or a positive integer, got: %r\"\n",
       "   686                                                           % batch_size)\n",
       "   687                                           \n",
       "   688        17         19.0      1.1      0.7          self._backend = backend\n",
       "   689        17         25.0      1.5      1.0          self._output = None\n",
       "   690        17         28.0      1.6      1.1          self._jobs = list()\n",
       "   691        17         22.0      1.3      0.9          self._managed_backend = False\n",
       "   692                                           \n",
       "   693                                                   # This lock is used coordinate the main thread of this process with\n",
       "   694                                                   # the async callback thread of our the pool.\n",
       "   695        17         68.0      4.0      2.6          self._lock = threading.RLock()\n",
       "\n",
       "Total time: 0.000619 s\n",
       "File: /usr/local/lib/python3.7/site-packages/joblib/parallel.py\n",
       "Function: _initialize_backend at line 706\n",
       "\n",
       "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
       "==============================================================\n",
       "   706                                               def _initialize_backend(self):\n",
       "   707                                                   \"\"\"Build a process or thread pool and return the number of workers\"\"\"\n",
       "   708        34         25.0      0.7      4.0          try:\n",
       "   709        34         46.0      1.4      7.4              n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,\n",
       "   710        34        469.0     13.8     75.8                                               **self._backend_args)\n",
       "   711        17         12.0      0.7      1.9              if self.timeout is not None and not self._backend.supports_timeout:\n",
       "   712                                                           warnings.warn(\n",
       "   713                                                               'The backend class {!r} does not support timeout. '\n",
       "   714                                                               \"You have set 'timeout={}' in Parallel but \"\n",
       "   715                                                               \"the 'timeout' parameter will not be used.\".format(\n",
       "   716                                                                   self._backend.__class__.__name__,\n",
       "   717                                                                   self.timeout))\n",
       "   718                                           \n",
       "   719        17         17.0      1.0      2.7          except FallbackToBackend as e:\n",
       "   720                                                       # Recursively initialize the backend in case of requested fallback.\n",
       "   721        17         11.0      0.6      1.8              self._backend = e.backend\n",
       "   722        17         17.0      1.0      2.7              n_jobs = self._initialize_backend()\n",
       "   723                                           \n",
       "   724        34         22.0      0.6      3.6          return n_jobs\n",
       "\n",
       "Total time: 3.4e-05 s\n",
       "File: /usr/local/lib/python3.7/site-packages/joblib/parallel.py\n",
       "Function: _terminate_backend at line 731\n",
       "\n",
       "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
       "==============================================================\n",
       "   731                                               def _terminate_backend(self):\n",
       "   732        17         13.0      0.8     38.2          if self._backend is not None:\n",
       "   733        17         21.0      1.2     61.8              self._backend.terminate()\n",
       "\n",
       "Total time: 45.0165 s\n",
       "File: /usr/local/lib/python3.7/site-packages/joblib/parallel.py\n",
       "Function: _dispatch at line 735\n",
       "\n",
       "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
       "==============================================================\n",
       "   735                                               def _dispatch(self, batch):\n",
       "   736                                                   \"\"\"Queue the batch for computing, with or without multiprocessing\n",
       "   737                                           \n",
       "   738                                                   WARNING: this method is not thread-safe: it should be only called\n",
       "   739                                                   indirectly via dispatch_one_batch.\n",
       "   740                                           \n",
       "   741                                                   \"\"\"\n",
       "   742                                                   # If job.get() catches an exception, it closes the queue:\n",
       "   743        17         11.0      0.6      0.0          if self._aborting:\n",
       "   744                                                       return\n",
       "   745                                           \n",
       "   746        17         21.0      1.2      0.0          self.n_dispatched_tasks += len(batch)\n",
       "   747        17         13.0      0.8      0.0          self.n_dispatched_batches += 1\n",
       "   748                                           \n",
       "   749        17         19.0      1.1      0.0          dispatch_timestamp = time.time()\n",
       "   750        17         57.0      3.4      0.0          cb = BatchCompletionCallBack(dispatch_timestamp, len(batch), self)\n",
       "   751        17         20.0      1.2      0.0          with self._lock:\n",
       "   752        17         14.0      0.8      0.0              job_idx = len(self._jobs)\n",
       "   753        17   45016344.0 2648020.2    100.0              job = self._backend.apply_async(batch, callback=cb)\n",
       "   754                                                       # A job can complete so quickly than its callback is\n",
       "   755                                                       # called before we get here, causing self._jobs to\n",
       "   756                                                       # grow. To ensure correct results ordering, .insert is\n",
       "   757                                                       # used (rather than .append) in the following line\n",
       "   758        17         36.0      2.1      0.0              self._jobs.insert(job_idx, job)\n",
       "\n",
       "Total time: 45.0195 s\n",
       "File: /usr/local/lib/python3.7/site-packages/joblib/parallel.py\n",
       "Function: dispatch_one_batch at line 772\n",
       "\n",
       "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
       "==============================================================\n",
       "   772                                               def dispatch_one_batch(self, iterator):\n",
       "   773                                                   \"\"\"Prefetch the tasks for the next batch and dispatch them.\n",
       "   774                                           \n",
       "   775                                                   The effective size of the batch is computed here.\n",
       "   776                                                   If there are no more jobs to dispatch, return False, else return True.\n",
       "   777                                           \n",
       "   778                                                   The iterator consumption and dispatching is protected by the same\n",
       "   779                                                   lock so calling this function should be thread safe.\n",
       "   780                                           \n",
       "   781                                                   \"\"\"\n",
       "   782        34         34.0      1.0      0.0          if self.batch_size == 'auto':\n",
       "   783        34         64.0      1.9      0.0              batch_size = self._backend.compute_batch_size()\n",
       "   784                                                   else:\n",
       "   785                                                       # Fixed batch size strategy\n",
       "   786                                                       batch_size = self.batch_size\n",
       "   787                                           \n",
       "   788        34         60.0      1.8      0.0          with self._lock:\n",
       "   789                                                       # to ensure an even distribution of the workolad between workers,\n",
       "   790                                                       # we look ahead in the original iterators more than batch_size\n",
       "   791                                                       # tasks - However, we keep consuming only one batch at each\n",
       "   792                                                       # dispatch_one_batch call. The extra tasks are stored in a local\n",
       "   793                                                       # queue, _ready_batches, that is looked-up prior to re-consuming\n",
       "   794                                                       # tasks from the origal iterator.\n",
       "   795        34         22.0      0.6      0.0              try:\n",
       "   796        34        337.0      9.9      0.0                  tasks = self._ready_batches.get(block=False)\n",
       "   797        34         39.0      1.1      0.0              except queue.Empty:\n",
       "   798                                                           # slice the iterator n_jobs * batchsize items at a time. If the\n",
       "   799                                                           # slice returns less than that, then the current batchsize puts\n",
       "   800                                                           # too much weight on a subset of workers, while other may end\n",
       "   801                                                           # up starving. So in this case, re-scale the batch size\n",
       "   802                                                           # accordingly to distribute evenly the last items between all\n",
       "   803                                                           # workers.\n",
       "   804        34         26.0      0.8      0.0                  n_jobs = self._cached_effective_n_jobs\n",
       "   805        34         74.0      2.2      0.0                  big_batch_size = batch_size * n_jobs\n",
       "   806                                           \n",
       "   807        34        726.0     21.4      0.0                  islice = list(itertools.islice(iterator, big_batch_size))\n",
       "   808        34         37.0      1.1      0.0                  if len(islice) == 0:\n",
       "   809        17         30.0      1.8      0.0                      return False\n",
       "   810        17         22.0      1.3      0.0                  elif (iterator is self._original_iterator\n",
       "   811                                                                 and len(islice) < big_batch_size):\n",
       "   812                                                               # We reached the end of the original iterator (unless\n",
       "   813                                                               # iterator is the ``pre_dispatch``-long initial slice of\n",
       "   814                                                               # the original iterator) -- decrease the batch size to\n",
       "   815                                                               # account for potential variance in the batches running\n",
       "   816                                                               # time.\n",
       "   817                                                               final_batch_size = max(1, len(islice) // (10 * n_jobs))\n",
       "   818                                                           else:\n",
       "   819        17         33.0      1.9      0.0                      final_batch_size = max(1, len(islice) // n_jobs)\n",
       "   820                                           \n",
       "   821                                                           # enqueue n_jobs batches in a local queue\n",
       "   822        34         58.0      1.7      0.0                  for i in range(0, len(islice), final_batch_size):\n",
       "   823        17         29.0      1.7      0.0                      tasks = BatchedCalls(islice[i:i + final_batch_size],\n",
       "   824        17        547.0     32.2      0.0                                           self._backend.get_nested_backend(),\n",
       "   825        17         93.0      5.5      0.0                                           self._pickle_cache)\n",
       "   826        17        295.0     17.4      0.0                      self._ready_batches.put(tasks)\n",
       "   827                                           \n",
       "   828                                                           # finally, get one task.\n",
       "   829        17        193.0     11.4      0.0                  tasks = self._ready_batches.get(block=False)\n",
       "   830        17         41.0      2.4      0.0              if len(tasks) == 0:\n",
       "   831                                                           # No more tasks available in the iterator: tell caller to stop.\n",
       "   832                                                           return False\n",
       "   833                                                       else:\n",
       "   834        17   45016717.0 2648042.2    100.0                  self._dispatch(tasks)\n",
       "   835        17         19.0      1.1      0.0                  return True\n",
       "\n",
       "Total time: 0.002567 s\n",
       "File: /usr/local/lib/python3.7/site-packages/joblib/parallel.py\n",
       "Function: _print at line 837\n",
       "\n",
       "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
       "==============================================================\n",
       "   837                                               def _print(self, msg, msg_args):\n",
       "   838                                                   \"\"\"Display the message on stout or stderr depending on verbosity\"\"\"\n",
       "   839                                                   # XXX: Not using the logger framework: need to\n",
       "   840                                                   # learn to use logger better.\n",
       "   841        34         23.0      0.7      0.9          if not self.verbose:\n",
       "   842        24          8.0      0.3      0.3              return\n",
       "   843        10          7.0      0.7      0.3          if self.verbose < 50:\n",
       "   844        10         21.0      2.1      0.8              writer = sys.stderr.write\n",
       "   845                                                   else:\n",
       "   846                                                       writer = sys.stdout.write\n",
       "   847        10         25.0      2.5      1.0          msg = msg % msg_args\n",
       "   848        10       2483.0    248.3     96.7          writer('[%s]: %s\\n' % (self, msg))\n",
       "\n",
       "Total time: 8.2e-05 s\n",
       "File: /usr/local/lib/python3.7/site-packages/joblib/parallel.py\n",
       "Function: print_progress at line 850\n",
       "\n",
       "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
       "==============================================================\n",
       "   850                                               def print_progress(self):\n",
       "   851                                                   \"\"\"Display the process of the parallel execution only a fraction\n",
       "   852                                                      of time, controlled by self.verbose.\n",
       "   853                                                   \"\"\"\n",
       "   854        17         24.0      1.4     29.3          if not self.verbose:\n",
       "   855        12          9.0      0.8     11.0              return\n",
       "   856         5          9.0      1.8     11.0          elapsed_time = time.time() - self._start_time\n",
       "   857                                           \n",
       "   858                                                   # Original job iterator becomes None once it has been fully\n",
       "   859                                                   # consumed : at this point we know the total number of jobs and we are\n",
       "   860                                                   # able to display an estimation of the remaining time based on already\n",
       "   861                                                   # completed jobs. Otherwise, we simply display the number of completed\n",
       "   862                                                   # tasks.\n",
       "   863         5          6.0      1.2      7.3          if self._original_iterator is not None:\n",
       "   864                                                       if _verbosity_filter(self.n_dispatched_batches, self.verbose):\n",
       "   865                                                           return\n",
       "   866                                                       self._print('Done %3i tasks      | elapsed: %s',\n",
       "   867                                                                   (self.n_completed_tasks,\n",
       "   868                                                                    short_format_time(elapsed_time), ))\n",
       "   869                                                   else:\n",
       "   870         5          3.0      0.6      3.7              index = self.n_completed_tasks\n",
       "   871                                                       # We are finished dispatching\n",
       "   872         5          2.0      0.4      2.4              total_tasks = self.n_dispatched_tasks\n",
       "   873                                                       # We always display the first loop\n",
       "   874         5          4.0      0.8      4.9              if not index == 0:\n",
       "   875                                                           # Display depending on the number of remaining items\n",
       "   876                                                           # A message as soon as we finish dispatching, cursor is 0\n",
       "   877         5          5.0      1.0      6.1                  cursor = (total_tasks - index + 1 -\n",
       "   878         5          4.0      0.8      4.9                            self._pre_dispatch_amount)\n",
       "   879         5          5.0      1.0      6.1                  frequency = (total_tasks // self.verbose) + 1\n",
       "   880         5          4.0      0.8      4.9                  is_last_item = (index + 1 == total_tasks)\n",
       "   881         5          5.0      1.0      6.1                  if (is_last_item or cursor % frequency):\n",
       "   882         5          2.0      0.4      2.4                      return\n",
       "   883                                                       remaining_time = (elapsed_time / index) * \\\n",
       "   884                                                                        (self.n_dispatched_tasks - index * 1.0)\n",
       "   885                                                       # only display status if remaining time is greater or equal to 0\n",
       "   886                                                       self._print('Done %3i out of %3i | elapsed: %s remaining: %s',\n",
       "   887                                                                   (index,\n",
       "   888                                                                    total_tasks,\n",
       "   889                                                                    short_format_time(elapsed_time),\n",
       "   890                                                                    short_format_time(remaining_time),\n",
       "   891                                                                    ))\n",
       "\n",
       "Total time: 0.000214 s\n",
       "File: /usr/local/lib/python3.7/site-packages/joblib/parallel.py\n",
       "Function: retrieve at line 893\n",
       "\n",
       "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
       "==============================================================\n",
       "   893                                               def retrieve(self):\n",
       "   894        17         25.0      1.5     11.7          self._output = list()\n",
       "   895        34         44.0      1.3     20.6          while self._iterating or len(self._jobs) > 0:\n",
       "   896        17         14.0      0.8      6.5              if len(self._jobs) == 0:\n",
       "   897                                                           # Wait for an async callback to dispatch new jobs\n",
       "   898                                                           time.sleep(0.01)\n",
       "   899                                                           continue\n",
       "   900                                                       # We need to be careful: the job list can be filling up as\n",
       "   901                                                       # we empty it and Python list are not thread-safe by default hence\n",
       "   902                                                       # the use of the lock\n",
       "   903        17         27.0      1.6     12.6              with self._lock:\n",
       "   904        17         34.0      2.0     15.9                  job = self._jobs.pop(0)\n",
       "   905                                           \n",
       "   906        17         12.0      0.7      5.6              try:\n",
       "   907        17         24.0      1.4     11.2                  if getattr(self._backend, 'supports_timeout', False):\n",
       "   908                                                               self._output.extend(job.get(timeout=self.timeout))\n",
       "   909                                                           else:\n",
       "   910        17         34.0      2.0     15.9                      self._output.extend(job.get())\n",
       "   911                                           \n",
       "   912                                                       except BaseException as exception:\n",
       "   913                                                           # Note: we catch any BaseException instead of just Exception\n",
       "   914                                                           # instances to also include KeyboardInterrupt.\n",
       "   915                                           \n",
       "   916                                                           # Stop dispatching any new job in the async callback thread\n",
       "   917                                                           self._aborting = True\n",
       "   918                                           \n",
       "   919                                                           # If the backend allows it, cancel or kill remaining running\n",
       "   920                                                           # tasks without waiting for the results as we will raise\n",
       "   921                                                           # the exception we got back to the caller instead of returning\n",
       "   922                                                           # any result.\n",
       "   923                                                           backend = self._backend\n",
       "   924                                                           if (backend is not None and\n",
       "   925                                                                   hasattr(backend, 'abort_everything')):\n",
       "   926                                                               # If the backend is managed externally we need to make sure\n",
       "   927                                                               # to leave it in a working state to allow for future jobs\n",
       "   928                                                               # scheduling.\n",
       "   929                                                               ensure_ready = self._managed_backend\n",
       "   930                                                               backend.abort_everything(ensure_ready=ensure_ready)\n",
       "   931                                           \n",
       "   932                                                           if isinstance(exception, TransportableException):\n",
       "   933                                                               # Capture exception to add information on the local\n",
       "   934                                                               # stack in addition to the distant stack\n",
       "   935                                                               this_report = format_outer_frames(context=10,\n",
       "   936                                                                                                 stack_start=1)\n",
       "   937                                                               raise exception.unwrap(this_report)\n",
       "   938                                                           else:\n",
       "   939                                                               raise\n",
       "\n",
       "Total time: 45.0255 s\n",
       "File: /usr/local/lib/python3.7/site-packages/joblib/parallel.py\n",
       "Function: __call__ at line 941\n",
       "\n",
       "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
       "==============================================================\n",
       "   941                                               def __call__(self, iterable):\n",
       "   942        17         23.0      1.4      0.0          if self._jobs:\n",
       "   943                                                       raise ValueError('This Parallel instance is already running')\n",
       "   944                                                   # A flag used to abort the dispatching of jobs in case an\n",
       "   945                                                   # exception is found\n",
       "   946        17         17.0      1.0      0.0          self._aborting = False\n",
       "   947                                           \n",
       "   948        17         17.0      1.0      0.0          if not self._managed_backend:\n",
       "   949        17        835.0     49.1      0.0              n_jobs = self._initialize_backend()\n",
       "   950                                                   else:\n",
       "   951                                                       n_jobs = self._effective_n_jobs()\n",
       "   952                                           \n",
       "   953                                                   # self._effective_n_jobs should be called in the Parallel.__call__\n",
       "   954                                                   # thread only -- store its value in an attribute for further queries.\n",
       "   955        17         17.0      1.0      0.0          self._cached_effective_n_jobs = n_jobs\n",
       "   956                                           \n",
       "   957        17         31.0      1.8      0.0          backend_name = self._backend.__class__.__name__\n",
       "   958        17         14.0      0.8      0.0          if n_jobs == 0:\n",
       "   959                                                       raise RuntimeError(\"%s has no active worker.\" % backend_name)\n",
       "   960                                           \n",
       "   961        17         18.0      1.1      0.0          self._print(\"Using backend %s with %d concurrent workers.\",\n",
       "   962        17       1511.0     88.9      0.0                      (backend_name, n_jobs))\n",
       "   963        17         34.0      2.0      0.0          if hasattr(self._backend, 'start_call'):\n",
       "   964        17         38.0      2.2      0.0              self._backend.start_call()\n",
       "   965        17         19.0      1.1      0.0          iterator = iter(iterable)\n",
       "   966        17         17.0      1.0      0.0          pre_dispatch = self.pre_dispatch\n",
       "   967                                           \n",
       "   968        17         20.0      1.2      0.0          if pre_dispatch == 'all' or n_jobs == 1:\n",
       "   969                                                       # prevent further dispatch via multiprocessing callback thread\n",
       "   970        17         19.0      1.1      0.0              self._original_iterator = None\n",
       "   971        17         17.0      1.0      0.0              self._pre_dispatch_amount = 0\n",
       "   972                                                   else:\n",
       "   973                                                       self._original_iterator = iterator\n",
       "   974                                                       if hasattr(pre_dispatch, 'endswith'):\n",
       "   975                                                           pre_dispatch = eval(pre_dispatch)\n",
       "   976                                                       self._pre_dispatch_amount = pre_dispatch = int(pre_dispatch)\n",
       "   977                                           \n",
       "   978                                                       # The main thread will consume the first pre_dispatch items and\n",
       "   979                                                       # the remaining items will later be lazily dispatched by async\n",
       "   980                                                       # callbacks upon task completions.\n",
       "   981                                           \n",
       "   982                                                       # TODO: this iterator should be batch_size * n_jobs\n",
       "   983                                                       iterator = itertools.islice(iterator, self._pre_dispatch_amount)\n",
       "   984                                           \n",
       "   985        17         36.0      2.1      0.0          self._start_time = time.time()\n",
       "   986        17         18.0      1.1      0.0          self.n_dispatched_batches = 0\n",
       "   987        17         18.0      1.1      0.0          self.n_dispatched_tasks = 0\n",
       "   988        17         16.0      0.9      0.0          self.n_completed_tasks = 0\n",
       "   989                                                   # Use a caching dict for callables that are pickled with cloudpickle to\n",
       "   990                                                   # improve performances. This cache is used only in the case of\n",
       "   991                                                   # functions that are defined in the __main__ module, functions that are\n",
       "   992                                                   # defined locally (inside another function) and lambda expressions.\n",
       "   993        17         26.0      1.5      0.0          self._pickle_cache = dict()\n",
       "   994        17         15.0      0.9      0.0          try:\n",
       "   995                                                       # Only set self._iterating to True if at least a batch\n",
       "   996                                                       # was dispatched. In particular this covers the edge\n",
       "   997                                                       # case of Parallel used with an exhausted iterator. If\n",
       "   998                                                       # self._original_iterator is None, then this means either\n",
       "   999                                                       # that pre_dispatch == \"all\", n_jobs == 1 or that the first batch\n",
       "  1000                                                       # was very quick and its callback already dispatched all the\n",
       "  1001                                                       # remaining jobs.\n",
       "  1002        17         18.0      1.1      0.0              self._iterating = False\n",
       "  1003        17   45019509.0 2648206.4    100.0              if self.dispatch_one_batch(iterator):\n",
       "  1004        17         23.0      1.4      0.0                  self._iterating = self._original_iterator is not None\n",
       "  1005                                           \n",
       "  1006        17        642.0     37.8      0.0              while self.dispatch_one_batch(iterator):\n",
       "  1007                                                           pass\n",
       "  1008                                           \n",
       "  1009        17         20.0      1.2      0.0              if pre_dispatch == \"all\" or n_jobs == 1:\n",
       "  1010                                                           # The iterable was consumed all at once by the above for loop.\n",
       "  1011                                                           # No need to wait for async callbacks to trigger to\n",
       "  1012                                                           # consumption.\n",
       "  1013        17         19.0      1.1      0.0                  self._iterating = False\n",
       "  1014                                           \n",
       "  1015        17        219.0     12.9      0.0              with self._backend.retrieval_context():\n",
       "  1016        17        512.0     30.1      0.0                  self.retrieve()\n",
       "  1017                                                       # Make sure that we get a last message telling us we are done\n",
       "  1018        17         27.0      1.6      0.0              elapsed_time = time.time() - self._start_time\n",
       "  1019        17         19.0      1.1      0.0              self._print('Done %3i out of %3i | elapsed: %s finished',\n",
       "  1020        17         22.0      1.3      0.0                          (len(self._output), len(self._output),\n",
       "  1021        17       1389.0     81.7      0.0                           short_format_time(elapsed_time)))\n",
       "  1022                                                   finally:\n",
       "  1023        17         35.0      2.1      0.0              if hasattr(self._backend, 'stop_call'):\n",
       "  1024        17         34.0      2.0      0.0                  self._backend.stop_call()\n",
       "  1025        17         17.0      1.0      0.0              if not self._managed_backend:\n",
       "  1026        17         85.0      5.0      0.0                  self._terminate_backend()\n",
       "  1027        17         34.0      2.0      0.0              self._jobs = list()\n",
       "  1028        17         21.0      1.2      0.0              self._pickle_cache = None\n",
       "  1029        17         17.0      1.0      0.0          output = self._output\n",
       "  1030        17         18.0      1.1      0.0          self._output = None\n",
       "  1031        17         14.0      0.8      0.0          return output\n",
       "\n",
       "Total time: 2.7e-05 s\n",
       "File: /usr/local/lib/python3.7/site-packages/joblib/parallel.py\n",
       "Function: __repr__ at line 1033\n",
       "\n",
       "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
       "==============================================================\n",
       "  1033                                               def __repr__(self):\n",
       "  1034        10         27.0      2.7    100.0          return '%s(n_jobs=%s)' % (self.__class__.__name__, self.n_jobs)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%lprun -m ExploreBFS -s speed.BFS_Run(1, 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=5)]: Using backend LokyBackend with 5 concurrent workers.\n",
      "[Parallel(n_jobs=5)]: Done   2 out of   5 | elapsed:    2.3s remaining:    3.5s\n",
      "[Parallel(n_jobs=5)]: Done   5 out of   5 | elapsed:    2.6s finished\n",
      "[Parallel(n_jobs=5)]: Using backend MultiprocessingBackend with 5 concurrent workers.\n",
      "[Parallel(n_jobs=5)]: Done   2 out of   5 | elapsed:    2.3s remaining:    3.4s\n",
      "[Parallel(n_jobs=5)]: Done   5 out of   5 | elapsed:    2.9s finished\n",
      "[Parallel(n_jobs=5)]: Using backend MultiprocessingBackend with 5 concurrent workers.\n",
      "[Parallel(n_jobs=5)]: Done   2 out of   5 | elapsed:   13.1s remaining:   19.7s\n",
      "[Parallel(n_jobs=5)]: Done   5 out of   5 | elapsed:   14.8s finished\n",
      "[Parallel(n_jobs=5)]: Using backend MultiprocessingBackend with 5 concurrent workers.\n",
      "[Parallel(n_jobs=5)]: Done   2 out of   5 | elapsed:   43.3s remaining:  1.1min\n",
      "[Parallel(n_jobs=5)]: Done   5 out of   5 | elapsed:   50.7s finished\n",
      "[Parallel(n_jobs=5)]: Using backend MultiprocessingBackend with 5 concurrent workers.\n",
      "[Parallel(n_jobs=5)]: Done   2 out of   5 | elapsed:   20.4s remaining:   30.6s\n",
      "[Parallel(n_jobs=5)]: Done   5 out of   5 | elapsed:   28.0s finished\n",
      "[Parallel(n_jobs=5)]: Using backend MultiprocessingBackend with 5 concurrent workers.\n",
      "[Parallel(n_jobs=5)]: Done   2 out of   5 | elapsed:   20.8s remaining:   31.2s\n",
      "[Parallel(n_jobs=5)]: Done   5 out of   5 | elapsed:   29.5s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Timer unit: 1e-06 s\n",
       "\n",
       "Total time: 134.69 s\n",
       "File: /Users/hector/Documents/BGWAS2/dbgwas_docker/Tarone/scripts/ExploreBFS.py\n",
       "Function: explore at line 24\n",
       "\n",
       "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
       "==============================================================\n",
       "    24                                           def explore(G, alpha, kmax, Lmax = 10 ** 7, verbose = False, threads = 1,\n",
       "    25                                                       backend = \"locky\"):\n",
       "    26                                               \"\"\"Compute the set R by incremental values of k:\n",
       "    27                                               \n",
       "    28                                               Args:\n",
       "    29                                                   G: the graph we want to explore.\n",
       "    30                                                   alpha: between 0 and 1. FWER we want to control.\n",
       "    31                                                   n1s: An vector of group sizes among the first phenotype.\n",
       "    32                                                   n2s: An vector of group sizes among the second phenotype.\n",
       "    33                                                   kmax: an integer, the maximum value of k we allow.\n",
       "    34                                                   Lmax: maximum size of the subgraph\n",
       "    35                                                   verbose: a boolean, default to false.\n",
       "    36                                                   threads: Number of cores used in the process\n",
       "    37                                               \n",
       "    38                                               Return:\n",
       "    39                                                   The array R of testable subgraphs.\n",
       "    40                                               \"\"\"\n",
       "    41                                               # We avoid computing this too often\n",
       "    42         1        438.0    438.0      0.0      n1s, n2s = G.ns()\n",
       "    43         1         22.0     22.0      0.0      n = int(n1s.sum() + n2s.sum())\n",
       "    44         1          3.0      3.0      0.0      nNodes = G.lengths.shape[0]\n",
       "    45         1        452.0    452.0      0.0      k0, TH = find_ko(np.array([]), alpha , 1)\n",
       "    46         1          2.0      2.0      0.0      if verbose:\n",
       "    47                                                   message1 = ('Starting to explore a graph with ' +\n",
       "    48                                                               '{N} nodes.'.format(N = nNodes))\n",
       "    49                                                   message2 = ('The value of alpha is {alpha}. '.format(alpha = alpha) +\n",
       "    50                                                               'k0 is initialized at 1.')\n",
       "    51                                                   print(message1)\n",
       "    52                                                   print(message2)\n",
       "    53                                                   print()\n",
       "    54                                               \n",
       "    55                                               # Initiate the list of candidates. We create the closure of every subgraph\n",
       "    56                                               # of size 1\n",
       "    57         1         82.0     82.0      0.0      chunks = np.array(range(nNodes))\n",
       "    58         1         64.0     64.0      0.0      chunks = np.array_split(chunks, threads)\n",
       "    59         1        166.0    166.0      0.0      C = Parallel(n_jobs=threads, verbose = 1)(delayed(start)\n",
       "    60         1    2573910.0 2573910.0      1.9                   (chunk, G, TH, n1s, n2s) for chunk in chunks)\n",
       "    61         1         37.0     37.0      0.0      C = np.concatenate(C)\n",
       "    62                                               # Then we prune the redundant ones\n",
       "    63         1        228.0    228.0      0.0      Tb = itemtable(nNodes)\n",
       "    64                                               \n",
       "    65       500       1136.0      2.3      0.0      for i, S in enumerate(C):\n",
       "    66       499       7467.0     15.0      0.0          explored = Tb.add_table(max(S.nodes), S.ys)\n",
       "    67                                               \n",
       "    68         1        133.0    133.0      0.0      chunks = np.array_split(C, threads)\n",
       "    69         1        217.0    217.0      0.0      Env = Parallel(n_jobs=threads, backend = backend, verbose = 0)(delayed(compute_envelopes)\n",
       "    70         1     175671.0 175671.0      0.1                     (chunk) for chunk in chunks)\n",
       "    71         1         89.0     89.0      0.0      Env = np.concatenate(Env)\n",
       "    72         1        794.0    794.0      0.0      Prunable = Parallel(n_jobs=threads, backend = backend, verbose = 0)(delayed(are_prunable)\n",
       "    73         1     178799.0 178799.0      0.1                          (chunk) for chunk in chunks)\n",
       "    74         1         94.0     94.0      0.0      Prunable = np.concatenate(Prunable)\n",
       "    75         1        778.0    778.0      0.0      Too_Large = Parallel(n_jobs=threads, backend = backend, verbose = 0)(delayed(are_too_large)\n",
       "    76         1     175343.0 175343.0      0.1                           (chunk, Lmax) for chunk in chunks)\n",
       "    77         1        167.0    167.0      0.0      Too_Large = np.concatenate(Too_Large)\n",
       "    78                                               \n",
       "    79                                               # We then find the updated k0 we considering only subgraphs of size 1\n",
       "    80         1       4290.0   4290.0      0.0      k0, TH = find_ko(Env, alpha)\n",
       "    81                                           \n",
       "    82                                               # We clean the list and we save testable subgraphs\n",
       "    83         1          9.0      9.0      0.0      are_Testable = Env >= TH\n",
       "    84         1         16.0     16.0      0.0      R = C[are_Testable]\n",
       "    85         1          6.0      6.0      0.0      R_Env = Env[are_Testable]\n",
       "    86         1         25.0     25.0      0.0      Keep = (Prunable * (1 - are_Testable) + Too_Large) == 0\n",
       "    87                                               \n",
       "    88         1          2.0      2.0      0.0      if verbose:\n",
       "    89                                                   messages(are_Testable, nNodes, Keep, Too_Large, Prunable, k0)\n",
       "    90                                               \n",
       "    91         1          6.0      6.0      0.0      C = C[Keep]\n",
       "    92                                               \n",
       "    93                                               # We then explore all subgraphs of size 2 and so on and so forth\n",
       "    94         5         24.0      4.8      0.0      while C.shape[0] > 0:\n",
       "    95         5         14.0      2.8      0.0          if k0 > kmax:\n",
       "    96                                                       if verbose:\n",
       "    97                                                           print('Reached kmax value')\n",
       "    98                                                       break\n",
       "    99                                                   # Compute all the parents\n",
       "   100         5       1380.0    276.0      0.0          chunks = np.array_split(C, threads)\n",
       "   101         5       2767.0    553.4      0.0          Parents = Parallel(n_jobs=threads, backend = backend, verbose = 1)(delayed(expand)\n",
       "   102         5  126784093.0 25356818.6     94.1                             (chunk, G, TH, n1s, n2s, Tb) for chunk in chunks)\n",
       "   103         5        789.0    157.8      0.0          Parents = np.concatenate(Parents)\n",
       "   104         5         49.0      9.8      0.0          if Parents.shape[0] == 0:\n",
       "   105         1          4.0      4.0      0.0              break\n",
       "   106         4        144.0     36.0      0.0          Explored = np.zeros(Parents.shape[0], dtype = np.bool)\n",
       "   107                                                   # Prune the redundants via the itemtable\n",
       "   108     11312      27390.0      2.4      0.0          for i, S in enumerate(Parents):\n",
       "   109     11308     278590.0     24.6      0.2              explored = Tb.check_table(max(S.nodes), S.ys)\n",
       "   110     11308      25601.0      2.3      0.0              if not explored:\n",
       "   111      6050      85452.0     14.1      0.1                  Tb.add_table(max(S.nodes), S.ys)\n",
       "   112     11308      28367.0      2.5      0.0              Explored[i] = explored\n",
       "   113                                                   \n",
       "   114                                                   # Update the set of closed subgraphs we explore after removing the\n",
       "   115                                                   # redundants\n",
       "   116         4        440.0    110.0      0.0          C =  Parents[Explored == False]\n",
       "   117                                                   \n",
       "   118         4       1219.0    304.8      0.0          chunks = np.array_split(C, threads)\n",
       "   119         4       2312.0    578.0      0.0          Env = Parallel(n_jobs=threads, backend = backend, verbose = 0)(delayed(compute_envelopes)\n",
       "   120         4    1490207.0 372551.8      1.1                         (chunk) for chunk in chunks)\n",
       "   121         4        703.0    175.8      0.0          Env = np.concatenate(Env)\n",
       "   122         4       3010.0    752.5      0.0          Prunable = Parallel(n_jobs=threads, backend = backend, verbose = 0)(delayed(are_prunable)\n",
       "   123         4    1388930.0 347232.5      1.0                              (chunk) for chunk in chunks)\n",
       "   124         4        634.0    158.5      0.0          Prunable = np.concatenate(Prunable)\n",
       "   125         4       5320.0   1330.0      0.0          Too_Large = Parallel(n_jobs=threads, backend = backend, verbose = 0)(delayed(are_too_large)\n",
       "   126         4    1402390.0 350597.5      1.0                               (chunk, Lmax) for chunk in chunks)\n",
       "   127         4        746.0    186.5      0.0          Too_Large = np.concatenate(Too_Large)\n",
       "   128                                                   \n",
       "   129         4      30781.0   7695.2      0.0          k0, TH = find_ko(np.concatenate([Env, R_Env]), alpha, k0)\n",
       "   130                                                   \n",
       "   131         4       1604.0    401.0      0.0          are_Testable = Env >= TH\n",
       "   132         4       5410.0   1352.5      0.0          R = np.concatenate([R[R_Env >= TH], C[are_Testable]])\n",
       "   133         4        384.0     96.0      0.0          R_Env = np.concatenate([R_Env[R_Env >= TH], Env[are_Testable]])\n",
       "   134         4        287.0     71.8      0.0          Keep = (Prunable * (1 - are_Testable) + Too_Large) == 0\n",
       "   135                                                   \n",
       "   136         4         13.0      3.2      0.0          if verbose:\n",
       "   137                                                       messages(are_Testable, C.shape[0], Keep, Too_Large, Prunable, k0)\n",
       "   138         4        237.0     59.2      0.0          C = C[Keep]\n",
       "   139                                                   \n",
       "   140                                               # We have finished and we return the testable graphs\n",
       "   141         1          2.0      2.0      0.0      return R, R_Env, k0, TH\n",
       "\n",
       "Total time: 6e-06 s\n",
       "File: /Users/hector/Documents/BGWAS2/dbgwas_docker/Tarone/scripts/Helper_Explo.py\n",
       "Function: __init__ at line 138\n",
       "\n",
       "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
       "==============================================================\n",
       "   138                                               def __init__(self, Pop, neighbours, nodes, pheno, lengths):\n",
       "   139         1          2.0      2.0     33.3          self.Pop = Pop\n",
       "   140         1          1.0      1.0     16.7          self.neighbours = neighbours\n",
       "   141         1          1.0      1.0     16.7          self.pattern = nodes\n",
       "   142         1          1.0      1.0     16.7          self.Pheno = pheno\n",
       "   143         1          1.0      1.0     16.7          self.lengths = lengths\n",
       "\n",
       "Total time: 0.000423 s\n",
       "File: /Users/hector/Documents/BGWAS2/dbgwas_docker/Tarone/scripts/Helper_Explo.py\n",
       "Function: ns at line 145\n",
       "\n",
       "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
       "==============================================================\n",
       "   145                                               def ns(self):\n",
       "   146                                                   # We have k groups\n",
       "   147                                                   # We returns two vectors of length k with the number of sample in each\n",
       "   148                                                   # group, split by phenotype.\n",
       "   149         1         78.0     78.0     18.4          clusters = np.unique(self.Pop)\n",
       "   150         1          2.0      2.0      0.5          clusters.sort()\n",
       "   151         1          5.0      5.0      1.2          n1s = np.zeros(len(clusters))\n",
       "   152         1          1.0      1.0      0.2          n2s = np.zeros(len(clusters))\n",
       "   153                                                   \n",
       "   154         2          2.0      1.0      0.5          for clus in clusters:\n",
       "   155         1         38.0     38.0      9.0              n1s[clus] = sum(self.Pheno[self.Pop == clus])\n",
       "   156         1        297.0    297.0     70.2              n2s[clus] = sum(self.Pop == clus) - n1s[clus]\n",
       "   157                                                   \n",
       "   158         1          0.0      0.0      0.0          return n1s, n2s\n",
       "\n",
       "Total time: 0.032296 s\n",
       "File: /Users/hector/Documents/BGWAS2/dbgwas_docker/Tarone/scripts/Helper_Tarone.py\n",
       "Function: find_ko at line 64\n",
       "\n",
       "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
       "==============================================================\n",
       "    64                                           def find_ko(min_ps, alpha, k = 1):\n",
       "    65                                               \"\"\"Compute the k0 according to the method in Terada et al\n",
       "    66                                               \n",
       "    67                                               Args:\n",
       "    68                                                   min_ps: The list of minimal p-values\n",
       "    69                                                   alpha: The threshold for controlling the FWER\n",
       "    70                                                   k: the previous value of k0 computed on a smaller set. Default to 1\n",
       "    71                                           \n",
       "    72                                               Return:\n",
       "    73                                                   The k0 value and associated cutoff for the Chi-square test\n",
       "    74                                               \"\"\"\n",
       "    75         6       2074.0    345.7      6.4      sortedMinP = -np.sort(-min_ps)\n",
       "    76         6         64.0     10.7      0.2      N = min_ps.shape[0]\n",
       "    77         6         10.0      1.7      0.0      a = k - 1\n",
       "    78         6          4.0      0.7      0.0      b = N\n",
       "    79        49         55.0      1.1      0.2      while b - a > 1:\n",
       "    80        43        127.0      3.0      0.4          mid = int((a + b) / 2)\n",
       "    81        43      27488.0    639.3     85.1          TH = chi2.isf(alpha / (mid + 1), 1)\n",
       "    82        43        121.0      2.8      0.4          if sortedMinP[mid] >= TH:\n",
       "    83        34         24.0      0.7      0.1              a = mid \n",
       "    84                                                   else:\n",
       "    85         9         13.0      1.4      0.0              b = mid\n",
       "    86         6          3.0      0.5      0.0      k0 = a + 1\n",
       "    87         6       2306.0    384.3      7.1      TH = chi2.isf(alpha / k0, 1)\n",
       "    88         6          7.0      1.2      0.0      return k0, TH\n",
       "\n",
       "Total time: 0.000217 s\n",
       "File: /Users/hector/Documents/BGWAS2/dbgwas_docker/Tarone/scripts/ItemTable.py\n",
       "Function: __init__ at line 6\n",
       "\n",
       "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
       "==============================================================\n",
       "     6                                               def __init__(self, nNodes):\n",
       "     7         1        216.0    216.0     99.5          self.dict = {k: set() for k in range(nNodes)}\n",
       "     8         1          1.0      1.0      0.5          return\n",
       "\n",
       "Total time: 0.139124 s\n",
       "File: /Users/hector/Documents/BGWAS2/dbgwas_docker/Tarone/scripts/ItemTable.py\n",
       "Function: check_table at line 10\n",
       "\n",
       "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
       "==============================================================\n",
       "    10                                               def check_table(self, max_node, pattern):\n",
       "    11     11308       4819.0      0.4      3.5          explored = False\n",
       "    12     11308      84358.0      7.5     60.6          max_pattern = tuple(pattern)\n",
       "    13     11308      43115.0      3.8     31.0          if max_pattern in self.dict[max_node]:\n",
       "    14      5258       2265.0      0.4      1.6              explored = True\n",
       "    15     11308       4567.0      0.4      3.3          return explored\n",
       "\n",
       "Total time: 0.060205 s\n",
       "File: /Users/hector/Documents/BGWAS2/dbgwas_docker/Tarone/scripts/ItemTable.py\n",
       "Function: add_table at line 17\n",
       "\n",
       "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
       "==============================================================\n",
       "    17                                               def add_table(self, max_node, pattern):\n",
       "    18      6549      39819.0      6.1     66.1          max_pattern = tuple(pattern)\n",
       "    19      6549      17631.0      2.7     29.3          self.dict[max_node].add(max_pattern)\n",
       "    20      6549       2755.0      0.4      4.6          return\n",
       "\n",
       "Total time: 0.003798 s\n",
       "File: /usr/local/lib/python3.7/site-packages/joblib/parallel.py\n",
       "Function: delayed at line 295\n",
       "\n",
       "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
       "==============================================================\n",
       "   295                                           def delayed(function, check_pickle=None):\n",
       "   296                                               \"\"\"Decorator used to capture the arguments of a function.\"\"\"\n",
       "   297       105        103.0      1.0      2.7      if check_pickle is not None:\n",
       "   298                                                   warnings.warn('check_pickle is deprecated in joblib 0.12 and will be'\n",
       "   299                                                                 ' removed in 0.13', DeprecationWarning)\n",
       "   300                                               # Try to pickle the input function, to catch the problems early when\n",
       "   301                                               # using with multiprocessing:\n",
       "   302       105         75.0      0.7      2.0      if check_pickle:\n",
       "   303                                                   dumps(function)\n",
       "   304                                           \n",
       "   305       105        334.0      3.2      8.8      def delayed_function(*args, **kwargs):\n",
       "   306                                                   return function, args, kwargs\n",
       "   307       105         61.0      0.6      1.6      try:\n",
       "   308       105       3160.0     30.1     83.2          delayed_function = functools.wraps(function)(delayed_function)\n",
       "   309                                               except AttributeError:\n",
       "   310                                                   \" functools.wraps fails on some callable objects \"\n",
       "   311       105         65.0      0.6      1.7      return delayed_function\n",
       "\n",
       "Total time: 0.011059 s\n",
       "File: /usr/local/lib/python3.7/site-packages/joblib/parallel.py\n",
       "Function: __init__ at line 615\n",
       "\n",
       "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
       "==============================================================\n",
       "   615                                               def __init__(self, n_jobs=None, backend=None, verbose=0, timeout=None,\n",
       "   616                                                            pre_dispatch='2 * n_jobs', batch_size='auto',\n",
       "   617                                                            temp_folder=None, max_nbytes='1M', mmap_mode='r',\n",
       "   618                                                            prefer=None, require=None):\n",
       "   619        21         33.0      1.6      0.3          active_backend, context_n_jobs = get_active_backend(\n",
       "   620        21       2000.0     95.2     18.1              prefer=prefer, require=require, verbose=verbose)\n",
       "   621        21         45.0      2.1      0.4          nesting_level = active_backend.nesting_level\n",
       "   622        21         24.0      1.1      0.2          if backend is None and n_jobs is None:\n",
       "   623                                                       # If we are under a parallel_backend context manager, look up\n",
       "   624                                                       # the default number of jobs and use that instead:\n",
       "   625                                                       n_jobs = context_n_jobs\n",
       "   626        21         26.0      1.2      0.2          if n_jobs is None:\n",
       "   627                                                       # No specific context override and no specific value request:\n",
       "   628                                                       # default to 1.\n",
       "   629                                                       n_jobs = 1\n",
       "   630        21        395.0     18.8      3.6          self.n_jobs = n_jobs\n",
       "   631        21         32.0      1.5      0.3          self.verbose = verbose\n",
       "   632        21         30.0      1.4      0.3          self.timeout = timeout\n",
       "   633        21         53.0      2.5      0.5          self.pre_dispatch = pre_dispatch\n",
       "   634        21       3283.0    156.3     29.7          self._ready_batches = queue.Queue()\n",
       "   635                                           \n",
       "   636        21         53.0      2.5      0.5          if isinstance(max_nbytes, _basestring):\n",
       "   637        21        833.0     39.7      7.5              max_nbytes = memstr_to_bytes(max_nbytes)\n",
       "   638                                           \n",
       "   639        21         37.0      1.8      0.3          self._backend_args = dict(\n",
       "   640        21         26.0      1.2      0.2              max_nbytes=max_nbytes,\n",
       "   641        21         25.0      1.2      0.2              mmap_mode=mmap_mode,\n",
       "   642        21         22.0      1.0      0.2              temp_folder=temp_folder,\n",
       "   643        21         23.0      1.1      0.2              prefer=prefer,\n",
       "   644        21         22.0      1.0      0.2              require=require,\n",
       "   645        21        145.0      6.9      1.3              verbose=max(0, self.verbose - 50),\n",
       "   646                                                   )\n",
       "   647        21         27.0      1.3      0.2          if DEFAULT_MP_CONTEXT is not None:\n",
       "   648                                                       self._backend_args['context'] = DEFAULT_MP_CONTEXT\n",
       "   649        21        527.0     25.1      4.8          elif hasattr(mp, \"get_context\"):\n",
       "   650        21        212.0     10.1      1.9              self._backend_args['context'] = mp.get_context()\n",
       "   651                                           \n",
       "   652        21         26.0      1.2      0.2          if backend is None:\n",
       "   653         1          1.0      1.0      0.0              backend = active_backend\n",
       "   654                                           \n",
       "   655        20       1477.0     73.8     13.4          elif isinstance(backend, ParallelBackendBase):\n",
       "   656                                                       # Use provided backend as is, with the current nesting_level if it\n",
       "   657                                                       # is not set yet.\n",
       "   658                                                       if backend.nesting_level is None:\n",
       "   659                                                           backend.nesting_level = nesting_level\n",
       "   660                                           \n",
       "   661        20        100.0      5.0      0.9          elif hasattr(backend, 'Pool') and hasattr(backend, 'Lock'):\n",
       "   662                                                       # Make it possible to pass a custom multiprocessing context as\n",
       "   663                                                       # backend to change the start method to forkserver or spawn or\n",
       "   664                                                       # preload modules on the forkserver helper process.\n",
       "   665                                                       self._backend_args['context'] = backend\n",
       "   666                                                       backend = MultiprocessingBackend(nesting_level=nesting_level)\n",
       "   667                                                   else:\n",
       "   668        20         23.0      1.1      0.2              try:\n",
       "   669        20         31.0      1.6      0.3                  backend_factory = BACKENDS[backend]\n",
       "   670                                                       except KeyError:\n",
       "   671                                                           raise ValueError(\"Invalid backend: %s, expected one of %r\"\n",
       "   672                                                                            % (backend, sorted(BACKENDS.keys())))\n",
       "   673        20        180.0      9.0      1.6              backend = backend_factory(nesting_level=nesting_level)\n",
       "   674                                           \n",
       "   675        21         27.0      1.3      0.2          if (require == 'sharedmem' and\n",
       "   676                                                           not getattr(backend, 'supports_sharedmem', False)):\n",
       "   677                                                       raise ValueError(\"Backend %s does not support shared memory\"\n",
       "   678                                                                        % backend)\n",
       "   679                                           \n",
       "   680        21         25.0      1.2      0.2          if (batch_size == 'auto' or isinstance(batch_size, Integral) and\n",
       "   681                                                           batch_size > 0):\n",
       "   682        21         32.0      1.5      0.3              self.batch_size = batch_size\n",
       "   683                                                   else:\n",
       "   684                                                       raise ValueError(\n",
       "   685                                                           \"batch_size must be 'auto' or a positive integer, got: %r\"\n",
       "   686                                                           % batch_size)\n",
       "   687                                           \n",
       "   688        21         29.0      1.4      0.3          self._backend = backend\n",
       "   689        21         24.0      1.1      0.2          self._output = None\n",
       "   690        21         37.0      1.8      0.3          self._jobs = list()\n",
       "   691        21         24.0      1.1      0.2          self._managed_backend = False\n",
       "   692                                           \n",
       "   693                                                   # This lock is used coordinate the main thread of this process with\n",
       "   694                                                   # the async callback thread of our the pool.\n",
       "   695        21       1150.0     54.8     10.4          self._lock = threading.RLock()\n",
       "\n",
       "Total time: 1.62734 s\n",
       "File: /usr/local/lib/python3.7/site-packages/joblib/parallel.py\n",
       "Function: _initialize_backend at line 706\n",
       "\n",
       "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
       "==============================================================\n",
       "   706                                               def _initialize_backend(self):\n",
       "   707                                                   \"\"\"Build a process or thread pool and return the number of workers\"\"\"\n",
       "   708        21         15.0      0.7      0.0          try:\n",
       "   709        21        693.0     33.0      0.0              n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,\n",
       "   710        21    1626422.0  77448.7     99.9                                               **self._backend_args)\n",
       "   711        21        193.0      9.2      0.0              if self.timeout is not None and not self._backend.supports_timeout:\n",
       "   712                                                           warnings.warn(\n",
       "   713                                                               'The backend class {!r} does not support timeout. '\n",
       "   714                                                               \"You have set 'timeout={}' in Parallel but \"\n",
       "   715                                                               \"the 'timeout' parameter will not be used.\".format(\n",
       "   716                                                                   self._backend.__class__.__name__,\n",
       "   717                                                                   self.timeout))\n",
       "   718                                           \n",
       "   719                                                   except FallbackToBackend as e:\n",
       "   720                                                       # Recursively initialize the backend in case of requested fallback.\n",
       "   721                                                       self._backend = e.backend\n",
       "   722                                                       n_jobs = self._initialize_backend()\n",
       "   723                                           \n",
       "   724        21         17.0      0.8      0.0          return n_jobs\n",
       "\n",
       "Total time: 1.69232 s\n",
       "File: /usr/local/lib/python3.7/site-packages/joblib/parallel.py\n",
       "Function: _terminate_backend at line 731\n",
       "\n",
       "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
       "==============================================================\n",
       "   731                                               def _terminate_backend(self):\n",
       "   732        21         20.0      1.0      0.0          if self._backend is not None:\n",
       "   733        21    1692295.0  80585.5    100.0              self._backend.terminate()\n",
       "\n",
       "Total time: 0.150472 s\n",
       "File: /usr/local/lib/python3.7/site-packages/joblib/parallel.py\n",
       "Function: _dispatch at line 735\n",
       "\n",
       "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
       "==============================================================\n",
       "   735                                               def _dispatch(self, batch):\n",
       "   736                                                   \"\"\"Queue the batch for computing, with or without multiprocessing\n",
       "   737                                           \n",
       "   738                                                   WARNING: this method is not thread-safe: it should be only called\n",
       "   739                                                   indirectly via dispatch_one_batch.\n",
       "   740                                           \n",
       "   741                                                   \"\"\"\n",
       "   742                                                   # If job.get() catches an exception, it closes the queue:\n",
       "   743       105        242.0      2.3      0.2          if self._aborting:\n",
       "   744                                                       return\n",
       "   745                                           \n",
       "   746       105        196.0      1.9      0.1          self.n_dispatched_tasks += len(batch)\n",
       "   747       105         94.0      0.9      0.1          self.n_dispatched_batches += 1\n",
       "   748                                           \n",
       "   749       105        274.0      2.6      0.2          dispatch_timestamp = time.time()\n",
       "   750       105        634.0      6.0      0.4          cb = BatchCompletionCallBack(dispatch_timestamp, len(batch), self)\n",
       "   751       105        133.0      1.3      0.1          with self._lock:\n",
       "   752       105        115.0      1.1      0.1              job_idx = len(self._jobs)\n",
       "   753       105     148170.0   1411.1     98.5              job = self._backend.apply_async(batch, callback=cb)\n",
       "   754                                                       # A job can complete so quickly than its callback is\n",
       "   755                                                       # called before we get here, causing self._jobs to\n",
       "   756                                                       # grow. To ensure correct results ordering, .insert is\n",
       "   757                                                       # used (rather than .append) in the following line\n",
       "   758       105        614.0      5.8      0.4              self._jobs.insert(job_idx, job)\n",
       "\n",
       "Total time: 0.169568 s\n",
       "File: /usr/local/lib/python3.7/site-packages/joblib/parallel.py\n",
       "Function: dispatch_one_batch at line 772\n",
       "\n",
       "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
       "==============================================================\n",
       "   772                                               def dispatch_one_batch(self, iterator):\n",
       "   773                                                   \"\"\"Prefetch the tasks for the next batch and dispatch them.\n",
       "   774                                           \n",
       "   775                                                   The effective size of the batch is computed here.\n",
       "   776                                                   If there are no more jobs to dispatch, return False, else return True.\n",
       "   777                                           \n",
       "   778                                                   The iterator consumption and dispatching is protected by the same\n",
       "   779                                                   lock so calling this function should be thread safe.\n",
       "   780                                           \n",
       "   781                                                   \"\"\"\n",
       "   782       126        244.0      1.9      0.1          if self.batch_size == 'auto':\n",
       "   783       126       1289.0     10.2      0.8              batch_size = self._backend.compute_batch_size()\n",
       "   784                                                   else:\n",
       "   785                                                       # Fixed batch size strategy\n",
       "   786                                                       batch_size = self.batch_size\n",
       "   787                                           \n",
       "   788       126        359.0      2.8      0.2          with self._lock:\n",
       "   789                                                       # to ensure an even distribution of the workolad between workers,\n",
       "   790                                                       # we look ahead in the original iterators more than batch_size\n",
       "   791                                                       # tasks - However, we keep consuming only one batch at each\n",
       "   792                                                       # dispatch_one_batch call. The extra tasks are stored in a local\n",
       "   793                                                       # queue, _ready_batches, that is looked-up prior to re-consuming\n",
       "   794                                                       # tasks from the origal iterator.\n",
       "   795       126        101.0      0.8      0.1              try:\n",
       "   796       126       2652.0     21.0      1.6                  tasks = self._ready_batches.get(block=False)\n",
       "   797        42        183.0      4.4      0.1              except queue.Empty:\n",
       "   798                                                           # slice the iterator n_jobs * batchsize items at a time. If the\n",
       "   799                                                           # slice returns less than that, then the current batchsize puts\n",
       "   800                                                           # too much weight on a subset of workers, while other may end\n",
       "   801                                                           # up starving. So in this case, re-scale the batch size\n",
       "   802                                                           # accordingly to distribute evenly the last items between all\n",
       "   803                                                           # workers.\n",
       "   804        42         55.0      1.3      0.0                  n_jobs = self._cached_effective_n_jobs\n",
       "   805        42         42.0      1.0      0.0                  big_batch_size = batch_size * n_jobs\n",
       "   806                                           \n",
       "   807        42       6446.0    153.5      3.8                  islice = list(itertools.islice(iterator, big_batch_size))\n",
       "   808        42         54.0      1.3      0.0                  if len(islice) == 0:\n",
       "   809        21         47.0      2.2      0.0                      return False\n",
       "   810        21         22.0      1.0      0.0                  elif (iterator is self._original_iterator\n",
       "   811                                                                 and len(islice) < big_batch_size):\n",
       "   812                                                               # We reached the end of the original iterator (unless\n",
       "   813                                                               # iterator is the ``pre_dispatch``-long initial slice of\n",
       "   814                                                               # the original iterator) -- decrease the batch size to\n",
       "   815                                                               # account for potential variance in the batches running\n",
       "   816                                                               # time.\n",
       "   817                                                               final_batch_size = max(1, len(islice) // (10 * n_jobs))\n",
       "   818                                                           else:\n",
       "   819        21         46.0      2.2      0.0                      final_batch_size = max(1, len(islice) // n_jobs)\n",
       "   820                                           \n",
       "   821                                                           # enqueue n_jobs batches in a local queue\n",
       "   822       126        195.0      1.5      0.1                  for i in range(0, len(islice), final_batch_size):\n",
       "   823       105        331.0      3.2      0.2                      tasks = BatchedCalls(islice[i:i + final_batch_size],\n",
       "   824       105       1135.0     10.8      0.7                                           self._backend.get_nested_backend(),\n",
       "   825       105       1053.0     10.0      0.6                                           self._pickle_cache)\n",
       "   826       105       1904.0     18.1      1.1                      self._ready_batches.put(tasks)\n",
       "   827                                           \n",
       "   828                                                           # finally, get one task.\n",
       "   829        21        673.0     32.0      0.4                  tasks = self._ready_batches.get(block=False)\n",
       "   830       105        293.0      2.8      0.2              if len(tasks) == 0:\n",
       "   831                                                           # No more tasks available in the iterator: tell caller to stop.\n",
       "   832                                                           return False\n",
       "   833                                                       else:\n",
       "   834       105     152277.0   1450.3     89.8                  self._dispatch(tasks)\n",
       "   835       105        167.0      1.6      0.1                  return True\n",
       "\n",
       "Total time: 0.003756 s\n",
       "File: /usr/local/lib/python3.7/site-packages/joblib/parallel.py\n",
       "Function: _print at line 837\n",
       "\n",
       "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
       "==============================================================\n",
       "   837                                               def _print(self, msg, msg_args):\n",
       "   838                                                   \"\"\"Display the message on stout or stderr depending on verbosity\"\"\"\n",
       "   839                                                   # XXX: Not using the logger framework: need to\n",
       "   840                                                   # learn to use logger better.\n",
       "   841        42         56.0      1.3      1.5          if not self.verbose:\n",
       "   842        30         25.0      0.8      0.7              return\n",
       "   843        12         10.0      0.8      0.3          if self.verbose < 50:\n",
       "   844        12         84.0      7.0      2.2              writer = sys.stderr.write\n",
       "   845                                                   else:\n",
       "   846                                                       writer = sys.stdout.write\n",
       "   847        12         60.0      5.0      1.6          msg = msg % msg_args\n",
       "   848        12       3521.0    293.4     93.7          writer('[%s]: %s\\n' % (self, msg))\n",
       "\n",
       "Total time: 130.62 s\n",
       "File: /usr/local/lib/python3.7/site-packages/joblib/parallel.py\n",
       "Function: retrieve at line 893\n",
       "\n",
       "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
       "==============================================================\n",
       "   893                                               def retrieve(self):\n",
       "   894        21        137.0      6.5      0.0          self._output = list()\n",
       "   895       126        509.0      4.0      0.0          while self._iterating or len(self._jobs) > 0:\n",
       "   896       105        165.0      1.6      0.0              if len(self._jobs) == 0:\n",
       "   897                                                           # Wait for an async callback to dispatch new jobs\n",
       "   898                                                           time.sleep(0.01)\n",
       "   899                                                           continue\n",
       "   900                                                       # We need to be careful: the job list can be filling up as\n",
       "   901                                                       # we empty it and Python list are not thread-safe by default hence\n",
       "   902                                                       # the use of the lock\n",
       "   903       105        237.0      2.3      0.0              with self._lock:\n",
       "   904       105        644.0      6.1      0.0                  job = self._jobs.pop(0)\n",
       "   905                                           \n",
       "   906       105        118.0      1.1      0.0              try:\n",
       "   907       105        263.0      2.5      0.0                  if getattr(self._backend, 'supports_timeout', False):\n",
       "   908       105  130618291.0 1243983.7    100.0                      self._output.extend(job.get(timeout=self.timeout))\n",
       "   909                                                           else:\n",
       "   910                                                               self._output.extend(job.get())\n",
       "   911                                           \n",
       "   912                                                       except BaseException as exception:\n",
       "   913                                                           # Note: we catch any BaseException instead of just Exception\n",
       "   914                                                           # instances to also include KeyboardInterrupt.\n",
       "   915                                           \n",
       "   916                                                           # Stop dispatching any new job in the async callback thread\n",
       "   917                                                           self._aborting = True\n",
       "   918                                           \n",
       "   919                                                           # If the backend allows it, cancel or kill remaining running\n",
       "   920                                                           # tasks without waiting for the results as we will raise\n",
       "   921                                                           # the exception we got back to the caller instead of returning\n",
       "   922                                                           # any result.\n",
       "   923                                                           backend = self._backend\n",
       "   924                                                           if (backend is not None and\n",
       "   925                                                                   hasattr(backend, 'abort_everything')):\n",
       "   926                                                               # If the backend is managed externally we need to make sure\n",
       "   927                                                               # to leave it in a working state to allow for future jobs\n",
       "   928                                                               # scheduling.\n",
       "   929                                                               ensure_ready = self._managed_backend\n",
       "   930                                                               backend.abort_everything(ensure_ready=ensure_ready)\n",
       "   931                                           \n",
       "   932                                                           if isinstance(exception, TransportableException):\n",
       "   933                                                               # Capture exception to add information on the local\n",
       "   934                                                               # stack in addition to the distant stack\n",
       "   935                                                               this_report = format_outer_frames(context=10,\n",
       "   936                                                                                                 stack_start=1)\n",
       "   937                                                               raise exception.unwrap(this_report)\n",
       "   938                                                           else:\n",
       "   939                                                               raise\n",
       "\n",
       "Total time: 134.132 s\n",
       "File: /usr/local/lib/python3.7/site-packages/joblib/parallel.py\n",
       "Function: __call__ at line 941\n",
       "\n",
       "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
       "==============================================================\n",
       "   941                                               def __call__(self, iterable):\n",
       "   942        21         33.0      1.6      0.0          if self._jobs:\n",
       "   943                                                       raise ValueError('This Parallel instance is already running')\n",
       "   944                                                   # A flag used to abort the dispatching of jobs in case an\n",
       "   945                                                   # exception is found\n",
       "   946        21         28.0      1.3      0.0          self._aborting = False\n",
       "   947                                           \n",
       "   948        21         24.0      1.1      0.0          if not self._managed_backend:\n",
       "   949        21    1628322.0  77539.1      1.2              n_jobs = self._initialize_backend()\n",
       "   950                                                   else:\n",
       "   951                                                       n_jobs = self._effective_n_jobs()\n",
       "   952                                           \n",
       "   953                                                   # self._effective_n_jobs should be called in the Parallel.__call__\n",
       "   954                                                   # thread only -- store its value in an attribute for further queries.\n",
       "   955        21        518.0     24.7      0.0          self._cached_effective_n_jobs = n_jobs\n",
       "   956                                           \n",
       "   957        21        315.0     15.0      0.0          backend_name = self._backend.__class__.__name__\n",
       "   958        21         25.0      1.2      0.0          if n_jobs == 0:\n",
       "   959                                                       raise RuntimeError(\"%s has no active worker.\" % backend_name)\n",
       "   960                                           \n",
       "   961        21        123.0      5.9      0.0          self._print(\"Using backend %s with %d concurrent workers.\",\n",
       "   962        21       3352.0    159.6      0.0                      (backend_name, n_jobs))\n",
       "   963        21        268.0     12.8      0.0          if hasattr(self._backend, 'start_call'):\n",
       "   964        21        235.0     11.2      0.0              self._backend.start_call()\n",
       "   965        21        144.0      6.9      0.0          iterator = iter(iterable)\n",
       "   966        21         41.0      2.0      0.0          pre_dispatch = self.pre_dispatch\n",
       "   967                                           \n",
       "   968        21         31.0      1.5      0.0          if pre_dispatch == 'all' or n_jobs == 1:\n",
       "   969                                                       # prevent further dispatch via multiprocessing callback thread\n",
       "   970                                                       self._original_iterator = None\n",
       "   971                                                       self._pre_dispatch_amount = 0\n",
       "   972                                                   else:\n",
       "   973        21         82.0      3.9      0.0              self._original_iterator = iterator\n",
       "   974        21        182.0      8.7      0.0              if hasattr(pre_dispatch, 'endswith'):\n",
       "   975        21       4243.0    202.0      0.0                  pre_dispatch = eval(pre_dispatch)\n",
       "   976        21         90.0      4.3      0.0              self._pre_dispatch_amount = pre_dispatch = int(pre_dispatch)\n",
       "   977                                           \n",
       "   978                                                       # The main thread will consume the first pre_dispatch items and\n",
       "   979                                                       # the remaining items will later be lazily dispatched by async\n",
       "   980                                                       # callbacks upon task completions.\n",
       "   981                                           \n",
       "   982                                                       # TODO: this iterator should be batch_size * n_jobs\n",
       "   983        21        222.0     10.6      0.0              iterator = itertools.islice(iterator, self._pre_dispatch_amount)\n",
       "   984                                           \n",
       "   985        21        320.0     15.2      0.0          self._start_time = time.time()\n",
       "   986        21         26.0      1.2      0.0          self.n_dispatched_batches = 0\n",
       "   987        21         23.0      1.1      0.0          self.n_dispatched_tasks = 0\n",
       "   988        21         22.0      1.0      0.0          self.n_completed_tasks = 0\n",
       "   989                                                   # Use a caching dict for callables that are pickled with cloudpickle to\n",
       "   990                                                   # improve performances. This cache is used only in the case of\n",
       "   991                                                   # functions that are defined in the __main__ module, functions that are\n",
       "   992                                                   # defined locally (inside another function) and lambda expressions.\n",
       "   993        21        183.0      8.7      0.0          self._pickle_cache = dict()\n",
       "   994        21         30.0      1.4      0.0          try:\n",
       "   995                                                       # Only set self._iterating to True if at least a batch\n",
       "   996                                                       # was dispatched. In particular this covers the edge\n",
       "   997                                                       # case of Parallel used with an exhausted iterator. If\n",
       "   998                                                       # self._original_iterator is None, then this means either\n",
       "   999                                                       # that pre_dispatch == \"all\", n_jobs == 1 or that the first batch\n",
       "  1000                                                       # was very quick and its callback already dispatched all the\n",
       "  1001                                                       # remaining jobs.\n",
       "  1002        21         59.0      2.8      0.0              self._iterating = False\n",
       "  1003        21     161078.0   7670.4      0.1              if self.dispatch_one_batch(iterator):\n",
       "  1004        21         59.0      2.8      0.0                  self._iterating = self._original_iterator is not None\n",
       "  1005                                           \n",
       "  1006       105      11009.0    104.8      0.0              while self.dispatch_one_batch(iterator):\n",
       "  1007        84         88.0      1.0      0.0                  pass\n",
       "  1008                                           \n",
       "  1009        21         25.0      1.2      0.0              if pre_dispatch == \"all\" or n_jobs == 1:\n",
       "  1010                                                           # The iterable was consumed all at once by the above for loop.\n",
       "  1011                                                           # No need to wait for async callbacks to trigger to\n",
       "  1012                                                           # consumption.\n",
       "  1013                                                           self._iterating = False\n",
       "  1014                                           \n",
       "  1015        21       1810.0     86.2      0.0              with self._backend.retrieval_context():\n",
       "  1016        21  130623027.0 6220144.1     97.4                  self.retrieve()\n",
       "  1017                                                       # Make sure that we get a last message telling us we are done\n",
       "  1018        21        137.0      6.5      0.0              elapsed_time = time.time() - self._start_time\n",
       "  1019        21         51.0      2.4      0.0              self._print('Done %3i out of %3i | elapsed: %s finished',\n",
       "  1020        21        409.0     19.5      0.0                          (len(self._output), len(self._output),\n",
       "  1021        21       1867.0     88.9      0.0                           short_format_time(elapsed_time)))\n",
       "  1022                                                   finally:\n",
       "  1023        21         72.0      3.4      0.0              if hasattr(self._backend, 'stop_call'):\n",
       "  1024        21         67.0      3.2      0.0                  self._backend.stop_call()\n",
       "  1025        21         30.0      1.4      0.0              if not self._managed_backend:\n",
       "  1026        21    1692536.0  80597.0      1.3                  self._terminate_backend()\n",
       "  1027        21        357.0     17.0      0.0              self._jobs = list()\n",
       "  1028        21         41.0      2.0      0.0              self._pickle_cache = None\n",
       "  1029        21         28.0      1.3      0.0          output = self._output\n",
       "  1030        21         22.0      1.0      0.0          self._output = None\n",
       "  1031        21         20.0      1.0      0.0          return output\n",
       "\n",
       "Total time: 0.000119 s\n",
       "File: /usr/local/lib/python3.7/site-packages/joblib/parallel.py\n",
       "Function: __repr__ at line 1033\n",
       "\n",
       "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
       "==============================================================\n",
       "  1033                                               def __repr__(self):\n",
       "  1034        12        119.0      9.9    100.0          return '%s(n_jobs=%s)' % (self.__class__.__name__, self.n_jobs)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%lprun -m ExploreBFS -s speed.BFS_Run(5, 500, backend = \"multiprocessing\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done   2 out of   4 | elapsed:    0.3s remaining:    0.3s\n",
      "[Parallel(n_jobs=4)]: Done   4 out of   4 | elapsed:    0.3s finished\n",
      "[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done   2 out of   4 | elapsed:    2.6s remaining:    2.6s\n",
      "[Parallel(n_jobs=4)]: Done   4 out of   4 | elapsed:    3.0s finished\n",
      "[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done   2 out of   4 | elapsed:    8.4s remaining:    8.4s\n",
      "[Parallel(n_jobs=4)]: Done   4 out of   4 | elapsed:    9.7s finished\n",
      "[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done   2 out of   4 | elapsed:   30.6s remaining:   30.6s\n",
      "[Parallel(n_jobs=4)]: Done   4 out of   4 | elapsed:   34.2s finished\n",
      "[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done   2 out of   4 | elapsed:   10.7s remaining:   10.7s\n",
      "[Parallel(n_jobs=4)]: Done   4 out of   4 | elapsed:   11.3s finished\n",
      "[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done   2 out of   4 | elapsed:    7.7s remaining:    7.7s\n",
      "[Parallel(n_jobs=4)]: Done   4 out of   4 | elapsed:    7.8s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Timer unit: 1e-06 s\n",
       "\n",
       "Total time: 68.9864 s\n",
       "File: /Users/hector/Documents/BGWAS2/dbgwas_docker/Tarone/scripts/ExploreBFS.py\n",
       "Function: explore at line 24\n",
       "\n",
       "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
       "==============================================================\n",
       "    24                                           def explore(G, alpha, kmax, Lmax = 10 ** 7, verbose = False, threads = 1,\n",
       "    25                                                       backend = \"loky\"):\n",
       "    26                                               \"\"\"Compute the set R by incremental values of k:\n",
       "    27                                               \n",
       "    28                                               Args:\n",
       "    29                                                   G: the graph we want to explore.\n",
       "    30                                                   alpha: between 0 and 1. FWER we want to control.\n",
       "    31                                                   n1s: An vector of group sizes among the first phenotype.\n",
       "    32                                                   n2s: An vector of group sizes among the second phenotype.\n",
       "    33                                                   kmax: an integer, the maximum value of k we allow.\n",
       "    34                                                   Lmax: maximum size of the subgraph\n",
       "    35                                                   verbose: a boolean, default to false.\n",
       "    36                                                   threads: Number of cores used in the process\n",
       "    37                                                   backend: the backend used for parallelization\n",
       "    38                                               \n",
       "    39                                               Return:\n",
       "    40                                                   The array R of testable subgraphs.\n",
       "    41                                               \"\"\"\n",
       "    42                                               # We avoid computing this too often\n",
       "    43         1       3929.0   3929.0      0.0      n1s, n2s = G.ns()\n",
       "    44         1         17.0     17.0      0.0      n = int(n1s.sum() + n2s.sum())\n",
       "    45         1          3.0      3.0      0.0      nNodes = G.lengths.shape[0]\n",
       "    46         1        442.0    442.0      0.0      k0, TH = find_ko(np.array([]), alpha , 1)\n",
       "    47         1          2.0      2.0      0.0      if verbose:\n",
       "    48                                                   message1 = ('Starting to explore a graph with ' +\n",
       "    49                                                               '{N} nodes.'.format(N = nNodes))\n",
       "    50                                                   message2 = ('The value of alpha is {alpha}. '.format(alpha = alpha) +\n",
       "    51                                                               'k0 is initialized at 1.')\n",
       "    52                                                   print(message1)\n",
       "    53                                                   print(message2)\n",
       "    54                                                   print()\n",
       "    55                                               \n",
       "    56                                               # Initiate the list of candidates. We create the closure of every subgraph\n",
       "    57                                               # of size 1\n",
       "    58         1         81.0     81.0      0.0      chunks = np.array(range(nNodes))\n",
       "    59         1         59.0     59.0      0.0      chunks = np.array_split(chunks, threads)\n",
       "    60         1        192.0    192.0      0.0      C = Parallel(n_jobs=threads, backend = backend, verbose = 1)(\n",
       "    61         1     360315.0 360315.0      0.5                   delayed(start)(chunk, G, TH, n1s, n2s) for chunk in chunks)\n",
       "    62         1         28.0     28.0      0.0      C = np.concatenate(C)\n",
       "    63                                               # Then we prune the redundant ones\n",
       "    64         1        233.0    233.0      0.0      Tb = itemtable(nNodes)\n",
       "    65                                               \n",
       "    66       500       1112.0      2.2      0.0      for i, S in enumerate(C):\n",
       "    67       499      11178.0     22.4      0.0          explored = Tb.add_table(max(S.nodes), S.ys)\n",
       "    68                                               \n",
       "    69         1         87.0     87.0      0.0      chunks = np.array_split(C, threads)\n",
       "    70         1        189.0    189.0      0.0      Env = Parallel(n_jobs=threads, backend = backend, verbose = 0)(\n",
       "    71         1     125843.0 125843.0      0.2                     delayed(compute_envelopes)(chunk) for chunk in chunks)\n",
       "    72         1        632.0    632.0      0.0      Env = np.concatenate(Env)\n",
       "    73         1        184.0    184.0      0.0      Prunable = Parallel(n_jobs=threads, backend = backend, verbose = 0)(\n",
       "    74         1     112810.0 112810.0      0.2                          delayed(are_prunable)(chunk) for chunk in chunks)\n",
       "    75         1       1322.0   1322.0      0.0      Prunable = np.concatenate(Prunable)\n",
       "    76         1        183.0    183.0      0.0      Too_Large = Parallel(n_jobs=threads, backend = backend, verbose = 0)(\n",
       "    77         1     111683.0 111683.0      0.2                          delayed(are_too_large)(chunk, Lmax) for chunk in chunks)\n",
       "    78         1       1167.0   1167.0      0.0      Too_Large = np.concatenate(Too_Large)\n",
       "    79                                               \n",
       "    80                                               # We then find the updated k0 we considering only subgraphs of size 1\n",
       "    81         1       5328.0   5328.0      0.0      k0, TH = find_ko(Env, alpha)\n",
       "    82                                           \n",
       "    83                                               # We clean the list and we save testable subgraphs\n",
       "    84         1          7.0      7.0      0.0      are_Testable = Env >= TH\n",
       "    85         1         13.0     13.0      0.0      R = C[are_Testable]\n",
       "    86         1          5.0      5.0      0.0      R_Env = Env[are_Testable]\n",
       "    87         1         22.0     22.0      0.0      Keep = (Prunable * (1 - are_Testable) + Too_Large) == 0\n",
       "    88                                               \n",
       "    89         1          2.0      2.0      0.0      if verbose:\n",
       "    90                                                   messages(are_Testable, nNodes, Keep, Too_Large, Prunable, k0)\n",
       "    91                                               \n",
       "    92         1          8.0      8.0      0.0      C = C[Keep]\n",
       "    93                                               \n",
       "    94                                               # We then explore all subgraphs of size 2 and so on and so forth\n",
       "    95         5         18.0      3.6      0.0      while C.shape[0] > 0:\n",
       "    96         5         12.0      2.4      0.0          if k0 > kmax:\n",
       "    97                                                       if verbose:\n",
       "    98                                                           print('Reached kmax value')\n",
       "    99                                                       break\n",
       "   100                                                   # Compute all the parents\n",
       "   101         5        399.0     79.8      0.0          chunks = np.array_split(C, threads)\n",
       "   102         5        971.0    194.2      0.0          Parents = Parallel(n_jobs=threads, backend = backend, verbose = 1)(\n",
       "   103         5   66409754.0 13281950.8     96.3                  delayed(expand)(chunk, G, TH, n1s, n2s, Tb) for chunk in chunks)\n",
       "   104         5        418.0     83.6      0.0          Parents = np.concatenate(Parents)\n",
       "   105         5         31.0      6.2      0.0          if Parents.shape[0] == 0:\n",
       "   106         1          6.0      6.0      0.0              break\n",
       "   107         4         62.0     15.5      0.0          Explored = np.zeros(Parents.shape[0], dtype = np.bool)\n",
       "   108                                                   # Prune the redundants via the itemtable\n",
       "   109     11731      31233.0      2.7      0.0          for i, S in enumerate(Parents):\n",
       "   110     11727     335530.0     28.6      0.5              explored = Tb.check_table(max(S.nodes), S.ys)\n",
       "   111     11727      26879.0      2.3      0.0              if not explored:\n",
       "   112      6258      93042.0     14.9      0.1                  Tb.add_table(max(S.nodes), S.ys)\n",
       "   113     11727      35329.0      3.0      0.1              Explored[i] = explored\n",
       "   114                                                   \n",
       "   115                                                   # Update the set of closed subgraphs we explore after removing the\n",
       "   116                                                   # redundants\n",
       "   117         4       2630.0    657.5      0.0          C =  Parents[Explored == False]\n",
       "   118                                                   \n",
       "   119         4        460.0    115.0      0.0          chunks = np.array_split(C, threads)\n",
       "   120         4        915.0    228.8      0.0          Env = Parallel(n_jobs=threads, backend = backend, verbose = 0)(\n",
       "   121         4     428400.0 107100.0      0.6                         delayed(compute_envelopes)(chunk) for chunk in chunks)\n",
       "   122         4        154.0     38.5      0.0          Env = np.concatenate(Env)\n",
       "   123         4       1212.0    303.0      0.0          Prunable = Parallel(n_jobs=threads, backend = backend, verbose = 0)(\n",
       "   124         4     429691.0 107422.8      0.6                              delayed(are_prunable)(chunk) for chunk in chunks)\n",
       "   125         4        150.0     37.5      0.0          Prunable = np.concatenate(Prunable)\n",
       "   126         4       1436.0    359.0      0.0          Too_Large = Parallel(n_jobs=threads, backend = backend, verbose = 0)(\n",
       "   127         4     426151.0 106537.8      0.6                          delayed(are_too_large)(chunk, Lmax) for chunk in chunks)\n",
       "   128         4        147.0     36.8      0.0          Too_Large = np.concatenate(Too_Large)\n",
       "   129                                                   \n",
       "   130         4      21989.0   5497.2      0.0          k0, TH = find_ko(np.concatenate([Env, R_Env]), alpha, k0)\n",
       "   131                                                   \n",
       "   132         4         50.0     12.5      0.0          are_Testable = Env >= TH\n",
       "   133         4       1842.0    460.5      0.0          R = np.concatenate([R[R_Env >= TH], C[are_Testable]])\n",
       "   134         4        141.0     35.2      0.0          R_Env = np.concatenate([R_Env[R_Env >= TH], Env[are_Testable]])\n",
       "   135         4        156.0     39.0      0.0          Keep = (Prunable * (1 - are_Testable) + Too_Large) == 0\n",
       "   136                                                   \n",
       "   137         4          9.0      2.2      0.0          if verbose:\n",
       "   138                                                       messages(are_Testable, C.shape[0], Keep, Too_Large, Prunable, k0)\n",
       "   139         4         58.0     14.5      0.0          C = C[Keep]\n",
       "   140                                                   \n",
       "   141                                               # We have finished and we return the testable graphs\n",
       "   142         1          5.0      5.0      0.0      return R, R_Env, k0, TH\n",
       "\n",
       "Total time: 6e-06 s\n",
       "File: /Users/hector/Documents/BGWAS2/dbgwas_docker/Tarone/scripts/Helper_Explo.py\n",
       "Function: __init__ at line 138\n",
       "\n",
       "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
       "==============================================================\n",
       "   138                                               def __init__(self, Pop, neighbours, nodes, pheno, lengths):\n",
       "   139         1          2.0      2.0     33.3          self.Pop = Pop\n",
       "   140         1          1.0      1.0     16.7          self.neighbours = neighbours\n",
       "   141         1          1.0      1.0     16.7          self.pattern = nodes\n",
       "   142         1          1.0      1.0     16.7          self.Pheno = pheno\n",
       "   143         1          1.0      1.0     16.7          self.lengths = lengths\n",
       "\n",
       "Total time: 0.003905 s\n",
       "File: /Users/hector/Documents/BGWAS2/dbgwas_docker/Tarone/scripts/Helper_Explo.py\n",
       "Function: ns at line 145\n",
       "\n",
       "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
       "==============================================================\n",
       "   145                                               def ns(self):\n",
       "   146                                                   # We have k groups\n",
       "   147                                                   # We returns two vectors of length k with the number of sample in each\n",
       "   148                                                   # group, split by phenotype.\n",
       "   149         1         63.0     63.0      1.6          clusters = np.unique(self.Pop)\n",
       "   150         1          1.0      1.0      0.0          clusters.sort()\n",
       "   151         1       3504.0   3504.0     89.7          n1s = np.zeros(len(clusters))\n",
       "   152         1          7.0      7.0      0.2          n2s = np.zeros(len(clusters))\n",
       "   153                                                   \n",
       "   154         2          4.0      2.0      0.1          for clus in clusters:\n",
       "   155         1         34.0     34.0      0.9              n1s[clus] = sum(self.Pheno[self.Pop == clus])\n",
       "   156         1        292.0    292.0      7.5              n2s[clus] = sum(self.Pop == clus) - n1s[clus]\n",
       "   157                                                   \n",
       "   158         1          0.0      0.0      0.0          return n1s, n2s\n",
       "\n",
       "Total time: 0.026496 s\n",
       "File: /Users/hector/Documents/BGWAS2/dbgwas_docker/Tarone/scripts/Helper_Tarone.py\n",
       "Function: find_ko at line 64\n",
       "\n",
       "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
       "==============================================================\n",
       "    64                                           def find_ko(min_ps, alpha, k = 1):\n",
       "    65                                               \"\"\"Compute the k0 according to the method in Terada et al\n",
       "    66                                               \n",
       "    67                                               Args:\n",
       "    68                                                   min_ps: The list of minimal p-values\n",
       "    69                                                   alpha: The threshold for controlling the FWER\n",
       "    70                                                   k: the previous value of k0 computed on a smaller set. Default to 1\n",
       "    71                                           \n",
       "    72                                               Return:\n",
       "    73                                                   The k0 value and associated cutoff for the Chi-square test\n",
       "    74                                               \"\"\"\n",
       "    75         6       4704.0    784.0     17.8      sortedMinP = -np.sort(-min_ps)\n",
       "    76         6         17.0      2.8      0.1      N = min_ps.shape[0]\n",
       "    77         6          7.0      1.2      0.0      a = k - 1\n",
       "    78         6          5.0      0.8      0.0      b = N\n",
       "    79        47         47.0      1.0      0.2      while b - a > 1:\n",
       "    80        41         99.0      2.4      0.4          mid = int((a + b) / 2)\n",
       "    81        41      19269.0    470.0     72.7          TH = chi2.isf(alpha / (mid + 1), 1)\n",
       "    82        41         84.0      2.0      0.3          if sortedMinP[mid] >= TH:\n",
       "    83        35         24.0      0.7      0.1              a = mid \n",
       "    84                                                   else:\n",
       "    85         6          5.0      0.8      0.0              b = mid\n",
       "    86         6          6.0      1.0      0.0      k0 = a + 1\n",
       "    87         6       2222.0    370.3      8.4      TH = chi2.isf(alpha / k0, 1)\n",
       "    88         6          7.0      1.2      0.0      return k0, TH\n",
       "\n",
       "Total time: 0.000225 s\n",
       "File: /Users/hector/Documents/BGWAS2/dbgwas_docker/Tarone/scripts/ItemTable.py\n",
       "Function: __init__ at line 6\n",
       "\n",
       "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
       "==============================================================\n",
       "     6                                               def __init__(self, nNodes):\n",
       "     7         1        224.0    224.0     99.6          self.dict = {k: set() for k in range(nNodes)}\n",
       "     8         1          1.0      1.0      0.4          return\n",
       "\n",
       "Total time: 0.172625 s\n",
       "File: /Users/hector/Documents/BGWAS2/dbgwas_docker/Tarone/scripts/ItemTable.py\n",
       "Function: check_table at line 10\n",
       "\n",
       "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
       "==============================================================\n",
       "    10                                               def check_table(self, max_node, pattern):\n",
       "    11     11727       5744.0      0.5      3.3          explored = False\n",
       "    12     11727      97595.0      8.3     56.5          max_pattern = tuple(pattern)\n",
       "    13     11727      61539.0      5.2     35.6          if max_pattern in self.dict[max_node]:\n",
       "    14      5469       2736.0      0.5      1.6              explored = True\n",
       "    15     11727       5011.0      0.4      2.9          return explored\n",
       "\n",
       "Total time: 0.06583 s\n",
       "File: /Users/hector/Documents/BGWAS2/dbgwas_docker/Tarone/scripts/ItemTable.py\n",
       "Function: add_table at line 17\n",
       "\n",
       "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
       "==============================================================\n",
       "    17                                               def add_table(self, max_node, pattern):\n",
       "    18      6757      41809.0      6.2     63.5          max_pattern = tuple(pattern)\n",
       "    19      6757      21080.0      3.1     32.0          self.dict[max_node].add(max_pattern)\n",
       "    20      6757       2941.0      0.4      4.5          return\n",
       "\n",
       "Total time: 0.0016 s\n",
       "File: /usr/local/lib/python3.7/site-packages/joblib/parallel.py\n",
       "Function: delayed at line 295\n",
       "\n",
       "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
       "==============================================================\n",
       "   295                                           def delayed(function, check_pickle=None):\n",
       "   296                                               \"\"\"Decorator used to capture the arguments of a function.\"\"\"\n",
       "   297        84         74.0      0.9      4.6      if check_pickle is not None:\n",
       "   298                                                   warnings.warn('check_pickle is deprecated in joblib 0.12 and will be'\n",
       "   299                                                                 ' removed in 0.13', DeprecationWarning)\n",
       "   300                                               # Try to pickle the input function, to catch the problems early when\n",
       "   301                                               # using with multiprocessing:\n",
       "   302        84         58.0      0.7      3.6      if check_pickle:\n",
       "   303                                                   dumps(function)\n",
       "   304                                           \n",
       "   305        84         79.0      0.9      4.9      def delayed_function(*args, **kwargs):\n",
       "   306                                                   return function, args, kwargs\n",
       "   307        84         59.0      0.7      3.7      try:\n",
       "   308        84       1272.0     15.1     79.5          delayed_function = functools.wraps(function)(delayed_function)\n",
       "   309                                               except AttributeError:\n",
       "   310                                                   \" functools.wraps fails on some callable objects \"\n",
       "   311        84         58.0      0.7      3.6      return delayed_function\n",
       "\n",
       "Total time: 0.003546 s\n",
       "File: /usr/local/lib/python3.7/site-packages/joblib/parallel.py\n",
       "Function: __init__ at line 615\n",
       "\n",
       "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
       "==============================================================\n",
       "   615                                               def __init__(self, n_jobs=None, backend=None, verbose=0, timeout=None,\n",
       "   616                                                            pre_dispatch='2 * n_jobs', batch_size='auto',\n",
       "   617                                                            temp_folder=None, max_nbytes='1M', mmap_mode='r',\n",
       "   618                                                            prefer=None, require=None):\n",
       "   619        21         46.0      2.2      1.3          active_backend, context_n_jobs = get_active_backend(\n",
       "   620        21        698.0     33.2     19.7              prefer=prefer, require=require, verbose=verbose)\n",
       "   621        21         39.0      1.9      1.1          nesting_level = active_backend.nesting_level\n",
       "   622        21         32.0      1.5      0.9          if backend is None and n_jobs is None:\n",
       "   623                                                       # If we are under a parallel_backend context manager, look up\n",
       "   624                                                       # the default number of jobs and use that instead:\n",
       "   625                                                       n_jobs = context_n_jobs\n",
       "   626        21         31.0      1.5      0.9          if n_jobs is None:\n",
       "   627                                                       # No specific context override and no specific value request:\n",
       "   628                                                       # default to 1.\n",
       "   629                                                       n_jobs = 1\n",
       "   630        21         37.0      1.8      1.0          self.n_jobs = n_jobs\n",
       "   631        21         43.0      2.0      1.2          self.verbose = verbose\n",
       "   632        21         32.0      1.5      0.9          self.timeout = timeout\n",
       "   633        21         31.0      1.5      0.9          self.pre_dispatch = pre_dispatch\n",
       "   634        21        950.0     45.2     26.8          self._ready_batches = queue.Queue()\n",
       "   635                                           \n",
       "   636        21         44.0      2.1      1.2          if isinstance(max_nbytes, _basestring):\n",
       "   637        21        322.0     15.3      9.1              max_nbytes = memstr_to_bytes(max_nbytes)\n",
       "   638                                           \n",
       "   639        21         33.0      1.6      0.9          self._backend_args = dict(\n",
       "   640        21         29.0      1.4      0.8              max_nbytes=max_nbytes,\n",
       "   641        21         27.0      1.3      0.8              mmap_mode=mmap_mode,\n",
       "   642        21         30.0      1.4      0.8              temp_folder=temp_folder,\n",
       "   643        21         26.0      1.2      0.7              prefer=prefer,\n",
       "   644        21         30.0      1.4      0.8              require=require,\n",
       "   645        21        118.0      5.6      3.3              verbose=max(0, self.verbose - 50),\n",
       "   646                                                   )\n",
       "   647        21         29.0      1.4      0.8          if DEFAULT_MP_CONTEXT is not None:\n",
       "   648                                                       self._backend_args['context'] = DEFAULT_MP_CONTEXT\n",
       "   649        21         53.0      2.5      1.5          elif hasattr(mp, \"get_context\"):\n",
       "   650        21        114.0      5.4      3.2              self._backend_args['context'] = mp.get_context()\n",
       "   651                                           \n",
       "   652        21         30.0      1.4      0.8          if backend is None:\n",
       "   653                                                       backend = active_backend\n",
       "   654                                           \n",
       "   655        21        154.0      7.3      4.3          elif isinstance(backend, ParallelBackendBase):\n",
       "   656                                                       # Use provided backend as is, with the current nesting_level if it\n",
       "   657                                                       # is not set yet.\n",
       "   658                                                       if backend.nesting_level is None:\n",
       "   659                                                           backend.nesting_level = nesting_level\n",
       "   660                                           \n",
       "   661        21         41.0      2.0      1.2          elif hasattr(backend, 'Pool') and hasattr(backend, 'Lock'):\n",
       "   662                                                       # Make it possible to pass a custom multiprocessing context as\n",
       "   663                                                       # backend to change the start method to forkserver or spawn or\n",
       "   664                                                       # preload modules on the forkserver helper process.\n",
       "   665                                                       self._backend_args['context'] = backend\n",
       "   666                                                       backend = MultiprocessingBackend(nesting_level=nesting_level)\n",
       "   667                                                   else:\n",
       "   668        21         29.0      1.4      0.8              try:\n",
       "   669        21         36.0      1.7      1.0                  backend_factory = BACKENDS[backend]\n",
       "   670                                                       except KeyError:\n",
       "   671                                                           raise ValueError(\"Invalid backend: %s, expected one of %r\"\n",
       "   672                                                                            % (backend, sorted(BACKENDS.keys())))\n",
       "   673        21         96.0      4.6      2.7              backend = backend_factory(nesting_level=nesting_level)\n",
       "   674                                           \n",
       "   675        21         31.0      1.5      0.9          if (require == 'sharedmem' and\n",
       "   676                                                           not getattr(backend, 'supports_sharedmem', False)):\n",
       "   677                                                       raise ValueError(\"Backend %s does not support shared memory\"\n",
       "   678                                                                        % backend)\n",
       "   679                                           \n",
       "   680        21         29.0      1.4      0.8          if (batch_size == 'auto' or isinstance(batch_size, Integral) and\n",
       "   681                                                           batch_size > 0):\n",
       "   682        21         35.0      1.7      1.0              self.batch_size = batch_size\n",
       "   683                                                   else:\n",
       "   684                                                       raise ValueError(\n",
       "   685                                                           \"batch_size must be 'auto' or a positive integer, got: %r\"\n",
       "   686                                                           % batch_size)\n",
       "   687                                           \n",
       "   688        21         30.0      1.4      0.8          self._backend = backend\n",
       "   689        21         34.0      1.6      1.0          self._output = None\n",
       "   690        21         43.0      2.0      1.2          self._jobs = list()\n",
       "   691        21         60.0      2.9      1.7          self._managed_backend = False\n",
       "   692                                           \n",
       "   693                                                   # This lock is used coordinate the main thread of this process with\n",
       "   694                                                   # the async callback thread of our the pool.\n",
       "   695        21        104.0      5.0      2.9          self._lock = threading.RLock()\n",
       "\n",
       "Total time: 0.001826 s\n",
       "File: /usr/local/lib/python3.7/site-packages/joblib/parallel.py\n",
       "Function: _initialize_backend at line 706\n",
       "\n",
       "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
       "==============================================================\n",
       "   706                                               def _initialize_backend(self):\n",
       "   707                                                   \"\"\"Build a process or thread pool and return the number of workers\"\"\"\n",
       "   708        21         16.0      0.8      0.9          try:\n",
       "   709        21         38.0      1.8      2.1              n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,\n",
       "   710        21       1739.0     82.8     95.2                                               **self._backend_args)\n",
       "   711        21         23.0      1.1      1.3              if self.timeout is not None and not self._backend.supports_timeout:\n",
       "   712                                                           warnings.warn(\n",
       "   713                                                               'The backend class {!r} does not support timeout. '\n",
       "   714                                                               \"You have set 'timeout={}' in Parallel but \"\n",
       "   715                                                               \"the 'timeout' parameter will not be used.\".format(\n",
       "   716                                                                   self._backend.__class__.__name__,\n",
       "   717                                                                   self.timeout))\n",
       "   718                                           \n",
       "   719                                                   except FallbackToBackend as e:\n",
       "   720                                                       # Recursively initialize the backend in case of requested fallback.\n",
       "   721                                                       self._backend = e.backend\n",
       "   722                                                       n_jobs = self._initialize_backend()\n",
       "   723                                           \n",
       "   724        21         10.0      0.5      0.5          return n_jobs\n",
       "\n",
       "Total time: 1.89933 s\n",
       "File: /usr/local/lib/python3.7/site-packages/joblib/parallel.py\n",
       "Function: _terminate_backend at line 731\n",
       "\n",
       "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
       "==============================================================\n",
       "   731                                               def _terminate_backend(self):\n",
       "   732        21         10.0      0.5      0.0          if self._backend is not None:\n",
       "   733        21    1899320.0  90443.8    100.0              self._backend.terminate()\n",
       "\n",
       "Total time: 0.183109 s\n",
       "File: /usr/local/lib/python3.7/site-packages/joblib/parallel.py\n",
       "Function: _dispatch at line 735\n",
       "\n",
       "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
       "==============================================================\n",
       "   735                                               def _dispatch(self, batch):\n",
       "   736                                                   \"\"\"Queue the batch for computing, with or without multiprocessing\n",
       "   737                                           \n",
       "   738                                                   WARNING: this method is not thread-safe: it should be only called\n",
       "   739                                                   indirectly via dispatch_one_batch.\n",
       "   740                                           \n",
       "   741                                                   \"\"\"\n",
       "   742                                                   # If job.get() catches an exception, it closes the queue:\n",
       "   743        84         70.0      0.8      0.0          if self._aborting:\n",
       "   744                                                       return\n",
       "   745                                           \n",
       "   746        84        163.0      1.9      0.1          self.n_dispatched_tasks += len(batch)\n",
       "   747        84         73.0      0.9      0.0          self.n_dispatched_batches += 1\n",
       "   748                                           \n",
       "   749        84        130.0      1.5      0.1          dispatch_timestamp = time.time()\n",
       "   750        84        300.0      3.6      0.2          cb = BatchCompletionCallBack(dispatch_timestamp, len(batch), self)\n",
       "   751        84        121.0      1.4      0.1          with self._lock:\n",
       "   752        84         76.0      0.9      0.0              job_idx = len(self._jobs)\n",
       "   753        84     181964.0   2166.2     99.4              job = self._backend.apply_async(batch, callback=cb)\n",
       "   754                                                       # A job can complete so quickly than its callback is\n",
       "   755                                                       # called before we get here, causing self._jobs to\n",
       "   756                                                       # grow. To ensure correct results ordering, .insert is\n",
       "   757                                                       # used (rather than .append) in the following line\n",
       "   758        84        212.0      2.5      0.1              self._jobs.insert(job_idx, job)\n",
       "\n",
       "Total time: 0.191877 s\n",
       "File: /usr/local/lib/python3.7/site-packages/joblib/parallel.py\n",
       "Function: dispatch_one_batch at line 772\n",
       "\n",
       "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
       "==============================================================\n",
       "   772                                               def dispatch_one_batch(self, iterator):\n",
       "   773                                                   \"\"\"Prefetch the tasks for the next batch and dispatch them.\n",
       "   774                                           \n",
       "   775                                                   The effective size of the batch is computed here.\n",
       "   776                                                   If there are no more jobs to dispatch, return False, else return True.\n",
       "   777                                           \n",
       "   778                                                   The iterator consumption and dispatching is protected by the same\n",
       "   779                                                   lock so calling this function should be thread safe.\n",
       "   780                                           \n",
       "   781                                                   \"\"\"\n",
       "   782       105        121.0      1.2      0.1          if self.batch_size == 'auto':\n",
       "   783       105        257.0      2.4      0.1              batch_size = self._backend.compute_batch_size()\n",
       "   784                                                   else:\n",
       "   785                                                       # Fixed batch size strategy\n",
       "   786                                                       batch_size = self.batch_size\n",
       "   787                                           \n",
       "   788       105        206.0      2.0      0.1          with self._lock:\n",
       "   789                                                       # to ensure an even distribution of the workolad between workers,\n",
       "   790                                                       # we look ahead in the original iterators more than batch_size\n",
       "   791                                                       # tasks - However, we keep consuming only one batch at each\n",
       "   792                                                       # dispatch_one_batch call. The extra tasks are stored in a local\n",
       "   793                                                       # queue, _ready_batches, that is looked-up prior to re-consuming\n",
       "   794                                                       # tasks from the origal iterator.\n",
       "   795       105         87.0      0.8      0.0              try:\n",
       "   796       105       1391.0     13.2      0.7                  tasks = self._ready_batches.get(block=False)\n",
       "   797        42         62.0      1.5      0.0              except queue.Empty:\n",
       "   798                                                           # slice the iterator n_jobs * batchsize items at a time. If the\n",
       "   799                                                           # slice returns less than that, then the current batchsize puts\n",
       "   800                                                           # too much weight on a subset of workers, while other may end\n",
       "   801                                                           # up starving. So in this case, re-scale the batch size\n",
       "   802                                                           # accordingly to distribute evenly the last items between all\n",
       "   803                                                           # workers.\n",
       "   804        42         44.0      1.0      0.0                  n_jobs = self._cached_effective_n_jobs\n",
       "   805        42         48.0      1.1      0.0                  big_batch_size = batch_size * n_jobs\n",
       "   806                                           \n",
       "   807        42       2575.0     61.3      1.3                  islice = list(itertools.islice(iterator, big_batch_size))\n",
       "   808        42         53.0      1.3      0.0                  if len(islice) == 0:\n",
       "   809        21         35.0      1.7      0.0                      return False\n",
       "   810        21         28.0      1.3      0.0                  elif (iterator is self._original_iterator\n",
       "   811                                                                 and len(islice) < big_batch_size):\n",
       "   812                                                               # We reached the end of the original iterator (unless\n",
       "   813                                                               # iterator is the ``pre_dispatch``-long initial slice of\n",
       "   814                                                               # the original iterator) -- decrease the batch size to\n",
       "   815                                                               # account for potential variance in the batches running\n",
       "   816                                                               # time.\n",
       "   817                                                               final_batch_size = max(1, len(islice) // (10 * n_jobs))\n",
       "   818                                                           else:\n",
       "   819        21         47.0      2.2      0.0                      final_batch_size = max(1, len(islice) // n_jobs)\n",
       "   820                                           \n",
       "   821                                                           # enqueue n_jobs batches in a local queue\n",
       "   822       105        161.0      1.5      0.1                  for i in range(0, len(islice), final_batch_size):\n",
       "   823        84        127.0      1.5      0.1                      tasks = BatchedCalls(islice[i:i + final_batch_size],\n",
       "   824        84        470.0      5.6      0.2                                           self._backend.get_nested_backend(),\n",
       "   825        84        421.0      5.0      0.2                                           self._pickle_cache)\n",
       "   826        84       1045.0     12.4      0.5                      self._ready_batches.put(tasks)\n",
       "   827                                           \n",
       "   828                                                           # finally, get one task.\n",
       "   829        21        296.0     14.1      0.2                  tasks = self._ready_batches.get(block=False)\n",
       "   830        84        264.0      3.1      0.1              if len(tasks) == 0:\n",
       "   831                                                           # No more tasks available in the iterator: tell caller to stop.\n",
       "   832                                                           return False\n",
       "   833                                                       else:\n",
       "   834        84     184034.0   2190.9     95.9                  self._dispatch(tasks)\n",
       "   835        84        105.0      1.2      0.1                  return True\n",
       "\n",
       "Total time: 0.009934 s\n",
       "File: /usr/local/lib/python3.7/site-packages/joblib/parallel.py\n",
       "Function: _print at line 837\n",
       "\n",
       "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
       "==============================================================\n",
       "   837                                               def _print(self, msg, msg_args):\n",
       "   838                                                   \"\"\"Display the message on stout or stderr depending on verbosity\"\"\"\n",
       "   839                                                   # XXX: Not using the logger framework: need to\n",
       "   840                                                   # learn to use logger better.\n",
       "   841        42         38.0      0.9      0.4          if not self.verbose:\n",
       "   842        30         22.0      0.7      0.2              return\n",
       "   843        12          8.0      0.7      0.1          if self.verbose < 50:\n",
       "   844        12         23.0      1.9      0.2              writer = sys.stderr.write\n",
       "   845                                                   else:\n",
       "   846                                                       writer = sys.stdout.write\n",
       "   847        12         30.0      2.5      0.3          msg = msg % msg_args\n",
       "   848        12       9813.0    817.8     98.8          writer('[%s]: %s\\n' % (self, msg))\n",
       "\n",
       "Total time: 66.2671 s\n",
       "File: /usr/local/lib/python3.7/site-packages/joblib/parallel.py\n",
       "Function: retrieve at line 893\n",
       "\n",
       "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
       "==============================================================\n",
       "   893                                               def retrieve(self):\n",
       "   894        21         41.0      2.0      0.0          self._output = list()\n",
       "   895       105        163.0      1.6      0.0          while self._iterating or len(self._jobs) > 0:\n",
       "   896        84         92.0      1.1      0.0              if len(self._jobs) == 0:\n",
       "   897                                                           # Wait for an async callback to dispatch new jobs\n",
       "   898                                                           time.sleep(0.01)\n",
       "   899                                                           continue\n",
       "   900                                                       # We need to be careful: the job list can be filling up as\n",
       "   901                                                       # we empty it and Python list are not thread-safe by default hence\n",
       "   902                                                       # the use of the lock\n",
       "   903        84        158.0      1.9      0.0              with self._lock:\n",
       "   904        84        422.0      5.0      0.0                  job = self._jobs.pop(0)\n",
       "   905                                           \n",
       "   906        84         75.0      0.9      0.0              try:\n",
       "   907        84        119.0      1.4      0.0                  if getattr(self._backend, 'supports_timeout', False):\n",
       "   908        84   66266004.0 788881.0    100.0                      self._output.extend(job.get(timeout=self.timeout))\n",
       "   909                                                           else:\n",
       "   910                                                               self._output.extend(job.get())\n",
       "   911                                           \n",
       "   912                                                       except BaseException as exception:\n",
       "   913                                                           # Note: we catch any BaseException instead of just Exception\n",
       "   914                                                           # instances to also include KeyboardInterrupt.\n",
       "   915                                           \n",
       "   916                                                           # Stop dispatching any new job in the async callback thread\n",
       "   917                                                           self._aborting = True\n",
       "   918                                           \n",
       "   919                                                           # If the backend allows it, cancel or kill remaining running\n",
       "   920                                                           # tasks without waiting for the results as we will raise\n",
       "   921                                                           # the exception we got back to the caller instead of returning\n",
       "   922                                                           # any result.\n",
       "   923                                                           backend = self._backend\n",
       "   924                                                           if (backend is not None and\n",
       "   925                                                                   hasattr(backend, 'abort_everything')):\n",
       "   926                                                               # If the backend is managed externally we need to make sure\n",
       "   927                                                               # to leave it in a working state to allow for future jobs\n",
       "   928                                                               # scheduling.\n",
       "   929                                                               ensure_ready = self._managed_backend\n",
       "   930                                                               backend.abort_everything(ensure_ready=ensure_ready)\n",
       "   931                                           \n",
       "   932                                                           if isinstance(exception, TransportableException):\n",
       "   933                                                               # Capture exception to add information on the local\n",
       "   934                                                               # stack in addition to the distant stack\n",
       "   935                                                               this_report = format_outer_frames(context=10,\n",
       "   936                                                                                                 stack_start=1)\n",
       "   937                                                               raise exception.unwrap(this_report)\n",
       "   938                                                           else:\n",
       "   939                                                               raise\n",
       "\n",
       "Total time: 68.3772 s\n",
       "File: /usr/local/lib/python3.7/site-packages/joblib/parallel.py\n",
       "Function: __call__ at line 941\n",
       "\n",
       "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
       "==============================================================\n",
       "   941                                               def __call__(self, iterable):\n",
       "   942        21         37.0      1.8      0.0          if self._jobs:\n",
       "   943                                                       raise ValueError('This Parallel instance is already running')\n",
       "   944                                                   # A flag used to abort the dispatching of jobs in case an\n",
       "   945                                                   # exception is found\n",
       "   946        21         29.0      1.4      0.0          self._aborting = False\n",
       "   947                                           \n",
       "   948        21         29.0      1.4      0.0          if not self._managed_backend:\n",
       "   949        21       2052.0     97.7      0.0              n_jobs = self._initialize_backend()\n",
       "   950                                                   else:\n",
       "   951                                                       n_jobs = self._effective_n_jobs()\n",
       "   952                                           \n",
       "   953                                                   # self._effective_n_jobs should be called in the Parallel.__call__\n",
       "   954                                                   # thread only -- store its value in an attribute for further queries.\n",
       "   955        21         26.0      1.2      0.0          self._cached_effective_n_jobs = n_jobs\n",
       "   956                                           \n",
       "   957        21         49.0      2.3      0.0          backend_name = self._backend.__class__.__name__\n",
       "   958        21         26.0      1.2      0.0          if n_jobs == 0:\n",
       "   959                                                       raise RuntimeError(\"%s has no active worker.\" % backend_name)\n",
       "   960                                           \n",
       "   961        21         30.0      1.4      0.0          self._print(\"Using backend %s with %d concurrent workers.\",\n",
       "   962        21       5739.0    273.3      0.0                      (backend_name, n_jobs))\n",
       "   963        21         51.0      2.4      0.0          if hasattr(self._backend, 'start_call'):\n",
       "   964        21         54.0      2.6      0.0              self._backend.start_call()\n",
       "   965        21         40.0      1.9      0.0          iterator = iter(iterable)\n",
       "   966        21         27.0      1.3      0.0          pre_dispatch = self.pre_dispatch\n",
       "   967                                           \n",
       "   968        21         29.0      1.4      0.0          if pre_dispatch == 'all' or n_jobs == 1:\n",
       "   969                                                       # prevent further dispatch via multiprocessing callback thread\n",
       "   970                                                       self._original_iterator = None\n",
       "   971                                                       self._pre_dispatch_amount = 0\n",
       "   972                                                   else:\n",
       "   973        21         30.0      1.4      0.0              self._original_iterator = iterator\n",
       "   974        21         40.0      1.9      0.0              if hasattr(pre_dispatch, 'endswith'):\n",
       "   975        21       1045.0     49.8      0.0                  pre_dispatch = eval(pre_dispatch)\n",
       "   976        21         62.0      3.0      0.0              self._pre_dispatch_amount = pre_dispatch = int(pre_dispatch)\n",
       "   977                                           \n",
       "   978                                                       # The main thread will consume the first pre_dispatch items and\n",
       "   979                                                       # the remaining items will later be lazily dispatched by async\n",
       "   980                                                       # callbacks upon task completions.\n",
       "   981                                           \n",
       "   982                                                       # TODO: this iterator should be batch_size * n_jobs\n",
       "   983        21         68.0      3.2      0.0              iterator = itertools.islice(iterator, self._pre_dispatch_amount)\n",
       "   984                                           \n",
       "   985        21         67.0      3.2      0.0          self._start_time = time.time()\n",
       "   986        21         38.0      1.8      0.0          self.n_dispatched_batches = 0\n",
       "   987        21         28.0      1.3      0.0          self.n_dispatched_tasks = 0\n",
       "   988        21         27.0      1.3      0.0          self.n_completed_tasks = 0\n",
       "   989                                                   # Use a caching dict for callables that are pickled with cloudpickle to\n",
       "   990                                                   # improve performances. This cache is used only in the case of\n",
       "   991                                                   # functions that are defined in the __main__ module, functions that are\n",
       "   992                                                   # defined locally (inside another function) and lambda expressions.\n",
       "   993        21         41.0      2.0      0.0          self._pickle_cache = dict()\n",
       "   994        21         24.0      1.1      0.0          try:\n",
       "   995                                                       # Only set self._iterating to True if at least a batch\n",
       "   996                                                       # was dispatched. In particular this covers the edge\n",
       "   997                                                       # case of Parallel used with an exhausted iterator. If\n",
       "   998                                                       # self._original_iterator is None, then this means either\n",
       "   999                                                       # that pre_dispatch == \"all\", n_jobs == 1 or that the first batch\n",
       "  1000                                                       # was very quick and its callback already dispatched all the\n",
       "  1001                                                       # remaining jobs.\n",
       "  1002        21         59.0      2.8      0.0              self._iterating = False\n",
       "  1003        21     187379.0   8922.8      0.3              if self.dispatch_one_batch(iterator):\n",
       "  1004        21         52.0      2.5      0.0                  self._iterating = self._original_iterator is not None\n",
       "  1005                                           \n",
       "  1006        84       6699.0     79.8      0.0              while self.dispatch_one_batch(iterator):\n",
       "  1007        63         69.0      1.1      0.0                  pass\n",
       "  1008                                           \n",
       "  1009        21         29.0      1.4      0.0              if pre_dispatch == \"all\" or n_jobs == 1:\n",
       "  1010                                                           # The iterable was consumed all at once by the above for loop.\n",
       "  1011                                                           # No need to wait for async callbacks to trigger to\n",
       "  1012                                                           # consumption.\n",
       "  1013                                                           self._iterating = False\n",
       "  1014                                           \n",
       "  1015        21        337.0     16.0      0.0              with self._backend.retrieval_context():\n",
       "  1016        21   66268176.0 3155627.4     96.9                  self.retrieve()\n",
       "  1017                                                       # Make sure that we get a last message telling us we are done\n",
       "  1018        21         52.0      2.5      0.0              elapsed_time = time.time() - self._start_time\n",
       "  1019        21         31.0      1.5      0.0              self._print('Done %3i out of %3i | elapsed: %s finished',\n",
       "  1020        21         30.0      1.4      0.0                          (len(self._output), len(self._output),\n",
       "  1021        21       4674.0    222.6      0.0                           short_format_time(elapsed_time)))\n",
       "  1022                                                   finally:\n",
       "  1023        21         51.0      2.4      0.0              if hasattr(self._backend, 'stop_call'):\n",
       "  1024        21         48.0      2.3      0.0                  self._backend.stop_call()\n",
       "  1025        21         23.0      1.1      0.0              if not self._managed_backend:\n",
       "  1026        21    1899526.0  90453.6      2.8                  self._terminate_backend()\n",
       "  1027        21        132.0      6.3      0.0              self._jobs = list()\n",
       "  1028        21         52.0      2.5      0.0              self._pickle_cache = None\n",
       "  1029        21         52.0      2.5      0.0          output = self._output\n",
       "  1030        21         38.0      1.8      0.0          self._output = None\n",
       "  1031        21         29.0      1.4      0.0          return output\n",
       "\n",
       "Total time: 2.7e-05 s\n",
       "File: /usr/local/lib/python3.7/site-packages/joblib/parallel.py\n",
       "Function: __repr__ at line 1033\n",
       "\n",
       "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
       "==============================================================\n",
       "  1033                                               def __repr__(self):\n",
       "  1034        12         27.0      2.2    100.0          return '%s(n_jobs=%s)' % (self.__class__.__name__, self.n_jobs)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%lprun -m ExploreBFS -s speed.BFS_Run(4, 500, backend = \"threading\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
